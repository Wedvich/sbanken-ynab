{"version":3,"file":"905.index.js","mappings":";;;;;;;AAAA,cAAc,mBAAO,CAAC,KAAQ;AAC9B,YAAY,mBAAO,CAAC,KAAM;AAC1B,iBAAiB,mBAAO,CAAC,KAAY;AACrC,gBAAgB,mBAAO,CAAC,KAAW;;AAEnC;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,UAAU;AACV;AACA;AACA;;AAEA;AACA;;AAEA,YAAY,sBAAsB;;AAElC;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,gBAAgB,uBAAuB;AACvC;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;;AAET;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,cAAc;AACd;AACA;AACA,SAAS;;AAET;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;;AAET;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,sBAAsB;AACtB;AACA;AACA,iBAAiB;AACjB,cAAc;AACd;AACA;AACA,SAAS;;AAET;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;;AAET;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;;AAET;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;;AAET;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;;AAET;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;;AAET;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;;AAET;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA,cAAc;AACd;AACA;AACA,SAAS;;AAET;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB,cAAc;AACd;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA,yFAAyF;AACzF;AACA;AACA;AACA;AACA,8BAA8B;AAC9B;AACA;AACA;AACA,qBAAqB;AACrB;AACA,cAAc;AACd;AACA;AACA,SAAS;;AAET;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB,cAAc;AACd;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA,kBAAkB;AAClB;AACA,kBAAkB;AAClB;AACA;;AAEA;AACA;AACA;AACA;AACA,6FAA6F;AAC7F;AACA;AACA;AACA,+DAA+D;AAC/D;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8CAA8C;AAC9C;AACA;AACA;AACA,yCAAyC;AACzC,sCAAsC;AACtC;AACA;AACA;AACA,iCAAiC;AACjC,8BAA8B;AAC9B;AACA;AACA,0BAA0B;AAC1B;AACA;AACA;;AAEA;AACA;AACA,aAAa;AACb,SAAS;;AAET;AACA;AACA,mBAAmB,QAAQ;AAC3B,mBAAmB,QAAQ;AAC3B,mBAAmB,QAAQ;AAC3B,mBAAmB,kBAAkB;AACrC;AACA;AACA;AACA,wBAAwB,kBAAkB,kBAAkB;AAC5D;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA,aAAa;AACb,SAAS;;AAET;AACA;AACA;AACA;AACA;AACA,mBAAmB,QAAQ;AAC3B,mBAAmB,iBAAiB;AACpC,mBAAmB,QAAQ;AAC3B,mBAAmB,iBAAiB;AACpC;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA,yDAAyD;;AAEzD;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,kBAAkB;AAClB;AACA;AACA,kBAAkB;AAClB;AACA,+DAA+D;AAC/D;;AAEA,4DAA4D;AAC5D;;AAEA;;AAEA;AACA;AACA,SAAS;;AAET;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;;AAET;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;;AAET;AACA;AACA,SAAS;;AAET;AACA;AACA,SAAS;;AAET;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,SAAS;;AAET;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kBAAkB;AAClB;AACA;AACA;AACA;AACA,SAAS;;AAET;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kBAAkB;AAClB;AACA;AACA,aAAa;AACb,SAAS;;AAET;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,kBAAkB;AAClB;AACA;AACA,aAAa;;AAEb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kBAAkB;AAClB;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sBAAsB;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B;AAC7B,yBAAyB;AACzB;AACA,iBAAiB;AACjB;AACA;AACA;AACA,SAAS;;AAET;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,SAAS;;AAET;AACA,oBAAoB,kBAAkB,kBAAkB,iBAAiB;;AAEzE;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,iBAAiB;AACjB,aAAa;AACb,SAAS;;AAET;AACA;AACA;AACA,aAAa;AACb,SAAS;;AAET;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC9wBA,YAAY,mBAAO,CAAC,KAAS;AAC7B;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qCAAqC;AACrC;;AAEA;;AAEA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,SAAS;;AAET;AACA;AACA,SAAS;AACT;AACA;AACA,SAAS;;AAET;AACA;AACA,SAAS;AACT;AACA;AACA,SAAS;;AAET;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;;AAET;AACA;AACA,SAAS;AACT;AACA;AACA,SAAS;;AAET;AACA;AACA,SAAS;AACT;AACA;AACA,SAAS;;AAET;AACA;AACA,SAAS;AACT;AACA;AACA,SAAS;;AAET;AACA;AACA,SAAS;AACT;AACA;AACA,SAAS;;AAET;AACA;AACA,SAAS;AACT;AACA;AACA,SAAS;;AAET;AACA;AACA,SAAS;AACT;AACA;AACA,SAAS;;AAET;AACA;AACA,SAAS;AACT;AACA;AACA,SAAS;;AAET;AACA;AACA,SAAS;AACT;AACA;AACA,SAAS;;AAET;AACA;AACA,SAAS;AACT;AACA;AACA,SAAS;;AAET;AACA;AACA,SAAS;AACT;AACA;AACA,SAAS;;AAET;AACA;AACA;AACA,SAAS;;AAET;AACA;AACA,SAAS;AACT;AACA;AACA,SAAS;;AAET;AACA;AACA,SAAS;;AAET;AACA;AACA,SAAS;;AAET;AACA;AACA,SAAS;;AAET;AACA;AACA,SAAS;;AAET;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;;AAET;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;;AAET;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;;AAET;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;;AAET;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;;AAET;AACA;AACA;AACA;AACA;;;;;;;;ACjVA,gDAA8C;AAC9C,+CAA4C;;;;;;;;ACD5C,YAAY,mBAAO,CAAC,KAAS;AAC7B;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,SAAS;;AAET;AACA;AACA,SAAS;AACT;AACA;AACA,SAAS;;AAET;AACA;AACA,SAAS;AACT;AACA;AACA,SAAS;;AAET;AACA;AACA,SAAS;AACT;AACA;AACA,SAAS;;AAET;AACA;AACA,SAAS;AACT;AACA;AACA,SAAS;;AAET;AACA;AACA,SAAS;;AAET;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,cAAc;AACd;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,SAAS;;AAET;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,SAAS;;AAET;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;;AAET;AACA;AACA;AACA;AACA;;;;;;;;AChIA;AACA,eAAe,mBAAO,CAAC,KAAM;;AAE7B,iBAAiB;;AAEjB;AACA;AACA;AACA,SAAS;;AAET;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA,gCAAgC,kBAAkB;AAClD;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;;;;;;;;AChCA,6CAAwC;AACxC,6CAAwC;AACxC,8CAA0C;;;;;;;;ACF1C;AACA,eAAe,mBAAO,CAAC,KAAM;;AAE7B;AACA;AACA;AACA,SAAS;;AAET;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA,gCAAgC,kBAAkB;AAClD;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;;;;;;;;;AC9Ba;;AAEb;AACA;AACA,QAAQ,iBAAiB,EAAE,mBAAO,CAAC,KAAQ;;AAE3C;AACA;AACA,oBAAoB,OAAO;AAC3B;AACA;AACA,UAAU;AACV;AACA;AACA;AACA;AACA,CAAC;;AAED;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,oBAAoB,SAAS;AAC7B;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,oBAAoB,iBAAiB;AACrC;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,wCAAwC;AACxC,yCAAyC;AACzC;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC;AACjC,8DAA8D;AAC9D;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,mCAAmC;AACnC,mCAAmC;AACnC,gCAAgC;AAChC;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,mBAAmB;;;;;;;;ACzKnB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC7IA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AClCA,WAAW,kCAA+B;AAC1C,YAAY,mBAAO,CAAC,KAAM;;AAE1B;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,sDAAsD;AACtD,oDAAoD;AACpD;AACA,MAAM;AACN;AACA;;AAEA;AACA;AACA;AACA,SAAS;;AAET;AACA;AACA,SAAS;;AAET;AACA;AACA,SAAS;;AAET;AACA;AACA,SAAS;;AAET;AACA;AACA,SAAS;;AAET;AACA;AACA,SAAS;;AAET,wCAAwC;;AAExC,wCAAwC;;AAExC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;;AAET;AACA;AACA;AACA;AACA;;;;;;;;AC9EA,eAAe;AACf;AACA;AACA,+BAA+B,mBAAO,CAAC,0IAAa;AACpD;AACA;AACA;AACA,UAAU;AACV;AACA,WAAW,mBAAO,CAAC,KAAI;AACvB;;;;;;;;ACVA,0CAAmC;AACnC,qDAAiD;AACjD,kDAA2C;AAC3C,oDAA4C;;;;;;;;ACH5C,gBAAgB,kCAA+B;AAC/C,YAAY,mBAAO,CAAC,KAAM;AAC1B,kBAAkB,mBAAO,CAAC,KAAa;AACvC;;AAEA;;AAEA;AACA;AACA,oBAAoB,OAAO;AAC3B;AACA;AACA,UAAU;AACV;AACA;AACA;AACA;AACA,CAAC;;AAED;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,cAAc;AACd;AACA;AACA;AACA,SAAS;AACT;;AAEA;AACA;;AAEA;AACA;AACA;AACA,sCAAsC;;AAEtC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,+CAA+C;AAC/C,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA,UAAU;AACV;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yCAAyC;AACzC,qCAAqC;AACrC,iCAAiC;AACjC,6BAA6B;AAC7B,yBAAyB;AACzB,sBAAsB;AACtB;AACA;AACA;AACA;AACA,iCAAiC;AACjC,6BAA6B;AAC7B,yBAAyB;AACzB,sBAAsB;AACtB;AACA;AACA,yBAAyB;AACzB;AACA,iBAAiB;AACjB,aAAa;AACb,SAAS;AACT,KAAK;AACL;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA,SAAS;AACT;AACA;;AAEA;AACA;;AAEA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,sBAAsB,WAAW;AACjC;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,sCAAsC,OAAO;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA,MAAM;AACN;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,yBAAyB,sBAAsB;AAC/C;;AAEA,qBAAqB;AACrB;;;;;;;;ACrPA,YAAY,mBAAO,CAAC,KAAQ;AAC5B,cAAc,mBAAO,CAAC,KAAW;AACjC;AACA,cAAc,mBAAO,CAAC,KAAW;;AAEjC;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,UAAU;AACV;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iFAAiF;AACjF;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA,iFAAiF;AACjF;AACA,kBAAkB;AAClB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kBAAkB;AAClB;AACA;AACA;AACA;AACA,wEAAwE;AACxE,8BAA8B;AAC9B;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sBAAsB;AACtB;AACA;AACA;AACA;AACA;AACA,yBAAyB;AACzB;AACA;AACA;AACA;AACA,UAAU;AACV;AACA,UAAU;AACV;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA,SAAS;;AAET;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,SAAS;;AAET;AACA;AACA,SAAS;AACT;AACA;AACA;AACA,SAAS;;AAET;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,SAAS;;AAET;AACA;AACA,SAAS;;AAET;AACA;AACA,SAAS;;AAET;AACA;AACA;AACA;AACA;AACA;AACA;AACA,cAAc;AACd;AACA;AACA;AACA,SAAS;;AAET;AACA;AACA;AACA,cAAc;AACd;AACA;AACA,SAAS;;AAET;AACA;AACA;AACA,cAAc;AACd;AACA;AACA,SAAS;;AAET;AACA;AACA,SAAS;AACT;AACA;AACA,SAAS;;AAET;AACA;AACA,SAAS;;AAET;AACA;AACA,SAAS;;AAET;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;;AAET;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;;AAET;AACA;AACA;AACA;AACA;;;;;;;;AC5UA,iBAAiB,mBAAO,CAAC,KAAY;AACrC,gBAAgB,mBAAO,CAAC,KAAW;AACnC,cAAc,mBAAO,CAAC,KAAQ;;AAE9B;AACA;AACA,uBAAuB;AACvB;AACA;AACA;;AAEA;AACA;;AAEA,YAAY,SAAS;;AAErB;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;;AAEA;AACA,qDAAqD;AACrD,uCAAuC;;AAEvC,wBAAwB,kBAAkB;AAC1C;AACA;;AAEA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,uDAAuD;AACvD,uCAAuC;AACvC,wBAAwB,sBAAsB;AAC9C;AACA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,gBAAgB,QAAQ;AACxB,gDAAgD;AAChD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;;AAET;AACA;AACA,oBAAoB;AACpB;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA,SAAS;;AAET;AACA;AACA;AACA;;AAEA;AACA,SAAS;;AAET;AACA;AACA;AACA;AACA;;AAEA;AACA,SAAS;;AAET;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;;AAET;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;;AAET;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA,SAAS;;AAET;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA,SAAS;;AAET;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,oDAAoD;AACpD;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,2DAA2D;AAC3D;AACA;;AAEA;AACA,SAAS;;AAET;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA,yBAAyB;AACzB,sBAAsB;AACtB,gEAAgE;AAChE;AACA;;AAEA;AACA;AACA;AACA,6DAA6D;AAC7D;AACA,yBAAyB;AACzB;AACA,6DAA6D;AAC7D;AACA,yBAAyB;;AAEzB;AACA;AACA,uEAAuE;AACvE;;AAEA,oDAAoD;;AAEpD;AACA;AACA;;AAEA;AACA,cAAc;AACd;AACA;AACA;AACA;AACA;;;;;;;;;AC/XY;;AAEZ,QAAQ,SAAS,EAAE,mBAAO,CAAC,KAAQ;AACnC;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA,wCAAwC,aAAa;;AAErD;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA,kBAAkB,uBAAuB;AACzC;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,kBAAkB,cAAc;AAChC;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,oBAAoB,uBAAuB;AAC3C;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA,uBAAuB,uBAAuB;AAC9C;;AAEA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA,IAAI;AACJ;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA,kBAAkB,uBAAuB;AACzC;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,IAAI;AACJ,oBAAoB,gBAAgB;AACpC;AACA;AACA,IAAI;AACJ;AACA,oBAAoB,sBAAsB;AAC1C;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,IAAI;AACJ;AACA,IAAI;AACJ;AACA,IAAI;AACJ;AACA,IAAI;AACJ;AACA,IAAI;AACJ;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA,SAAS,6BAA6B;AACtC;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA,QAAQ;AACR;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA,6BAA6B,8BAA8B;AAC3D;AACA;AACA;AACA;AACA;AACA;;AAEA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ;AACR;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;;AAED;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;;;;;;;;AC3YY;;AAEZ,qBAAqB,iCAAiC;AACtD,iBAAiB,mBAAO,CAAC,KAAU;AACnC,mBAAmB,mBAAO,CAAC,IAAc;;AAEzC;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;;AAEL;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;;AAEL;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA,+BAA+B;AAC/B,yBAAyB;;;;;;;;ACnFzB;AACA,aAAa,mBAAO,CAAC,KAAM;AAC3B;AACA;AACA;AACA,EAAE;AACF;AACA,EAAE,2CAAiD;AACnD;;;;;;;;ACRA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA,EAAE;AACF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AC1Ba;;AAEb;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,OAAO,EAAE,sCAAsC;AACtE;AACA,MAAM;AACN,uBAAuB,OAAO,EAAE,aAAa,KAAK,YAAY;AAC9D,MAAM;AACN,mBAAmB,OAAO,EAAE,YAAY;AACxC;AACA,IAAI;AACJ,iBAAiB,OAAO,EAAE,iBAAiB;AAC3C;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,IAAI;AACJ;AACA;AACA;;AAEA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;;AAEA;AACA;AACA;AACA,iBAAiB,MAAM,EAAE,YAAY,EAAE,wBAAwB;AAC/D,IAAI;AACJ;AACA,kBAAkB,KAAK,IAAI,MAAM,EAAE,YAAY,EAAE,wBAAwB;AACzE;;AAEA,4BAA4B,cAAc;AAC1C;AACA,CAAC;AACD;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;;AAEA,gBAAoB;;;;;;;;;ACnHpB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACa;AACb;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;;AAGA;;AAEA,eAAe,mBAAO,CAAC,KAAoB;;AAE3C,eAAe,mBAAO,CAAC,KAAoB;;AAE3C,mBAAO,CAAC,KAAU;;AAElB;AACA;AACA;;AAEA,kBAAkB,iBAAiB;AACnC;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,GAAG;;AAEJ;AACA;AACA,yCAAyC;AACzC;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;;;AAGA;AACA;AACA;AACA,CAAC;;;;;;;;AC1ID;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACa;;AAEb;;AAEA,gBAAgB,mBAAO,CAAC,KAAqB;;AAE7C,mBAAO,CAAC,KAAU;;AAElB;AACA;AACA;AACA;;AAEA;AACA;AACA;;;;;;;;ACtCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACa;;AAEb;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA,SAAS,uCAA8B;;AAEvC;AACA;AACA;AACA;;AAEA;;;AAGA,aAAa,mBAAO,CAAC,KAA2B;AAChD;;;AAGA,aAAa,iCAAwB;;AAErC;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;;AAGA,gBAAgB,mBAAO,CAAC,KAAM;;AAE9B;;AAEA;AACA;AACA,EAAE;AACF;AACA;AACA;;;AAGA,iBAAiB,mBAAO,CAAC,KAAgC;;AAEzD,kBAAkB,mBAAO,CAAC,KAA4B;;AAEtD,eAAe,mBAAO,CAAC,KAA0B;AACjD;;AAEA,qBAAqB,wCAA0B;AAC/C;AACA;AACA;AACA,4FAA4F;;;AAG5F;AACA;AACA;;AAEA,mBAAO,CAAC,KAAU;;AAElB;AACA;;AAEA;AACA;AACA;AACA,gGAAgG;AAChG;AACA;AACA;;AAEA,yEAAyE,mFAAmF;AAC5J;;AAEA;AACA,qBAAqB,mBAAO,CAAC,KAAkB;AAC/C,2BAA2B;AAC3B;AACA;AACA;AACA;;AAEA,0EAA0E;AAC1E;;AAEA;AACA,mFAAmF;AACnF;;AAEA,2FAA2F;AAC3F;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB;AACxB;AACA;AACA;;AAEA,oBAAoB;AACpB;;AAEA;AACA;AACA;AACA;AACA,sBAAsB;;AAEtB,gDAAgD;;AAEhD,4CAA4C;;AAE5C,0BAA0B;AAC1B;AACA;;AAEA,4DAA4D;;AAE5D,uBAAuB;;AAEvB;AACA;AACA;;AAEA;AACA,wCAAwC,iDAAwC;AAChF;AACA;AACA;AACA;;AAEA;AACA,qBAAqB,mBAAO,CAAC,KAAkB;AAC/C,iEAAiE;AACjE;;AAEA;AACA,oEAAoE;;AAEpE;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;;;AAGA;AACA;AACA,CAAC;AACD;AACA;;AAEA;AACA;AACA,GAAG;AACH;AACA;AACA;;;AAGA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA,IAAI;AACJ;AACA;;AAEA;AACA,GAAG;;;AAGH;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,IAAI;AACJ;AACA;;AAEA;AACA;AACA,MAAM;AACN;AACA;AACA;;AAEA;AACA,+FAA+F;AAC/F,QAAQ;AACR;AACA,QAAQ;AACR;AACA,QAAQ;AACR;;AAEA;AACA;AACA,4FAA4F;AAC5F,UAAU;AACV;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,IAAI;AACJ;AACA;;;AAGA;AACA;;AAEA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA,gDAAgD;AAChD;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA,GAAG;;;AAGH;AACA,sCAAsC,iDAAwC;AAC9E;AACA,yCAAyC;;AAEzC,uEAAuE;;AAEvE;AACA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA,GAAG;;;AAGH;;AAEA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,EAAE;AACF;;;AAGA;AACA;AACA;;AAEA;AACA;AACA,4EAA4E;AAC5E,IAAI;;;AAGJ;AACA,mCAAmC;;AAEnC;AACA;AACA;AACA;;AAEA;AACA,EAAE;;;AAGF;AACA;AACA;AACA;AACA;AACA,8CAA8C;AAC9C;AACA;;AAEA;AACA;AACA,6DAA6D;AAC7D;AACA;;AAEA,+BAA+B;;AAE/B;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AAGA;AACA,kCAAkC;;AAElC;AACA;AACA;AACA,IAAI;AACJ;;;AAGA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA,uBAAuB;;AAEvB,uDAAuD;;AAEvD;;AAEA,wBAAwB;AACxB;;AAEA;AACA;;AAEA;AACA,sCAAsC;;AAEtC;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;;AAEA;AACA;AACA;AACA,iDAAiD;;AAEjD;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,EAAE;AACF;AACA;;;AAGA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;;;AAGA;AACA;AACA,EAAE;AACF;AACA;AACA;AACA;AACA;;;AAGA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,EAAE;AACF;AACA;AACA;;;AAGA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,gDAAgD;AAChD;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;;;AAGA;AACA;AACA;;AAEA;AACA,sBAAsB;;AAEtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sBAAsB;AACtB;AACA;AACA;AACA;;AAEA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,IAAI;AACJ;;;AAGA;AACA;AACA;AACA;AACA;AACA,IAAI;;;AAGJ,2CAA2C;;AAE3C;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA,IAAI;;;AAGJ,0BAA0B;;AAE1B;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,KAAK;;AAEL,2CAA2C;;AAE3C;AACA;AACA;AACA,mCAAmC;;AAEnC;AACA;AACA;AACA;AACA;AACA,IAAI;;;AAGJ;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,oBAAoB,SAAS;AAC7B;AACA;AACA,OAAO;AACP;;AAEA;AACA,IAAI;;;AAGJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;;;AAGA;AACA;AACA;;AAEA;AACA;AACA;AACA,kEAAkE;;AAElE;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,QAAQ;AACR;AACA;AACA;AACA;;AAEA;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,0BAA0B;AAC1B,IAAI;AACJ;AACA;AACA;;AAEA;AACA;AACA;AACA,EAAE;AACF;;;AAGA;AACA;;AAEA;AACA,qBAAqB;AACrB;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,EAAE;AACF;AACA;;;AAGA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA,GAAG;AACH;AACA;AACA,2DAA2D;;AAE3D,4EAA4E;;AAE5E;;AAEA;AACA;AACA;AACA;AACA,GAAG,GAAG;AACN;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA,IAAI;;;AAGJ,kBAAkB,yBAAyB;AAC3C;AACA,IAAI;AACJ;;;AAGA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA,0CAA0C,mBAAO,CAAC,KAAmC;AACrF;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA,CAAC,GAAG;;AAEJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,GAAG;AACJ;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,mDAAmD;AACnD;AACA,mDAAmD,+DAA+D;AAClH;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA,0DAA0D;;AAE1D;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,aAAa,mBAAO,CAAC,KAAyB;AAC9C;;AAEA;AACA;AACA;;AAEA;AACA,iCAAiC,OAAO;AACxC;AACA;;AAEA;AACA;;;;;;;;ACnmCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0CAA0C,aAAa;AACvD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACa;;AAEb;;AAEA,qBAAqB,wCAA0B;AAC/C;AACA;AACA;AACA;;AAEA,aAAa,mBAAO,CAAC,KAAkB;;AAEvC,mBAAO,CAAC,KAAU;;AAElB;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;;AAEL,2CAA2C;AAC3C;AACA;;AAEA;;AAEA;AACA;AACA;AACA,IAAI;;;AAGJ;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA,KAAK;AACL,IAAI;AACJ;AACA;AACA;;AAEA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AAGA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;;;AAGA;AACA;;AAEA;AACA;;AAEA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA,uBAAuB;AACvB;AACA;;AAEA;AACA;AACA;AACA;;;;;;;;ACxMA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACa;;AAEb;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,EAAE;AACF;;;AAGA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;;;AAGA;AACA;;AAEA;AACA;;AAEA;AACA,aAAa,mBAAO,CAAC,KAAgB;AACrC;AACA;;AAEA;;AAEA,aAAa,mBAAO,CAAC,KAA2B;AAChD;;;AAGA,aAAa,iCAAwB;;AAErC;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,kBAAkB,mBAAO,CAAC,KAA4B;;AAEtD,eAAe,mBAAO,CAAC,KAA0B;AACjD;;AAEA,qBAAqB,wCAA0B;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA,mBAAO,CAAC,KAAU;;AAElB;;AAEA;AACA,qBAAqB,mBAAO,CAAC,KAAkB;AAC/C,2BAA2B;AAC3B;AACA;AACA;AACA;;AAEA,0EAA0E;AAC1E;;AAEA;AACA,mFAAmF;AACnF;AACA;;AAEA,2FAA2F;;AAE3F,4BAA4B;;AAE5B,0BAA0B;;AAE1B,uBAAuB;;AAEvB,sBAAsB;;AAEtB,yBAAyB;;AAEzB,0BAA0B;AAC1B;AACA;;AAEA;AACA,kCAAkC;AAClC;AACA;;AAEA,4DAA4D;AAC5D;AACA;;AAEA,mBAAmB;;AAEnB,wBAAwB;;AAExB,mBAAmB;AACnB;AACA;AACA;;AAEA,oBAAoB;AACpB;AACA;;AAEA,iCAAiC;;AAEjC;AACA;AACA,KAAK;;;AAGL,uBAAuB;;AAEvB;AACA;AACA,mCAAmC;AACnC;;AAEA,sBAAsB;AACtB;;AAEA,4BAA4B;;AAE5B,6BAA6B;;AAE7B,gDAAgD;;AAEhD,4CAA4C;;AAE5C,iCAAiC;AACjC;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL,IAAI;AACJ,CAAC,KAAK;AACN;;;AAGA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH,EAAE;AACF;AACA;AACA;AACA;;AAEA;AACA,qBAAqB,mBAAO,CAAC,KAAkB,GAAG;AAClD;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,oEAAoE;;AAEpE;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,EAAE;;;AAGF;AACA;AACA;;AAEA;AACA,6CAA6C;;AAE7C;AACA;AACA,EAAE;AACF;AACA;;;AAGA;AACA;;AAEA;AACA;AACA,IAAI;AACJ;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA,iCAAiC;AACjC;AACA,4CAA4C;AAC5C;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;;AAED;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,GAAG;AACJ;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,gDAAgD;;AAEhD;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,MAAM;AACN;AACA;;AAEA;AACA,IAAI;AACJ;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,wEAAwE,sDAAsD;AAC9H;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA,8BAA8B;AAC9B;;AAEA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA,gCAAgC;AAChC;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,oDAAoD;AACpD;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,EAAE;AACF;AACA;;;AAGA;AACA;AACA;AACA;AACA;AACA,EAAE;;;AAGF;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,2EAA2E;AAC3E;;AAEA;AACA;;AAEA;AACA;AACA;AACA,MAAM;AACN;AACA;;AAEA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oCAAoC;AACpC;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;;AAEA,0EAA0E;;AAE1E;AACA;AACA;AACA,IAAI;;;AAGJ;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;;AAED;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA,6CAA6C;AAC7C;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,IAAI;;;AAGJ;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;;;AAGA;AACA;AACA,CAAC;AACD;AACA;;AAEA;AACA;AACA;;;;;;;;ACxrBa;;AAEb;;AAEA,4CAA4C,kBAAkB,kCAAkC,oEAAoE,KAAK,OAAO,oBAAoB;;AAEpM,eAAe,mBAAO,CAAC,IAAiB;;AAExC;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA,qCAAqC;AACrC;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,KAAK;AACL;AACA;;AAEA,iEAAiE;AACjE;AACA;AACA;AACA,GAAG;;AAEH;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY;AACZ;AACA;AACA,SAAS;AACT,OAAO;AACP,MAAM;AACN;AACA;AACA;;;AAGA;AACA;;AAEA;AACA;AACA,MAAM;AACN;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA,CAAC;AACD;AACA,CAAC;AACD;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,KAAK;AACL,GAAG;AACH,CAAC;;AAED;AACA;;AAEA,yFAAyF;AACzF;AACA;AACA,GAAG;AACH;AACA;AACA,GAAG;AACH;AACA;AACA,GAAG;AACH;AACA;AACA,GAAG;AACH;AACA;AACA,GAAG;AACH;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,QAAQ;AACR;AACA;AACA;AACA,KAAK;AACL;AACA,GAAG;AACH;AACA;AACA;AACA,0CAA0C;AAC1C;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,GAAG;AACH;AACA;AACA;;AAEA;;;;;;;;AC9Ma;;AAEb,2CAA2C,gCAAgC,oCAAoC,oDAAoD,8DAA8D,iEAAiE,GAAG,kCAAkC;;AAEvU,iCAAiC,gBAAgB,sBAAsB,OAAO,uDAAuD,aAAa,uDAAuD,4CAA4C,KAAK,6CAA6C,6EAA6E,OAAO,iDAAiD,mFAAmF,OAAO;;AAEtgB,4CAA4C,kBAAkB,kCAAkC,oEAAoE,KAAK,OAAO,oBAAoB;;AAEpM,kDAAkD,0CAA0C;;AAE5F,4CAA4C,gBAAgB,kBAAkB,OAAO,2BAA2B,wDAAwD,gCAAgC,uDAAuD;;AAE/P,8DAA8D,sEAAsE,8DAA8D;;AAElM,eAAe,mBAAO,CAAC,KAAQ;AAC/B;;AAEA,gBAAgB,mBAAO,CAAC,KAAM;AAC9B;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kDAAkD;AAClD;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,0DAA0D;AAC1D;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA,MAAM;;AAEN,GAAG;AACH;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,QAAQ;AACR;AACA;AACA,QAAQ;AACR;AACA;AACA;;AAEA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA,MAAM;;AAEN,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,0CAA0C;AAC1C;;AAEA;AACA;AACA;AACA,2CAA2C;AAC3C,YAAY;AACZ;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA,MAAM;;AAEN,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,2CAA2C;AAC3C,YAAY;AACZ;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA,MAAM;;AAEN,GAAG;AACH;AACA;AACA,2CAA2C;AAC3C;AACA;AACA;AACA;AACA,OAAO;AACP;AACA,GAAG;;AAEH;AACA,CAAC;;;;;;;;ACjNY,CAAC;;AAEd;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,QAAQ;AACR;AACA;AACA;AACA;;AAEA;AACA,IAAI;AACJ;;;AAGA;AACA;AACA,IAAI;;;AAGJ;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,QAAQ;AACR;AACA;AACA,QAAQ;AACR;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA,GAAG;;AAEH;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wFAAwF;AACxF;;AAEA;AACA;AACA;AACA;AACA;;;;;;;;ACxGA;AACA;AACa;;AAEb,iCAAiC,8FAA2D;;AAE5F;AACA;AACA;AACA;AACA;;AAEA,wEAAwE,aAAa;AACrF;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,gCAAgC;AAChC,IAAI;AACJ;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;;;;;;;ACvGa;;AAEb,6EAA6E,MAAM,0BAA0B,0BAA0B,gBAAgB,eAAe,UAAU,iBAAiB,kBAAkB,OAAO;;AAE1N,iCAAiC,qBAAqB,mCAAmC,gDAAgD,gCAAgC,wBAAwB,0EAA0E,uBAAuB,yEAAyE,mBAAmB;;AAE9X,2CAA2C,gCAAgC,oCAAoC,oDAAoD,8DAA8D,iEAAiE,GAAG,kCAAkC;;AAEvU,iCAAiC,gBAAgB,sBAAsB,OAAO,uDAAuD,aAAa,uDAAuD,4CAA4C,KAAK,6CAA6C,6EAA6E,OAAO,iDAAiD,mFAAmF,OAAO;;AAEtgB,4CAA4C,kBAAkB,kCAAkC,oEAAoE,KAAK,OAAO,oBAAoB;;AAEpM,2BAA2B,kFAAqD;;AAEhF;AACA;;AAEA;AACA;AACA,IAAI,iGAAiG,uFAAuF;;AAE5L;AACA;AACA,GAAG,UAAU;AACb;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,UAAU;AACV;AACA,UAAU;AACV;AACA;AACA,QAAQ;AACR;AACA;AACA,KAAK;AACL;AACA;;AAEA;AACA;;AAEA;;;;;;;;AC/DA;AACA;AACa;;AAEb;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,qBAAqB,wCAAgC;AACrD;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH,+BAA+B,mBAAO,CAAC,IAAiB;AACxD;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,sBAAsB;;AAEtB;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA,yEAAyE,aAAa;AACtF;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL,GAAG;AACH;AACA;;AAEA;;;;;;;;AChGa;;AAEb,4BAA4B,oFAAsD;;AAElF;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA,IAAI;;;AAGJ;AACA;;AAEA;AACA;AACA;;;;;;;AC1BA,2CAAkC;;;;;;;;ACAlC,aAAa,mBAAO,CAAC,KAAQ;AAC7B;AACA;AACA;AACA,EAAE,qBAAqB;AACvB,EAAE;AACF,YAAY,2CAAqD;AACjE,EAAE,cAAc;AAChB,EAAE,gBAAgB;AAClB,EAAE,6CAAuD;AACzD,EAAE,2CAAmD;AACrD,EAAE,8CAAyD;AAC3D,EAAE,gDAA6D;AAC/D,EAAE,4CAAqE;AACvE,EAAE,6CAAgE;AAClE;;;;;;;;;ACfA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEa;;AAEb;;AAEA,aAAa,iCAA6B;AAC1C;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B;AAC7B;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,SAAqB;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,6BAA6B,sCAAsC,sCAAsC;AACzG;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B;AAC3B;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;;;;;;ACvSA;AACA;AACA,aAAa,mBAAO,CAAC,KAAQ;AAC7B;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,EAAE;AACF;AACA;AACA,EAAE,cAAc;AAChB;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AC/DA;AACA;AACA;;AAEA,qDAA0C","sources":["webpack://snyk/./node_modules/adm-zip/adm-zip.js","webpack://snyk/./node_modules/adm-zip/headers/entryHeader.js","webpack://snyk/./node_modules/adm-zip/headers/index.js","webpack://snyk/./node_modules/adm-zip/headers/mainHeader.js","webpack://snyk/./node_modules/adm-zip/methods/deflater.js","webpack://snyk/./node_modules/adm-zip/methods/index.js","webpack://snyk/./node_modules/adm-zip/methods/inflater.js","webpack://snyk/./node_modules/adm-zip/methods/zipcrypto.js","webpack://snyk/./node_modules/adm-zip/util/constants.js","webpack://snyk/./node_modules/adm-zip/util/errors.js","webpack://snyk/./node_modules/adm-zip/util/fattr.js","webpack://snyk/./node_modules/adm-zip/util/fileSystem.js","webpack://snyk/./node_modules/adm-zip/util/index.js","webpack://snyk/./node_modules/adm-zip/util/utils.js","webpack://snyk/./node_modules/adm-zip/zipEntry.js","webpack://snyk/./node_modules/adm-zip/zipFile.js","webpack://snyk/./node_modules/bl/BufferList.js","webpack://snyk/./node_modules/bl/bl.js","webpack://snyk/./node_modules/inherits/inherits.js","webpack://snyk/./node_modules/inherits/inherits_browser.js","webpack://snyk/./node_modules/readable-stream/errors.js","webpack://snyk/./node_modules/readable-stream/lib/_stream_duplex.js","webpack://snyk/./node_modules/readable-stream/lib/_stream_passthrough.js","webpack://snyk/./node_modules/readable-stream/lib/_stream_readable.js","webpack://snyk/./node_modules/readable-stream/lib/_stream_transform.js","webpack://snyk/./node_modules/readable-stream/lib/_stream_writable.js","webpack://snyk/./node_modules/readable-stream/lib/internal/streams/async_iterator.js","webpack://snyk/./node_modules/readable-stream/lib/internal/streams/buffer_list.js","webpack://snyk/./node_modules/readable-stream/lib/internal/streams/destroy.js","webpack://snyk/./node_modules/readable-stream/lib/internal/streams/end-of-stream.js","webpack://snyk/./node_modules/readable-stream/lib/internal/streams/from.js","webpack://snyk/./node_modules/readable-stream/lib/internal/streams/pipeline.js","webpack://snyk/./node_modules/readable-stream/lib/internal/streams/state.js","webpack://snyk/./node_modules/readable-stream/lib/internal/streams/stream.js","webpack://snyk/./node_modules/readable-stream/readable.js","webpack://snyk/./node_modules/string_decoder/lib/string_decoder.js","webpack://snyk/./node_modules/string_decoder/node_modules/safe-buffer/index.js","webpack://snyk/./node_modules/util-deprecate/node.js"],"sourcesContent":["const Utils = require(\"./util\");\nconst pth = require(\"path\");\nconst ZipEntry = require(\"./zipEntry\");\nconst ZipFile = require(\"./zipFile\");\n\nconst get_Bool = (val, def) => (typeof val === \"boolean\" ? val : def);\nconst get_Str = (val, def) => (typeof val === \"string\" ? val : def);\n\nconst defaultOptions = {\n    // option \"noSort\" : if true it disables files sorting\n    noSort: false,\n    // read entries during load (initial loading may be slower)\n    readEntries: false,\n    // default method is none\n    method: Utils.Constants.NONE,\n    // file system\n    fs: null\n};\n\nmodule.exports = function (/**String*/ input, /** object */ options) {\n    let inBuffer = null;\n\n    // create object based default options, allowing them to be overwritten\n    const opts = Object.assign(Object.create(null), defaultOptions);\n\n    // test input variable\n    if (input && \"object\" === typeof input) {\n        // if value is not buffer we accept it to be object with options\n        if (!(input instanceof Uint8Array)) {\n            Object.assign(opts, input);\n            input = opts.input ? opts.input : undefined;\n            if (opts.input) delete opts.input;\n        }\n\n        // if input is buffer\n        if (Buffer.isBuffer(input)) {\n            inBuffer = input;\n            opts.method = Utils.Constants.BUFFER;\n            input = undefined;\n        }\n    }\n\n    // assign options\n    Object.assign(opts, options);\n\n    // instanciate utils filesystem\n    const filetools = new Utils(opts);\n\n    // if input is file name we retrieve its content\n    if (input && \"string\" === typeof input) {\n        // load zip file\n        if (filetools.fs.existsSync(input)) {\n            opts.method = Utils.Constants.FILE;\n            opts.filename = input;\n            inBuffer = filetools.fs.readFileSync(input);\n        } else {\n            throw new Error(Utils.Errors.INVALID_FILENAME);\n        }\n    }\n\n    // create variable\n    const _zip = new ZipFile(inBuffer, opts);\n\n    const { canonical, sanitize } = Utils;\n\n    function getEntry(/**Object*/ entry) {\n        if (entry && _zip) {\n            var item;\n            // If entry was given as a file name\n            if (typeof entry === \"string\") item = _zip.getEntry(entry);\n            // if entry was given as a ZipEntry object\n            if (typeof entry === \"object\" && typeof entry.entryName !== \"undefined\" && typeof entry.header !== \"undefined\") item = _zip.getEntry(entry.entryName);\n\n            if (item) {\n                return item;\n            }\n        }\n        return null;\n    }\n\n    function fixPath(zipPath) {\n        const { join, normalize, sep } = pth.posix;\n        // convert windows file separators and normalize\n        return join(\".\", normalize(sep + zipPath.split(\"\\\\\").join(sep) + sep));\n    }\n\n    return {\n        /**\n         * Extracts the given entry from the archive and returns the content as a Buffer object\n         * @param entry ZipEntry object or String with the full path of the entry\n         *\n         * @return Buffer or Null in case of error\n         */\n        readFile: function (/**Object*/ entry, /*String, Buffer*/ pass) {\n            var item = getEntry(entry);\n            return (item && item.getData(pass)) || null;\n        },\n\n        /**\n         * Asynchronous readFile\n         * @param entry ZipEntry object or String with the full path of the entry\n         * @param callback\n         *\n         * @return Buffer or Null in case of error\n         */\n        readFileAsync: function (/**Object*/ entry, /**Function*/ callback) {\n            var item = getEntry(entry);\n            if (item) {\n                item.getDataAsync(callback);\n            } else {\n                callback(null, \"getEntry failed for:\" + entry);\n            }\n        },\n\n        /**\n         * Extracts the given entry from the archive and returns the content as plain text in the given encoding\n         * @param entry ZipEntry object or String with the full path of the entry\n         * @param encoding Optional. If no encoding is specified utf8 is used\n         *\n         * @return String\n         */\n        readAsText: function (/**Object*/ entry, /**String=*/ encoding) {\n            var item = getEntry(entry);\n            if (item) {\n                var data = item.getData();\n                if (data && data.length) {\n                    return data.toString(encoding || \"utf8\");\n                }\n            }\n            return \"\";\n        },\n\n        /**\n         * Asynchronous readAsText\n         * @param entry ZipEntry object or String with the full path of the entry\n         * @param callback\n         * @param encoding Optional. If no encoding is specified utf8 is used\n         *\n         * @return String\n         */\n        readAsTextAsync: function (/**Object*/ entry, /**Function*/ callback, /**String=*/ encoding) {\n            var item = getEntry(entry);\n            if (item) {\n                item.getDataAsync(function (data, err) {\n                    if (err) {\n                        callback(data, err);\n                        return;\n                    }\n\n                    if (data && data.length) {\n                        callback(data.toString(encoding || \"utf8\"));\n                    } else {\n                        callback(\"\");\n                    }\n                });\n            } else {\n                callback(\"\");\n            }\n        },\n\n        /**\n         * Remove the entry from the file or the entry and all it's nested directories and files if the given entry is a directory\n         *\n         * @param entry\n         */\n        deleteFile: function (/**Object*/ entry) {\n            // @TODO: test deleteFile\n            var item = getEntry(entry);\n            if (item) {\n                _zip.deleteEntry(item.entryName);\n            }\n        },\n\n        /**\n         * Adds a comment to the zip. The zip must be rewritten after adding the comment.\n         *\n         * @param comment\n         */\n        addZipComment: function (/**String*/ comment) {\n            // @TODO: test addZipComment\n            _zip.comment = comment;\n        },\n\n        /**\n         * Returns the zip comment\n         *\n         * @return String\n         */\n        getZipComment: function () {\n            return _zip.comment || \"\";\n        },\n\n        /**\n         * Adds a comment to a specified zipEntry. The zip must be rewritten after adding the comment\n         * The comment cannot exceed 65535 characters in length\n         *\n         * @param entry\n         * @param comment\n         */\n        addZipEntryComment: function (/**Object*/ entry, /**String*/ comment) {\n            var item = getEntry(entry);\n            if (item) {\n                item.comment = comment;\n            }\n        },\n\n        /**\n         * Returns the comment of the specified entry\n         *\n         * @param entry\n         * @return String\n         */\n        getZipEntryComment: function (/**Object*/ entry) {\n            var item = getEntry(entry);\n            if (item) {\n                return item.comment || \"\";\n            }\n            return \"\";\n        },\n\n        /**\n         * Updates the content of an existing entry inside the archive. The zip must be rewritten after updating the content\n         *\n         * @param entry\n         * @param content\n         */\n        updateFile: function (/**Object*/ entry, /**Buffer*/ content) {\n            var item = getEntry(entry);\n            if (item) {\n                item.setData(content);\n            }\n        },\n\n        /**\n         * Adds a file from the disk to the archive\n         *\n         * @param localPath File to add to zip\n         * @param zipPath Optional path inside the zip\n         * @param zipName Optional name for the file\n         */\n        addLocalFile: function (/**String*/ localPath, /**String=*/ zipPath, /**String=*/ zipName, /**String*/ comment) {\n            if (filetools.fs.existsSync(localPath)) {\n                // fix ZipPath\n                zipPath = zipPath ? fixPath(zipPath) : \"\";\n\n                // p - local file name\n                var p = localPath.split(\"\\\\\").join(\"/\").split(\"/\").pop();\n\n                // add file name into zippath\n                zipPath += zipName ? zipName : p;\n\n                // read file attributes\n                const _attr = filetools.fs.statSync(localPath);\n\n                // add file into zip file\n                this.addFile(zipPath, filetools.fs.readFileSync(localPath), comment, _attr);\n            } else {\n                throw new Error(Utils.Errors.FILE_NOT_FOUND.replace(\"%s\", localPath));\n            }\n        },\n\n        /**\n         * Adds a local directory and all its nested files and directories to the archive\n         *\n         * @param localPath\n         * @param zipPath optional path inside zip\n         * @param filter optional RegExp or Function if files match will\n         *               be included.\n         */\n        addLocalFolder: function (/**String*/ localPath, /**String=*/ zipPath, /**=RegExp|Function*/ filter) {\n            // Prepare filter\n            if (filter instanceof RegExp) {\n                // if filter is RegExp wrap it\n                filter = (function (rx) {\n                    return function (filename) {\n                        return rx.test(filename);\n                    };\n                })(filter);\n            } else if (\"function\" !== typeof filter) {\n                // if filter is not function we will replace it\n                filter = function () {\n                    return true;\n                };\n            }\n\n            // fix ZipPath\n            zipPath = zipPath ? fixPath(zipPath) : \"\";\n\n            // normalize the path first\n            localPath = pth.normalize(localPath);\n\n            if (filetools.fs.existsSync(localPath)) {\n                const items = filetools.findFiles(localPath);\n                const self = this;\n\n                if (items.length) {\n                    items.forEach(function (filepath) {\n                        var p = pth.relative(localPath, filepath).split(\"\\\\\").join(\"/\"); //windows fix\n                        if (filter(p)) {\n                            var stats = filetools.fs.statSync(filepath);\n                            if (stats.isFile()) {\n                                self.addFile(zipPath + p, filetools.fs.readFileSync(filepath), \"\", stats);\n                            } else {\n                                self.addFile(zipPath + p + \"/\", Buffer.alloc(0), \"\", stats);\n                            }\n                        }\n                    });\n                }\n            } else {\n                throw new Error(Utils.Errors.FILE_NOT_FOUND.replace(\"%s\", localPath));\n            }\n        },\n\n        /**\n         * Asynchronous addLocalFile\n         * @param localPath\n         * @param callback\n         * @param zipPath optional path inside zip\n         * @param filter optional RegExp or Function if files match will\n         *               be included.\n         */\n        addLocalFolderAsync: function (/*String*/ localPath, /*Function*/ callback, /*String*/ zipPath, /*RegExp|Function*/ filter) {\n            if (filter instanceof RegExp) {\n                filter = (function (rx) {\n                    return function (filename) {\n                        return rx.test(filename);\n                    };\n                })(filter);\n            } else if (\"function\" !== typeof filter) {\n                filter = function () {\n                    return true;\n                };\n            }\n\n            // fix ZipPath\n            zipPath = zipPath ? fixPath(zipPath) : \"\";\n\n            // normalize the path first\n            localPath = pth.normalize(localPath);\n\n            var self = this;\n            filetools.fs.open(localPath, \"r\", function (err) {\n                if (err && err.code === \"ENOENT\") {\n                    callback(undefined, Utils.Errors.FILE_NOT_FOUND.replace(\"%s\", localPath));\n                } else if (err) {\n                    callback(undefined, err);\n                } else {\n                    var items = filetools.findFiles(localPath);\n                    var i = -1;\n\n                    var next = function () {\n                        i += 1;\n                        if (i < items.length) {\n                            var filepath = items[i];\n                            var p = pth.relative(localPath, filepath).split(\"\\\\\").join(\"/\"); //windows fix\n                            p = p\n                                .normalize(\"NFD\")\n                                .replace(/[\\u0300-\\u036f]/g, \"\")\n                                .replace(/[^\\x20-\\x7E]/g, \"\"); // accent fix\n                            if (filter(p)) {\n                                filetools.fs.stat(filepath, function (er0, stats) {\n                                    if (er0) callback(undefined, er0);\n                                    if (stats.isFile()) {\n                                        filetools.fs.readFile(filepath, function (er1, data) {\n                                            if (er1) {\n                                                callback(undefined, er1);\n                                            } else {\n                                                self.addFile(zipPath + p, data, \"\", stats);\n                                                next();\n                                            }\n                                        });\n                                    } else {\n                                        self.addFile(zipPath + p + \"/\", Buffer.alloc(0), \"\", stats);\n                                        next();\n                                    }\n                                });\n                            } else {\n                                next();\n                            }\n                        } else {\n                            callback(true, undefined);\n                        }\n                    };\n\n                    next();\n                }\n            });\n        },\n\n        /**\n         *\n         * @param {string} localPath - path where files will be extracted\n         * @param {object} props - optional properties\n         * @param {string} props.zipPath - optional path inside zip\n         * @param {regexp, function} props.filter - RegExp or Function if files match will be included.\n         */\n        addLocalFolderPromise: function (/*String*/ localPath, /* object */ props) {\n            return new Promise((resolve, reject) => {\n                const { filter, zipPath } = Object.assign({}, props);\n                this.addLocalFolderAsync(\n                    localPath,\n                    (done, err) => {\n                        if (err) reject(err);\n                        if (done) resolve(this);\n                    },\n                    zipPath,\n                    filter\n                );\n            });\n        },\n\n        /**\n         * Allows you to create a entry (file or directory) in the zip file.\n         * If you want to create a directory the entryName must end in / and a null buffer should be provided.\n         * Comment and attributes are optional\n         *\n         * @param {string} entryName\n         * @param {Buffer | string} content - file content as buffer or utf8 coded string\n         * @param {string} comment - file comment\n         * @param {number | object} attr - number as unix file permissions, object as filesystem Stats object\n         */\n        addFile: function (/**String*/ entryName, /**Buffer*/ content, /**String*/ comment, /**Number*/ attr) {\n            let entry = getEntry(entryName);\n            const update = entry != null;\n\n            // prepare new entry\n            if (!update) {\n                entry = new ZipEntry();\n                entry.entryName = entryName;\n            }\n            entry.comment = comment || \"\";\n\n            const isStat = \"object\" === typeof attr && attr instanceof filetools.fs.Stats;\n\n            // last modification time from file stats\n            if (isStat) {\n                entry.header.time = attr.mtime;\n            }\n\n            // Set file attribute\n            var fileattr = entry.isDirectory ? 0x10 : 0; // (MS-DOS directory flag)\n\n            // extended attributes field for Unix\n            if (!Utils.isWin) {\n                // set file type either S_IFDIR / S_IFREG\n                let unix = entry.isDirectory ? 0x4000 : 0x8000;\n\n                if (isStat) {\n                    // File attributes from file stats\n                    unix |= 0xfff & attr.mode;\n                } else if (\"number\" === typeof attr) {\n                    // attr from given attr values\n                    unix |= 0xfff & attr;\n                } else {\n                    // Default values:\n                    unix |= entry.isDirectory ? 0o755 : 0o644; // permissions (drwxr-xr-x) or (-r-wr--r--)\n                }\n\n                fileattr = (fileattr | (unix << 16)) >>> 0; // add attributes\n            }\n\n            entry.attr = fileattr;\n\n            entry.setData(content);\n            if (!update) _zip.setEntry(entry);\n        },\n\n        /**\n         * Returns an array of ZipEntry objects representing the files and folders inside the archive\n         *\n         * @return Array\n         */\n        getEntries: function () {\n            return _zip ? _zip.entries : [];\n        },\n\n        /**\n         * Returns a ZipEntry object representing the file or folder specified by ``name``.\n         *\n         * @param name\n         * @return ZipEntry\n         */\n        getEntry: function (/**String*/ name) {\n            return getEntry(name);\n        },\n\n        getEntryCount: function () {\n            return _zip.getEntryCount();\n        },\n\n        forEach: function (callback) {\n            return _zip.forEach(callback);\n        },\n\n        /**\n         * Extracts the given entry to the given targetPath\n         * If the entry is a directory inside the archive, the entire directory and it's subdirectories will be extracted\n         *\n         * @param entry ZipEntry object or String with the full path of the entry\n         * @param targetPath Target folder where to write the file\n         * @param maintainEntryPath If maintainEntryPath is true and the entry is inside a folder, the entry folder\n         *                          will be created in targetPath as well. Default is TRUE\n         * @param overwrite If the file already exists at the target path, the file will be overwriten if this is true.\n         *                  Default is FALSE\n         * @param keepOriginalPermission The file will be set as the permission from the entry if this is true.\n         *                  Default is FALSE\n         * @param outFileName String If set will override the filename of the extracted file (Only works if the entry is a file)\n         *\n         * @return Boolean\n         */\n        extractEntryTo: function (\n            /**Object*/ entry,\n            /**String*/ targetPath,\n            /**Boolean*/ maintainEntryPath,\n            /**Boolean*/ overwrite,\n            /**Boolean*/ keepOriginalPermission,\n            /**String**/ outFileName\n        ) {\n            overwrite = get_Bool(overwrite, false);\n            keepOriginalPermission = get_Bool(keepOriginalPermission, false);\n            maintainEntryPath = get_Bool(maintainEntryPath, true);\n            outFileName = get_Str(outFileName, get_Str(keepOriginalPermission, undefined));\n\n            var item = getEntry(entry);\n            if (!item) {\n                throw new Error(Utils.Errors.NO_ENTRY);\n            }\n\n            var entryName = canonical(item.entryName);\n\n            var target = sanitize(targetPath, outFileName && !item.isDirectory ? outFileName : maintainEntryPath ? entryName : pth.basename(entryName));\n\n            if (item.isDirectory) {\n                var children = _zip.getEntryChildren(item);\n                children.forEach(function (child) {\n                    if (child.isDirectory) return;\n                    var content = child.getData();\n                    if (!content) {\n                        throw new Error(Utils.Errors.CANT_EXTRACT_FILE);\n                    }\n                    var name = canonical(child.entryName);\n                    var childName = sanitize(targetPath, maintainEntryPath ? name : pth.basename(name));\n                    // The reverse operation for attr depend on method addFile()\n                    const fileAttr = keepOriginalPermission ? child.header.fileAttr : undefined;\n                    filetools.writeFileTo(childName, content, overwrite, fileAttr);\n                });\n                return true;\n            }\n\n            var content = item.getData();\n            if (!content) throw new Error(Utils.Errors.CANT_EXTRACT_FILE);\n\n            if (filetools.fs.existsSync(target) && !overwrite) {\n                throw new Error(Utils.Errors.CANT_OVERRIDE);\n            }\n            // The reverse operation for attr depend on method addFile()\n            const fileAttr = keepOriginalPermission ? entry.header.fileAttr : undefined;\n            filetools.writeFileTo(target, content, overwrite, fileAttr);\n\n            return true;\n        },\n\n        /**\n         * Test the archive\n         *\n         */\n        test: function (pass) {\n            if (!_zip) {\n                return false;\n            }\n\n            for (var entry in _zip.entries) {\n                try {\n                    if (entry.isDirectory) {\n                        continue;\n                    }\n                    var content = _zip.entries[entry].getData(pass);\n                    if (!content) {\n                        return false;\n                    }\n                } catch (err) {\n                    return false;\n                }\n            }\n            return true;\n        },\n\n        /**\n         * Extracts the entire archive to the given location\n         *\n         * @param targetPath Target location\n         * @param overwrite If the file already exists at the target path, the file will be overwriten if this is true.\n         *                  Default is FALSE\n         * @param keepOriginalPermission The file will be set as the permission from the entry if this is true.\n         *                  Default is FALSE\n         */\n        extractAllTo: function (/**String*/ targetPath, /**Boolean*/ overwrite, /**Boolean*/ keepOriginalPermission, /*String, Buffer*/ pass) {\n            overwrite = get_Bool(overwrite, false);\n            pass = get_Str(keepOriginalPermission, pass);\n            keepOriginalPermission = get_Bool(keepOriginalPermission, false);\n            if (!_zip) {\n                throw new Error(Utils.Errors.NO_ZIP);\n            }\n            _zip.entries.forEach(function (entry) {\n                var entryName = sanitize(targetPath, canonical(entry.entryName.toString()));\n                if (entry.isDirectory) {\n                    filetools.makeDir(entryName);\n                    return;\n                }\n                var content = entry.getData(pass);\n                if (!content) {\n                    throw new Error(Utils.Errors.CANT_EXTRACT_FILE);\n                }\n                // The reverse operation for attr depend on method addFile()\n                const fileAttr = keepOriginalPermission ? entry.header.fileAttr : undefined;\n                filetools.writeFileTo(entryName, content, overwrite, fileAttr);\n                try {\n                    filetools.fs.utimesSync(entryName, entry.header.time, entry.header.time);\n                } catch (err) {\n                    throw new Error(Utils.Errors.CANT_EXTRACT_FILE);\n                }\n            });\n        },\n\n        /**\n         * Asynchronous extractAllTo\n         *\n         * @param targetPath Target location\n         * @param overwrite If the file already exists at the target path, the file will be overwriten if this is true.\n         *                  Default is FALSE\n         * @param keepOriginalPermission The file will be set as the permission from the entry if this is true.\n         *                  Default is FALSE\n         * @param callback The callback will be executed when all entries are extracted successfully or any error is thrown.\n         */\n        extractAllToAsync: function (/**String*/ targetPath, /**Boolean*/ overwrite, /**Boolean*/ keepOriginalPermission, /**Function*/ callback) {\n            if (!callback) {\n                callback = function () {};\n            }\n            overwrite = get_Bool(overwrite, false);\n            if (typeof keepOriginalPermission === \"function\" && !callback) callback = keepOriginalPermission;\n            keepOriginalPermission = get_Bool(keepOriginalPermission, false);\n            if (!_zip) {\n                callback(new Error(Utils.Errors.NO_ZIP));\n                return;\n            }\n\n            targetPath = pth.resolve(targetPath);\n            // convert entryName to\n            const getPath = (entry) => sanitize(targetPath, pth.normalize(canonical(entry.entryName.toString())));\n            const getError = (msg, file) => new Error(msg + ': \"' + file + '\"');\n\n            // separate directories from files\n            const dirEntries = [];\n            const fileEntries = new Set();\n            _zip.entries.forEach((e) => {\n                if (e.isDirectory) {\n                    dirEntries.push(e);\n                } else {\n                    fileEntries.add(e);\n                }\n            });\n\n            // Create directory entries first synchronously\n            // this prevents race condition and assures folders are there before writing files\n            for (const entry of dirEntries) {\n                const dirPath = getPath(entry);\n                // The reverse operation for attr depend on method addFile()\n                const dirAttr = keepOriginalPermission ? entry.header.fileAttr : undefined;\n                try {\n                    filetools.makeDir(dirPath);\n                    if (dirAttr) filetools.fs.chmodSync(dirPath, dirAttr);\n                    // in unix timestamp will change if files are later added to folder, but still\n                    filetools.fs.utimesSync(dirPath, entry.header.time, entry.header.time);\n                } catch (er) {\n                    callback(getError(\"Unable to create folder\", dirPath));\n                }\n            }\n\n            // callback wrapper, for some house keeping\n            const done = () => {\n                if (fileEntries.size === 0) {\n                    callback();\n                }\n            };\n\n            // Extract file entries asynchronously\n            for (const entry of fileEntries.values()) {\n                const entryName = pth.normalize(canonical(entry.entryName.toString()));\n                const filePath = sanitize(targetPath, entryName);\n                entry.getDataAsync(function (content, err_1) {\n                    if (err_1) {\n                        callback(new Error(err_1));\n                        return;\n                    }\n                    if (!content) {\n                        callback(new Error(Utils.Errors.CANT_EXTRACT_FILE));\n                    } else {\n                        // The reverse operation for attr depend on method addFile()\n                        const fileAttr = keepOriginalPermission ? entry.header.fileAttr : undefined;\n                        filetools.writeFileToAsync(filePath, content, overwrite, fileAttr, function (succ) {\n                            if (!succ) {\n                                callback(getError(\"Unable to write file\", filePath));\n                                return;\n                            }\n                            filetools.fs.utimes(filePath, entry.header.time, entry.header.time, function (err_2) {\n                                if (err_2) {\n                                    callback(getError(\"Unable to set times\", filePath));\n                                    return;\n                                }\n                                fileEntries.delete(entry);\n                                // call the callback if it was last entry\n                                done();\n                            });\n                        });\n                    }\n                });\n            }\n            // call the callback if fileEntries was empty\n            done();\n        },\n\n        /**\n         * Writes the newly created zip file to disk at the specified location or if a zip was opened and no ``targetFileName`` is provided, it will overwrite the opened zip\n         *\n         * @param targetFileName\n         * @param callback\n         */\n        writeZip: function (/**String*/ targetFileName, /**Function*/ callback) {\n            if (arguments.length === 1) {\n                if (typeof targetFileName === \"function\") {\n                    callback = targetFileName;\n                    targetFileName = \"\";\n                }\n            }\n\n            if (!targetFileName && opts.filename) {\n                targetFileName = opts.filename;\n            }\n            if (!targetFileName) return;\n\n            var zipData = _zip.compressToBuffer();\n            if (zipData) {\n                var ok = filetools.writeFileTo(targetFileName, zipData, true);\n                if (typeof callback === \"function\") callback(!ok ? new Error(\"failed\") : null, \"\");\n            }\n        },\n\n        writeZipPromise: function (/**String*/ targetFileName, /* object */ props) {\n            const { overwrite, perm } = Object.assign({ overwrite: true }, props);\n\n            return new Promise((resolve, reject) => {\n                // find file name\n                if (!targetFileName && opts.filename) targetFileName = opts.filename;\n                if (!targetFileName) reject(\"ADM-ZIP: ZIP File Name Missing\");\n\n                this.toBufferPromise().then((zipData) => {\n                    const ret = (done) => (done ? resolve(done) : reject(\"ADM-ZIP: Wasn't able to write zip file\"));\n                    filetools.writeFileToAsync(targetFileName, zipData, overwrite, perm, ret);\n                }, reject);\n            });\n        },\n\n        toBufferPromise: function () {\n            return new Promise((resolve, reject) => {\n                _zip.toAsyncBuffer(resolve, reject);\n            });\n        },\n\n        /**\n         * Returns the content of the entire zip file as a Buffer object\n         *\n         * @return Buffer\n         */\n        toBuffer: function (/**Function=*/ onSuccess, /**Function=*/ onFail, /**Function=*/ onItemStart, /**Function=*/ onItemEnd) {\n            this.valueOf = 2;\n            if (typeof onSuccess === \"function\") {\n                _zip.toAsyncBuffer(onSuccess, onFail, onItemStart, onItemEnd);\n                return null;\n            }\n            return _zip.compressToBuffer();\n        }\n    };\n};\n","var Utils = require(\"../util\"),\n    Constants = Utils.Constants;\n\n/* The central directory file header */\nmodule.exports = function () {\n    var _verMade = 20, // v2.0\n        _version = 10, // v1.0\n        _flags = 0,\n        _method = 0,\n        _time = 0,\n        _crc = 0,\n        _compressedSize = 0,\n        _size = 0,\n        _fnameLen = 0,\n        _extraLen = 0,\n        _comLen = 0,\n        _diskStart = 0,\n        _inattr = 0,\n        _attr = 0,\n        _offset = 0;\n\n    _verMade |= Utils.isWin ? 0x0a00 : 0x0300;\n\n    // Set EFS flag since filename and comment fields are all by default encoded using UTF-8.\n    // Without it file names may be corrupted for other apps when file names use unicode chars\n    _flags |= Constants.FLG_EFS;\n\n    var _dataHeader = {};\n\n    function setTime(val) {\n        val = new Date(val);\n        _time =\n            (((val.getFullYear() - 1980) & 0x7f) << 25) | // b09-16 years from 1980\n            ((val.getMonth() + 1) << 21) | // b05-08 month\n            (val.getDate() << 16) | // b00-04 hour\n            // 2 bytes time\n            (val.getHours() << 11) | // b11-15 hour\n            (val.getMinutes() << 5) | // b05-10 minute\n            (val.getSeconds() >> 1); // b00-04 seconds divided by 2\n    }\n\n    setTime(+new Date());\n\n    return {\n        get made() {\n            return _verMade;\n        },\n        set made(val) {\n            _verMade = val;\n        },\n\n        get version() {\n            return _version;\n        },\n        set version(val) {\n            _version = val;\n        },\n\n        get flags() {\n            return _flags;\n        },\n        set flags(val) {\n            _flags = val;\n        },\n\n        get method() {\n            return _method;\n        },\n        set method(val) {\n            switch (val) {\n                case Constants.STORED:\n                    this.version = 10;\n                case Constants.DEFLATED:\n                default:\n                    this.version = 20;\n            }\n            _method = val;\n        },\n\n        get time() {\n            return new Date(((_time >> 25) & 0x7f) + 1980, ((_time >> 21) & 0x0f) - 1, (_time >> 16) & 0x1f, (_time >> 11) & 0x1f, (_time >> 5) & 0x3f, (_time & 0x1f) << 1);\n        },\n        set time(val) {\n            setTime(val);\n        },\n\n        get crc() {\n            return _crc;\n        },\n        set crc(val) {\n            _crc = Math.max(0, val) >>> 0;\n        },\n\n        get compressedSize() {\n            return _compressedSize;\n        },\n        set compressedSize(val) {\n            _compressedSize = Math.max(0, val) >>> 0;\n        },\n\n        get size() {\n            return _size;\n        },\n        set size(val) {\n            _size = Math.max(0, val) >>> 0;\n        },\n\n        get fileNameLength() {\n            return _fnameLen;\n        },\n        set fileNameLength(val) {\n            _fnameLen = val;\n        },\n\n        get extraLength() {\n            return _extraLen;\n        },\n        set extraLength(val) {\n            _extraLen = val;\n        },\n\n        get commentLength() {\n            return _comLen;\n        },\n        set commentLength(val) {\n            _comLen = val;\n        },\n\n        get diskNumStart() {\n            return _diskStart;\n        },\n        set diskNumStart(val) {\n            _diskStart = Math.max(0, val) >>> 0;\n        },\n\n        get inAttr() {\n            return _inattr;\n        },\n        set inAttr(val) {\n            _inattr = Math.max(0, val) >>> 0;\n        },\n\n        get attr() {\n            return _attr;\n        },\n        set attr(val) {\n            _attr = Math.max(0, val) >>> 0;\n        },\n\n        // get Unix file permissions\n        get fileAttr() {\n            return _attr ? (((_attr >>> 0) | 0) >> 16) & 0xfff : 0;\n        },\n\n        get offset() {\n            return _offset;\n        },\n        set offset(val) {\n            _offset = Math.max(0, val) >>> 0;\n        },\n\n        get encripted() {\n            return (_flags & 1) === 1;\n        },\n\n        get entryHeaderSize() {\n            return Constants.CENHDR + _fnameLen + _extraLen + _comLen;\n        },\n\n        get realDataOffset() {\n            return _offset + Constants.LOCHDR + _dataHeader.fnameLen + _dataHeader.extraLen;\n        },\n\n        get dataHeader() {\n            return _dataHeader;\n        },\n\n        loadDataHeaderFromBinary: function (/*Buffer*/ input) {\n            var data = input.slice(_offset, _offset + Constants.LOCHDR);\n            // 30 bytes and should start with \"PK\\003\\004\"\n            if (data.readUInt32LE(0) !== Constants.LOCSIG) {\n                throw new Error(Utils.Errors.INVALID_LOC);\n            }\n            _dataHeader = {\n                // version needed to extract\n                version: data.readUInt16LE(Constants.LOCVER),\n                // general purpose bit flag\n                flags: data.readUInt16LE(Constants.LOCFLG),\n                // compression method\n                method: data.readUInt16LE(Constants.LOCHOW),\n                // modification time (2 bytes time, 2 bytes date)\n                time: data.readUInt32LE(Constants.LOCTIM),\n                // uncompressed file crc-32 value\n                crc: data.readUInt32LE(Constants.LOCCRC),\n                // compressed size\n                compressedSize: data.readUInt32LE(Constants.LOCSIZ),\n                // uncompressed size\n                size: data.readUInt32LE(Constants.LOCLEN),\n                // filename length\n                fnameLen: data.readUInt16LE(Constants.LOCNAM),\n                // extra field length\n                extraLen: data.readUInt16LE(Constants.LOCEXT)\n            };\n        },\n\n        loadFromBinary: function (/*Buffer*/ data) {\n            // data should be 46 bytes and start with \"PK 01 02\"\n            if (data.length !== Constants.CENHDR || data.readUInt32LE(0) !== Constants.CENSIG) {\n                throw new Error(Utils.Errors.INVALID_CEN);\n            }\n            // version made by\n            _verMade = data.readUInt16LE(Constants.CENVEM);\n            // version needed to extract\n            _version = data.readUInt16LE(Constants.CENVER);\n            // encrypt, decrypt flags\n            _flags = data.readUInt16LE(Constants.CENFLG);\n            // compression method\n            _method = data.readUInt16LE(Constants.CENHOW);\n            // modification time (2 bytes time, 2 bytes date)\n            _time = data.readUInt32LE(Constants.CENTIM);\n            // uncompressed file crc-32 value\n            _crc = data.readUInt32LE(Constants.CENCRC);\n            // compressed size\n            _compressedSize = data.readUInt32LE(Constants.CENSIZ);\n            // uncompressed size\n            _size = data.readUInt32LE(Constants.CENLEN);\n            // filename length\n            _fnameLen = data.readUInt16LE(Constants.CENNAM);\n            // extra field length\n            _extraLen = data.readUInt16LE(Constants.CENEXT);\n            // file comment length\n            _comLen = data.readUInt16LE(Constants.CENCOM);\n            // volume number start\n            _diskStart = data.readUInt16LE(Constants.CENDSK);\n            // internal file attributes\n            _inattr = data.readUInt16LE(Constants.CENATT);\n            // external file attributes\n            _attr = data.readUInt32LE(Constants.CENATX);\n            // LOC header offset\n            _offset = data.readUInt32LE(Constants.CENOFF);\n        },\n\n        dataHeaderToBinary: function () {\n            // LOC header size (30 bytes)\n            var data = Buffer.alloc(Constants.LOCHDR);\n            // \"PK\\003\\004\"\n            data.writeUInt32LE(Constants.LOCSIG, 0);\n            // version needed to extract\n            data.writeUInt16LE(_version, Constants.LOCVER);\n            // general purpose bit flag\n            data.writeUInt16LE(_flags, Constants.LOCFLG);\n            // compression method\n            data.writeUInt16LE(_method, Constants.LOCHOW);\n            // modification time (2 bytes time, 2 bytes date)\n            data.writeUInt32LE(_time, Constants.LOCTIM);\n            // uncompressed file crc-32 value\n            data.writeUInt32LE(_crc, Constants.LOCCRC);\n            // compressed size\n            data.writeUInt32LE(_compressedSize, Constants.LOCSIZ);\n            // uncompressed size\n            data.writeUInt32LE(_size, Constants.LOCLEN);\n            // filename length\n            data.writeUInt16LE(_fnameLen, Constants.LOCNAM);\n            // extra field length\n            data.writeUInt16LE(_extraLen, Constants.LOCEXT);\n            return data;\n        },\n\n        entryHeaderToBinary: function () {\n            // CEN header size (46 bytes)\n            var data = Buffer.alloc(Constants.CENHDR + _fnameLen + _extraLen + _comLen);\n            // \"PK\\001\\002\"\n            data.writeUInt32LE(Constants.CENSIG, 0);\n            // version made by\n            data.writeUInt16LE(_verMade, Constants.CENVEM);\n            // version needed to extract\n            data.writeUInt16LE(_version, Constants.CENVER);\n            // encrypt, decrypt flags\n            data.writeUInt16LE(_flags, Constants.CENFLG);\n            // compression method\n            data.writeUInt16LE(_method, Constants.CENHOW);\n            // modification time (2 bytes time, 2 bytes date)\n            data.writeUInt32LE(_time, Constants.CENTIM);\n            // uncompressed file crc-32 value\n            data.writeUInt32LE(_crc, Constants.CENCRC);\n            // compressed size\n            data.writeUInt32LE(_compressedSize, Constants.CENSIZ);\n            // uncompressed size\n            data.writeUInt32LE(_size, Constants.CENLEN);\n            // filename length\n            data.writeUInt16LE(_fnameLen, Constants.CENNAM);\n            // extra field length\n            data.writeUInt16LE(_extraLen, Constants.CENEXT);\n            // file comment length\n            data.writeUInt16LE(_comLen, Constants.CENCOM);\n            // volume number start\n            data.writeUInt16LE(_diskStart, Constants.CENDSK);\n            // internal file attributes\n            data.writeUInt16LE(_inattr, Constants.CENATT);\n            // external file attributes\n            data.writeUInt32LE(_attr, Constants.CENATX);\n            // LOC header offset\n            data.writeUInt32LE(_offset, Constants.CENOFF);\n            // fill all with\n            data.fill(0x00, Constants.CENHDR);\n            return data;\n        },\n\n        toJSON: function () {\n            const bytes = function (nr) {\n                return nr + \" bytes\";\n            };\n\n            return {\n                made: _verMade,\n                version: _version,\n                flags: _flags,\n                method: Utils.methodToString(_method),\n                time: this.time,\n                crc: \"0x\" + _crc.toString(16).toUpperCase(),\n                compressedSize: bytes(_compressedSize),\n                size: bytes(_size),\n                fileNameLength: bytes(_fnameLen),\n                extraLength: bytes(_extraLen),\n                commentLength: bytes(_comLen),\n                diskNumStart: _diskStart,\n                inAttr: _inattr,\n                attr: _attr,\n                offset: _offset,\n                entryHeaderSize: bytes(Constants.CENHDR + _fnameLen + _extraLen + _comLen)\n            };\n        },\n\n        toString: function () {\n            return JSON.stringify(this.toJSON(), null, \"\\t\");\n        }\n    };\n};\n","exports.EntryHeader = require(\"./entryHeader\");\nexports.MainHeader = require(\"./mainHeader\");\n","var Utils = require(\"../util\"),\n    Constants = Utils.Constants;\n\n/* The entries in the end of central directory */\nmodule.exports = function () {\n    var _volumeEntries = 0,\n        _totalEntries = 0,\n        _size = 0,\n        _offset = 0,\n        _commentLength = 0;\n\n    return {\n        get diskEntries() {\n            return _volumeEntries;\n        },\n        set diskEntries(/*Number*/ val) {\n            _volumeEntries = _totalEntries = val;\n        },\n\n        get totalEntries() {\n            return _totalEntries;\n        },\n        set totalEntries(/*Number*/ val) {\n            _totalEntries = _volumeEntries = val;\n        },\n\n        get size() {\n            return _size;\n        },\n        set size(/*Number*/ val) {\n            _size = val;\n        },\n\n        get offset() {\n            return _offset;\n        },\n        set offset(/*Number*/ val) {\n            _offset = val;\n        },\n\n        get commentLength() {\n            return _commentLength;\n        },\n        set commentLength(/*Number*/ val) {\n            _commentLength = val;\n        },\n\n        get mainHeaderSize() {\n            return Constants.ENDHDR + _commentLength;\n        },\n\n        loadFromBinary: function (/*Buffer*/ data) {\n            // data should be 22 bytes and start with \"PK 05 06\"\n            // or be 56+ bytes and start with \"PK 06 06\" for Zip64\n            if (\n                (data.length !== Constants.ENDHDR || data.readUInt32LE(0) !== Constants.ENDSIG) &&\n                (data.length < Constants.ZIP64HDR || data.readUInt32LE(0) !== Constants.ZIP64SIG)\n            ) {\n                throw new Error(Utils.Errors.INVALID_END);\n            }\n\n            if (data.readUInt32LE(0) === Constants.ENDSIG) {\n                // number of entries on this volume\n                _volumeEntries = data.readUInt16LE(Constants.ENDSUB);\n                // total number of entries\n                _totalEntries = data.readUInt16LE(Constants.ENDTOT);\n                // central directory size in bytes\n                _size = data.readUInt32LE(Constants.ENDSIZ);\n                // offset of first CEN header\n                _offset = data.readUInt32LE(Constants.ENDOFF);\n                // zip file comment length\n                _commentLength = data.readUInt16LE(Constants.ENDCOM);\n            } else {\n                // number of entries on this volume\n                _volumeEntries = Utils.readBigUInt64LE(data, Constants.ZIP64SUB);\n                // total number of entries\n                _totalEntries = Utils.readBigUInt64LE(data, Constants.ZIP64TOT);\n                // central directory size in bytes\n                _size = Utils.readBigUInt64LE(data, Constants.ZIP64SIZ);\n                // offset of first CEN header\n                _offset = Utils.readBigUInt64LE(data, Constants.ZIP64OFF);\n\n                _commentLength = 0;\n            }\n        },\n\n        toBinary: function () {\n            var b = Buffer.alloc(Constants.ENDHDR + _commentLength);\n            // \"PK 05 06\" signature\n            b.writeUInt32LE(Constants.ENDSIG, 0);\n            b.writeUInt32LE(0, 4);\n            // number of entries on this volume\n            b.writeUInt16LE(_volumeEntries, Constants.ENDSUB);\n            // total number of entries\n            b.writeUInt16LE(_totalEntries, Constants.ENDTOT);\n            // central directory size in bytes\n            b.writeUInt32LE(_size, Constants.ENDSIZ);\n            // offset of first CEN header\n            b.writeUInt32LE(_offset, Constants.ENDOFF);\n            // zip file comment length\n            b.writeUInt16LE(_commentLength, Constants.ENDCOM);\n            // fill comment memory with spaces so no garbage is left there\n            b.fill(\" \", Constants.ENDHDR);\n\n            return b;\n        },\n\n        toJSON: function () {\n            // creates 0x0000 style output\n            const offset = function (nr, len) {\n                let offs = nr.toString(16).toUpperCase();\n                while (offs.length < len) offs = \"0\" + offs;\n                return \"0x\" + offs;\n            };\n\n            return {\n                diskEntries: _volumeEntries,\n                totalEntries: _totalEntries,\n                size: _size + \" bytes\",\n                offset: offset(_offset, 4),\n                commentLength: _commentLength\n            };\n        },\n\n        toString: function () {\n            return JSON.stringify(this.toJSON(), null, \"\\t\");\n        }\n    };\n};\n","module.exports = function (/*Buffer*/ inbuf) {\n    var zlib = require(\"zlib\");\n\n    var opts = { chunkSize: (parseInt(inbuf.length / 1024) + 1) * 1024 };\n\n    return {\n        deflate: function () {\n            return zlib.deflateRawSync(inbuf, opts);\n        },\n\n        deflateAsync: function (/*Function*/ callback) {\n            var tmp = zlib.createDeflateRaw(opts),\n                parts = [],\n                total = 0;\n            tmp.on(\"data\", function (data) {\n                parts.push(data);\n                total += data.length;\n            });\n            tmp.on(\"end\", function () {\n                var buf = Buffer.alloc(total),\n                    written = 0;\n                buf.fill(0);\n                for (var i = 0; i < parts.length; i++) {\n                    var part = parts[i];\n                    part.copy(buf, written);\n                    written += part.length;\n                }\n                callback && callback(buf);\n            });\n            tmp.end(inbuf);\n        }\n    };\n};\n","exports.Deflater = require(\"./deflater\");\nexports.Inflater = require(\"./inflater\");\nexports.ZipCrypto = require(\"./zipcrypto\");\n","module.exports = function (/*Buffer*/ inbuf) {\n    var zlib = require(\"zlib\");\n\n    return {\n        inflate: function () {\n            return zlib.inflateRawSync(inbuf);\n        },\n\n        inflateAsync: function (/*Function*/ callback) {\n            var tmp = zlib.createInflateRaw(),\n                parts = [],\n                total = 0;\n            tmp.on(\"data\", function (data) {\n                parts.push(data);\n                total += data.length;\n            });\n            tmp.on(\"end\", function () {\n                var buf = Buffer.alloc(total),\n                    written = 0;\n                buf.fill(0);\n                for (var i = 0; i < parts.length; i++) {\n                    var part = parts[i];\n                    part.copy(buf, written);\n                    written += part.length;\n                }\n                callback && callback(buf);\n            });\n            tmp.end(inbuf);\n        }\n    };\n};\n","\"use strict\";\n\n// node crypt, we use it for generate salt\n// eslint-disable-next-line node/no-unsupported-features/node-builtins\nconst { randomFillSync } = require(\"crypto\");\n\n// generate CRC32 lookup table\nconst crctable = new Uint32Array(256).map((t, crc) => {\n    for (let j = 0; j < 8; j++) {\n        if (0 !== (crc & 1)) {\n            crc = (crc >>> 1) ^ 0xedb88320;\n        } else {\n            crc >>>= 1;\n        }\n    }\n    return crc >>> 0;\n});\n\n// C-style uInt32 Multiply (discards higher bits, when JS multiply discards lower bits)\nconst uMul = (a, b) => Math.imul(a, b) >>> 0;\n\n// crc32 byte single update (actually same function is part of utils.crc32 function :) )\nconst crc32update = (pCrc32, bval) => {\n    return crctable[(pCrc32 ^ bval) & 0xff] ^ (pCrc32 >>> 8);\n};\n\n// function for generating salt for encrytion header\nconst genSalt = () => {\n    if (\"function\" === typeof randomFillSync) {\n        return randomFillSync(Buffer.alloc(12));\n    } else {\n        // fallback if function is not defined\n        return genSalt.node();\n    }\n};\n\n// salt generation with node random function (mainly as fallback)\ngenSalt.node = () => {\n    const salt = Buffer.alloc(12);\n    const len = salt.length;\n    for (let i = 0; i < len; i++) salt[i] = (Math.random() * 256) & 0xff;\n    return salt;\n};\n\n// general config\nconst config = {\n    genSalt\n};\n\n// Class Initkeys handles same basic ops with keys\nfunction Initkeys(pw) {\n    const pass = Buffer.isBuffer(pw) ? pw : Buffer.from(pw);\n    this.keys = new Uint32Array([0x12345678, 0x23456789, 0x34567890]);\n    for (let i = 0; i < pass.length; i++) {\n        this.updateKeys(pass[i]);\n    }\n}\n\nInitkeys.prototype.updateKeys = function (byteValue) {\n    const keys = this.keys;\n    keys[0] = crc32update(keys[0], byteValue);\n    keys[1] += keys[0] & 0xff;\n    keys[1] = uMul(keys[1], 134775813) + 1;\n    keys[2] = crc32update(keys[2], keys[1] >>> 24);\n    return byteValue;\n};\n\nInitkeys.prototype.next = function () {\n    const k = (this.keys[2] | 2) >>> 0; // key\n    return (uMul(k, k ^ 1) >> 8) & 0xff; // decode\n};\n\nfunction make_decrypter(/*Buffer*/ pwd) {\n    // 1. Stage initialize key\n    const keys = new Initkeys(pwd);\n\n    // return decrypter function\n    return function (/*Buffer*/ data) {\n        // result - we create new Buffer for results\n        const result = Buffer.alloc(data.length);\n        let pos = 0;\n        // process input data\n        for (let c of data) {\n            //c ^= keys.next();\n            //result[pos++] = c; // decode & Save Value\n            result[pos++] = keys.updateKeys(c ^ keys.next()); // update keys with decoded byte\n        }\n        return result;\n    };\n}\n\nfunction make_encrypter(/*Buffer*/ pwd) {\n    // 1. Stage initialize key\n    const keys = new Initkeys(pwd);\n\n    // return encrypting function, result and pos is here so we dont have to merge buffers later\n    return function (/*Buffer*/ data, /*Buffer*/ result, /* Number */ pos = 0) {\n        // result - we create new Buffer for results\n        if (!result) result = Buffer.alloc(data.length);\n        // process input data\n        for (let c of data) {\n            const k = keys.next(); // save key byte\n            result[pos++] = c ^ k; // save val\n            keys.updateKeys(c); // update keys with decoded byte\n        }\n        return result;\n    };\n}\n\nfunction decrypt(/*Buffer*/ data, /*Object*/ header, /*String, Buffer*/ pwd) {\n    if (!data || !Buffer.isBuffer(data) || data.length < 12) {\n        return Buffer.alloc(0);\n    }\n\n    // 1. We Initialize and generate decrypting function\n    const decrypter = make_decrypter(pwd);\n\n    // 2. decrypt salt what is always 12 bytes and is a part of file content\n    const salt = decrypter(data.slice(0, 12));\n\n    // 3. does password meet expectations\n    if (salt[11] !== header.crc >>> 24) {\n        throw \"ADM-ZIP: Wrong Password\";\n    }\n\n    // 4. decode content\n    return decrypter(data.slice(12));\n}\n\n// lets add way to populate salt, NOT RECOMMENDED for production but maybe useful for testing general functionality\nfunction _salter(data) {\n    if (Buffer.isBuffer(data) && data.length >= 12) {\n        // be aware - currently salting buffer data is modified\n        config.genSalt = function () {\n            return data.slice(0, 12);\n        };\n    } else if (data === \"node\") {\n        // test salt generation with node random function\n        config.genSalt = genSalt.node;\n    } else {\n        // if value is not acceptable config gets reset.\n        config.genSalt = genSalt;\n    }\n}\n\nfunction encrypt(/*Buffer*/ data, /*Object*/ header, /*String, Buffer*/ pwd, /*Boolean*/ oldlike = false) {\n    // 1. test data if data is not Buffer we make buffer from it\n    if (data == null) data = Buffer.alloc(0);\n    // if data is not buffer be make buffer from it\n    if (!Buffer.isBuffer(data)) data = Buffer.from(data.toString());\n\n    // 2. We Initialize and generate encrypting function\n    const encrypter = make_encrypter(pwd);\n\n    // 3. generate salt (12-bytes of random data)\n    const salt = config.genSalt();\n    salt[11] = (header.crc >>> 24) & 0xff;\n\n    // old implementations (before PKZip 2.04g) used two byte check\n    if (oldlike) salt[10] = (header.crc >>> 16) & 0xff;\n\n    // 4. create output\n    const result = Buffer.alloc(data.length + 12);\n    encrypter(salt, result);\n\n    // finally encode content\n    return encrypter(data, result, 12);\n}\n\nmodule.exports = { decrypt, encrypt, _salter };\n","module.exports = {\n    /* The local file header */\n    LOCHDR           : 30, // LOC header size\n    LOCSIG           : 0x04034b50, // \"PK\\003\\004\"\n    LOCVER           : 4,\t// version needed to extract\n    LOCFLG           : 6, // general purpose bit flag\n    LOCHOW           : 8, // compression method\n    LOCTIM           : 10, // modification time (2 bytes time, 2 bytes date)\n    LOCCRC           : 14, // uncompressed file crc-32 value\n    LOCSIZ           : 18, // compressed size\n    LOCLEN           : 22, // uncompressed size\n    LOCNAM           : 26, // filename length\n    LOCEXT           : 28, // extra field length\n\n    /* The Data descriptor */\n    EXTSIG           : 0x08074b50, // \"PK\\007\\008\"\n    EXTHDR           : 16, // EXT header size\n    EXTCRC           : 4, // uncompressed file crc-32 value\n    EXTSIZ           : 8, // compressed size\n    EXTLEN           : 12, // uncompressed size\n\n    /* The central directory file header */\n    CENHDR           : 46, // CEN header size\n    CENSIG           : 0x02014b50, // \"PK\\001\\002\"\n    CENVEM           : 4, // version made by\n    CENVER           : 6, // version needed to extract\n    CENFLG           : 8, // encrypt, decrypt flags\n    CENHOW           : 10, // compression method\n    CENTIM           : 12, // modification time (2 bytes time, 2 bytes date)\n    CENCRC           : 16, // uncompressed file crc-32 value\n    CENSIZ           : 20, // compressed size\n    CENLEN           : 24, // uncompressed size\n    CENNAM           : 28, // filename length\n    CENEXT           : 30, // extra field length\n    CENCOM           : 32, // file comment length\n    CENDSK           : 34, // volume number start\n    CENATT           : 36, // internal file attributes\n    CENATX           : 38, // external file attributes (host system dependent)\n    CENOFF           : 42, // LOC header offset\n\n    /* The entries in the end of central directory */\n    ENDHDR           : 22, // END header size\n    ENDSIG           : 0x06054b50, // \"PK\\005\\006\"\n    ENDSUB           : 8, // number of entries on this disk\n    ENDTOT           : 10, // total number of entries\n    ENDSIZ           : 12, // central directory size in bytes\n    ENDOFF           : 16, // offset of first CEN header\n    ENDCOM           : 20, // zip file comment length\n\n    END64HDR         : 20, // zip64 END header size\n    END64SIG         : 0x07064b50, // zip64 Locator signature, \"PK\\006\\007\"\n    END64START       : 4, // number of the disk with the start of the zip64\n    END64OFF         : 8, // relative offset of the zip64 end of central directory\n    END64NUMDISKS    : 16, // total number of disks\n\n    ZIP64SIG         : 0x06064b50, // zip64 signature, \"PK\\006\\006\"\n    ZIP64HDR         : 56, // zip64 record minimum size\n    ZIP64LEAD        : 12, // leading bytes at the start of the record, not counted by the value stored in ZIP64SIZE\n    ZIP64SIZE        : 4, // zip64 size of the central directory record\n    ZIP64VEM         : 12, // zip64 version made by\n    ZIP64VER         : 14, // zip64 version needed to extract\n    ZIP64DSK         : 16, // zip64 number of this disk\n    ZIP64DSKDIR      : 20, // number of the disk with the start of the record directory\n    ZIP64SUB         : 24, // number of entries on this disk\n    ZIP64TOT         : 32, // total number of entries\n    ZIP64SIZB        : 40, // zip64 central directory size in bytes\n    ZIP64OFF         : 48, // offset of start of central directory with respect to the starting disk number\n    ZIP64EXTRA       : 56, // extensible data sector\n\n    /* Compression methods */\n    STORED           : 0, // no compression\n    SHRUNK           : 1, // shrunk\n    REDUCED1         : 2, // reduced with compression factor 1\n    REDUCED2         : 3, // reduced with compression factor 2\n    REDUCED3         : 4, // reduced with compression factor 3\n    REDUCED4         : 5, // reduced with compression factor 4\n    IMPLODED         : 6, // imploded\n    // 7 reserved for Tokenizing compression algorithm\n    DEFLATED         : 8, // deflated\n    ENHANCED_DEFLATED: 9, // enhanced deflated\n    PKWARE           : 10,// PKWare DCL imploded\n    // 11 reserved by PKWARE\n    BZIP2            : 12, //  compressed using BZIP2\n    // 13 reserved by PKWARE\n    LZMA             : 14, // LZMA\n    // 15-17 reserved by PKWARE\n    IBM_TERSE        : 18, // compressed using IBM TERSE\n    IBM_LZ77         : 19, // IBM LZ77 z\n    AES_ENCRYPT      : 99, // WinZIP AES encryption method\n\n    /* General purpose bit flag */\n    // values can obtained with expression 2**bitnr\n    FLG_ENC          : 1,    // Bit 0: encrypted file\n    FLG_COMP1        : 2,    // Bit 1, compression option\n    FLG_COMP2        : 4,    // Bit 2, compression option\n    FLG_DESC         : 8,    // Bit 3, data descriptor\n    FLG_ENH          : 16,   // Bit 4, enhanced deflating\n    FLG_PATCH        : 32,   // Bit 5, indicates that the file is compressed patched data.\n    FLG_STR          : 64,   // Bit 6, strong encryption (patented)\n                             // Bits 7-10: Currently unused.\n    FLG_EFS          : 2048, // Bit 11: Language encoding flag (EFS)\n                             // Bit 12: Reserved by PKWARE for enhanced compression.\n                             // Bit 13: encrypted the Central Directory (patented).\n                             // Bits 14-15: Reserved by PKWARE.\n    FLG_MSK          : 4096, // mask header values\n\n    /* Load type */\n    FILE             : 2,\n    BUFFER           : 1,\n    NONE             : 0,\n\n    /* 4.5 Extensible data fields */\n    EF_ID            : 0,\n    EF_SIZE          : 2,\n\n    /* Header IDs */\n    ID_ZIP64         : 0x0001,\n    ID_AVINFO        : 0x0007,\n    ID_PFS           : 0x0008,\n    ID_OS2           : 0x0009,\n    ID_NTFS          : 0x000a,\n    ID_OPENVMS       : 0x000c,\n    ID_UNIX          : 0x000d,\n    ID_FORK          : 0x000e,\n    ID_PATCH         : 0x000f,\n    ID_X509_PKCS7    : 0x0014,\n    ID_X509_CERTID_F : 0x0015,\n    ID_X509_CERTID_C : 0x0016,\n    ID_STRONGENC     : 0x0017,\n    ID_RECORD_MGT    : 0x0018,\n    ID_X509_PKCS7_RL : 0x0019,\n    ID_IBM1          : 0x0065,\n    ID_IBM2          : 0x0066,\n    ID_POSZIP        : 0x4690,\n\n    EF_ZIP64_OR_32   : 0xffffffff,\n    EF_ZIP64_OR_16   : 0xffff,\n    EF_ZIP64_SUNCOMP : 0,\n    EF_ZIP64_SCOMP   : 8,\n    EF_ZIP64_RHO     : 16,\n    EF_ZIP64_DSN     : 24\n};\n","module.exports = {\n    /* Header error messages */\n    INVALID_LOC: \"Invalid LOC header (bad signature)\",\n    INVALID_CEN: \"Invalid CEN header (bad signature)\",\n    INVALID_END: \"Invalid END header (bad signature)\",\n\n    /* ZipEntry error messages*/\n    NO_DATA: \"Nothing to decompress\",\n    BAD_CRC: \"CRC32 checksum failed\",\n    FILE_IN_THE_WAY: \"There is a file in the way: %s\",\n    UNKNOWN_METHOD: \"Invalid/unsupported compression method\",\n\n    /* Inflater error messages */\n    AVAIL_DATA: \"inflate::Available inflate data did not terminate\",\n    INVALID_DISTANCE: \"inflate::Invalid literal/length or distance code in fixed or dynamic block\",\n    TO_MANY_CODES: \"inflate::Dynamic block code description: too many length or distance codes\",\n    INVALID_REPEAT_LEN: \"inflate::Dynamic block code description: repeat more than specified lengths\",\n    INVALID_REPEAT_FIRST: \"inflate::Dynamic block code description: repeat lengths with no first length\",\n    INCOMPLETE_CODES: \"inflate::Dynamic block code description: code lengths codes incomplete\",\n    INVALID_DYN_DISTANCE: \"inflate::Dynamic block code description: invalid distance code lengths\",\n    INVALID_CODES_LEN: \"inflate::Dynamic block code description: invalid literal/length code lengths\",\n    INVALID_STORE_BLOCK: \"inflate::Stored block length did not match one's complement\",\n    INVALID_BLOCK_TYPE: \"inflate::Invalid block type (type == 3)\",\n\n    /* ADM-ZIP error messages */\n    CANT_EXTRACT_FILE: \"Could not extract the file\",\n    CANT_OVERRIDE: \"Target file already exists\",\n    NO_ZIP: \"No zip file was loaded\",\n    NO_ENTRY: \"Entry doesn't exist\",\n    DIRECTORY_CONTENT_ERROR: \"A directory cannot have content\",\n    FILE_NOT_FOUND: \"File not found: %s\",\n    NOT_IMPLEMENTED: \"Not implemented\",\n    INVALID_FILENAME: \"Invalid filename\",\n    INVALID_FORMAT: \"Invalid or unsupported zip format. No END header found\"\n};\n","const fs = require(\"./fileSystem\").require();\nconst pth = require(\"path\");\n\nfs.existsSync = fs.existsSync || pth.existsSync;\n\nmodule.exports = function (/*String*/ path) {\n    var _path = path || \"\",\n        _obj = newAttr(),\n        _stat = null;\n\n    function newAttr() {\n        return {\n            directory: false,\n            readonly: false,\n            hidden: false,\n            executable: false,\n            mtime: 0,\n            atime: 0\n        };\n    }\n\n    if (_path && fs.existsSync(_path)) {\n        _stat = fs.statSync(_path);\n        _obj.directory = _stat.isDirectory();\n        _obj.mtime = _stat.mtime;\n        _obj.atime = _stat.atime;\n        _obj.executable = (0o111 & _stat.mode) !== 0; // file is executable who ever har right not just owner\n        _obj.readonly = (0o200 & _stat.mode) === 0; // readonly if owner has no write right\n        _obj.hidden = pth.basename(_path)[0] === \".\";\n    } else {\n        console.warn(\"Invalid path: \" + _path);\n    }\n\n    return {\n        get directory() {\n            return _obj.directory;\n        },\n\n        get readOnly() {\n            return _obj.readonly;\n        },\n\n        get hidden() {\n            return _obj.hidden;\n        },\n\n        get mtime() {\n            return _obj.mtime;\n        },\n\n        get atime() {\n            return _obj.atime;\n        },\n\n        get executable() {\n            return _obj.executable;\n        },\n\n        decodeAttributes: function () {},\n\n        encodeAttributes: function () {},\n\n        toJSON: function () {\n            return {\n                path: _path,\n                isDirectory: _obj.directory,\n                isReadOnly: _obj.readonly,\n                isHidden: _obj.hidden,\n                isExecutable: _obj.executable,\n                mTime: _obj.mtime,\n                aTime: _obj.atime\n            };\n        },\n\n        toString: function () {\n            return JSON.stringify(this.toJSON(), null, \"\\t\");\n        }\n    };\n};\n","exports.require = function () {\n    if (typeof process === \"object\" && process.versions && process.versions[\"electron\"]) {\n        try {\n            const originalFs = require(\"original-fs\");\n            if (Object.keys(originalFs).length > 0) {\n                return originalFs;\n            }\n        } catch (e) {}\n    }\n    return require(\"fs\");\n};\n","module.exports = require(\"./utils\");\nmodule.exports.Constants = require(\"./constants\");\nmodule.exports.Errors = require(\"./errors\");\nmodule.exports.FileAttr = require(\"./fattr\");\n","const fsystem = require(\"./fileSystem\").require();\nconst pth = require(\"path\");\nconst Constants = require(\"./constants\");\nconst isWin = typeof process === \"object\" && \"win32\" === process.platform;\n\nconst is_Obj = (obj) => obj && typeof obj === \"object\";\n\n// generate CRC32 lookup table\nconst crcTable = new Uint32Array(256).map((t, c) => {\n    for (let k = 0; k < 8; k++) {\n        if ((c & 1) !== 0) {\n            c = 0xedb88320 ^ (c >>> 1);\n        } else {\n            c >>>= 1;\n        }\n    }\n    return c >>> 0;\n});\n\n// UTILS functions\n\nfunction Utils(opts) {\n    this.sep = pth.sep;\n    this.fs = fsystem;\n\n    if (is_Obj(opts)) {\n        // custom filesystem\n        if (is_Obj(opts.fs) && typeof opts.fs.statSync === \"function\") {\n            this.fs = opts.fs;\n        }\n    }\n}\n\nmodule.exports = Utils;\n\n// INSTANCED functions\n\nUtils.prototype.makeDir = function (/*String*/ folder) {\n    const self = this;\n\n    // Sync - make directories tree\n    function mkdirSync(/*String*/ fpath) {\n        let resolvedPath = fpath.split(self.sep)[0];\n        fpath.split(self.sep).forEach(function (name) {\n            if (!name || name.substr(-1, 1) === \":\") return;\n            resolvedPath += self.sep + name;\n            var stat;\n            try {\n                stat = self.fs.statSync(resolvedPath);\n            } catch (e) {\n                self.fs.mkdirSync(resolvedPath);\n            }\n            if (stat && stat.isFile()) throw Errors.FILE_IN_THE_WAY.replace(\"%s\", resolvedPath);\n        });\n    }\n\n    mkdirSync(folder);\n};\n\nUtils.prototype.writeFileTo = function (/*String*/ path, /*Buffer*/ content, /*Boolean*/ overwrite, /*Number*/ attr) {\n    const self = this;\n    if (self.fs.existsSync(path)) {\n        if (!overwrite) return false; // cannot overwrite\n\n        var stat = self.fs.statSync(path);\n        if (stat.isDirectory()) {\n            return false;\n        }\n    }\n    var folder = pth.dirname(path);\n    if (!self.fs.existsSync(folder)) {\n        self.makeDir(folder);\n    }\n\n    var fd;\n    try {\n        fd = self.fs.openSync(path, \"w\", 438); // 0666\n    } catch (e) {\n        self.fs.chmodSync(path, 438);\n        fd = self.fs.openSync(path, \"w\", 438);\n    }\n    if (fd) {\n        try {\n            self.fs.writeSync(fd, content, 0, content.length, 0);\n        } finally {\n            self.fs.closeSync(fd);\n        }\n    }\n    self.fs.chmodSync(path, attr || 438);\n    return true;\n};\n\nUtils.prototype.writeFileToAsync = function (/*String*/ path, /*Buffer*/ content, /*Boolean*/ overwrite, /*Number*/ attr, /*Function*/ callback) {\n    if (typeof attr === \"function\") {\n        callback = attr;\n        attr = undefined;\n    }\n\n    const self = this;\n\n    self.fs.exists(path, function (exist) {\n        if (exist && !overwrite) return callback(false);\n\n        self.fs.stat(path, function (err, stat) {\n            if (exist && stat.isDirectory()) {\n                return callback(false);\n            }\n\n            var folder = pth.dirname(path);\n            self.fs.exists(folder, function (exists) {\n                if (!exists) self.makeDir(folder);\n\n                self.fs.open(path, \"w\", 438, function (err, fd) {\n                    if (err) {\n                        self.fs.chmod(path, 438, function () {\n                            self.fs.open(path, \"w\", 438, function (err, fd) {\n                                self.fs.write(fd, content, 0, content.length, 0, function () {\n                                    self.fs.close(fd, function () {\n                                        self.fs.chmod(path, attr || 438, function () {\n                                            callback(true);\n                                        });\n                                    });\n                                });\n                            });\n                        });\n                    } else if (fd) {\n                        self.fs.write(fd, content, 0, content.length, 0, function () {\n                            self.fs.close(fd, function () {\n                                self.fs.chmod(path, attr || 438, function () {\n                                    callback(true);\n                                });\n                            });\n                        });\n                    } else {\n                        self.fs.chmod(path, attr || 438, function () {\n                            callback(true);\n                        });\n                    }\n                });\n            });\n        });\n    });\n};\n\nUtils.prototype.findFiles = function (/*String*/ path) {\n    const self = this;\n\n    function findSync(/*String*/ dir, /*RegExp*/ pattern, /*Boolean*/ recursive) {\n        if (typeof pattern === \"boolean\") {\n            recursive = pattern;\n            pattern = undefined;\n        }\n        let files = [];\n        self.fs.readdirSync(dir).forEach(function (file) {\n            var path = pth.join(dir, file);\n\n            if (self.fs.statSync(path).isDirectory() && recursive) files = files.concat(findSync(path, pattern, recursive));\n\n            if (!pattern || pattern.test(path)) {\n                files.push(pth.normalize(path) + (self.fs.statSync(path).isDirectory() ? self.sep : \"\"));\n            }\n        });\n        return files;\n    }\n\n    return findSync(path, undefined, true);\n};\n\nUtils.prototype.getAttributes = function () {};\n\nUtils.prototype.setAttributes = function () {};\n\n// STATIC functions\n\n// crc32 single update (it is part of crc32)\nUtils.crc32update = function (crc, byte) {\n    return crcTable[(crc ^ byte) & 0xff] ^ (crc >>> 8);\n};\n\nUtils.crc32 = function (buf) {\n    if (typeof buf === \"string\") {\n        buf = Buffer.from(buf, \"utf8\");\n    }\n    // Generate crcTable\n    if (!crcTable.length) genCRCTable();\n\n    let len = buf.length;\n    let crc = ~0;\n    for (let off = 0; off < len; ) crc = Utils.crc32update(crc, buf[off++]);\n    // xor and cast as uint32 number\n    return ~crc >>> 0;\n};\n\nUtils.methodToString = function (/*Number*/ method) {\n    switch (method) {\n        case Constants.STORED:\n            return \"STORED (\" + method + \")\";\n        case Constants.DEFLATED:\n            return \"DEFLATED (\" + method + \")\";\n        default:\n            return \"UNSUPPORTED (\" + method + \")\";\n    }\n};\n\n// removes \"..\" style path elements\nUtils.canonical = function (/*string*/ path) {\n    if (!path) return \"\";\n    // trick normalize think path is absolute\n    var safeSuffix = pth.posix.normalize(\"/\" + path.split(\"\\\\\").join(\"/\"));\n    return pth.join(\".\", safeSuffix);\n};\n\n// make abolute paths taking prefix as root folder\nUtils.sanitize = function (/*string*/ prefix, /*string*/ name) {\n    prefix = pth.resolve(pth.normalize(prefix));\n    var parts = name.split(\"/\");\n    for (var i = 0, l = parts.length; i < l; i++) {\n        var path = pth.normalize(pth.join(prefix, parts.slice(i, l).join(pth.sep)));\n        if (path.indexOf(prefix) === 0) {\n            return path;\n        }\n    }\n    return pth.normalize(pth.join(prefix, pth.basename(name)));\n};\n\n// converts buffer, Uint8Array, string types to buffer\nUtils.toBuffer = function toBuffer(/*buffer, Uint8Array, string*/ input) {\n    if (Buffer.isBuffer(input)) {\n        return input;\n    } else if (input instanceof Uint8Array) {\n        return Buffer.from(input);\n    } else {\n        // expect string all other values are invalid and return empty buffer\n        return typeof input === \"string\" ? Buffer.from(input, \"utf8\") : Buffer.alloc(0);\n    }\n};\n\nUtils.readBigUInt64LE = function (/*Buffer*/ buffer, /*int*/ index) {\n    var slice = Buffer.from(buffer.slice(index, index + 8));\n    slice.swap64();\n\n    return parseInt(`0x${slice.toString(\"hex\")}`);\n};\n\nUtils.isWin = isWin; // Do we have windows system\nUtils.crcTable = crcTable;\n","var Utils = require(\"./util\"),\n    Headers = require(\"./headers\"),\n    Constants = Utils.Constants,\n    Methods = require(\"./methods\");\n\nmodule.exports = function (/*Buffer*/ input) {\n    var _entryHeader = new Headers.EntryHeader(),\n        _entryName = Buffer.alloc(0),\n        _comment = Buffer.alloc(0),\n        _isDirectory = false,\n        uncompressedData = null,\n        _extra = Buffer.alloc(0);\n\n    function getCompressedDataFromZip() {\n        if (!input || !Buffer.isBuffer(input)) {\n            return Buffer.alloc(0);\n        }\n        _entryHeader.loadDataHeaderFromBinary(input);\n        return input.slice(_entryHeader.realDataOffset, _entryHeader.realDataOffset + _entryHeader.compressedSize);\n    }\n\n    function crc32OK(data) {\n        // if bit 3 (0x08) of the general-purpose flags field is set, then the CRC-32 and file sizes are not known when the header is written\n        if ((_entryHeader.flags & 0x8) !== 0x8) {\n            if (Utils.crc32(data) !== _entryHeader.dataHeader.crc) {\n                return false;\n            }\n        } else {\n            // @TODO: load and check data descriptor header\n            // The fields in the local header are filled with zero, and the CRC-32 and size are appended in a 12-byte structure\n            // (optionally preceded by a 4-byte signature) immediately after the compressed data:\n        }\n        return true;\n    }\n\n    function decompress(/*Boolean*/ async, /*Function*/ callback, /*String, Buffer*/ pass) {\n        if (typeof callback === \"undefined\" && typeof async === \"string\") {\n            pass = async;\n            async = void 0;\n        }\n        if (_isDirectory) {\n            if (async && callback) {\n                callback(Buffer.alloc(0), Utils.Errors.DIRECTORY_CONTENT_ERROR); //si added error.\n            }\n            return Buffer.alloc(0);\n        }\n\n        var compressedData = getCompressedDataFromZip();\n\n        if (compressedData.length === 0) {\n            // File is empty, nothing to decompress.\n            if (async && callback) callback(compressedData);\n            return compressedData;\n        }\n\n        if (_entryHeader.encripted) {\n            if (\"string\" !== typeof pass && !Buffer.isBuffer(pass)) {\n                throw new Error(\"ADM-ZIP: Incompatible password parameter\");\n            }\n            compressedData = Methods.ZipCrypto.decrypt(compressedData, _entryHeader, pass);\n        }\n\n        var data = Buffer.alloc(_entryHeader.size);\n\n        switch (_entryHeader.method) {\n            case Utils.Constants.STORED:\n                compressedData.copy(data);\n                if (!crc32OK(data)) {\n                    if (async && callback) callback(data, Utils.Errors.BAD_CRC); //si added error\n                    throw new Error(Utils.Errors.BAD_CRC);\n                } else {\n                    //si added otherwise did not seem to return data.\n                    if (async && callback) callback(data);\n                    return data;\n                }\n            case Utils.Constants.DEFLATED:\n                var inflater = new Methods.Inflater(compressedData);\n                if (!async) {\n                    const result = inflater.inflate(data);\n                    result.copy(data, 0);\n                    if (!crc32OK(data)) {\n                        throw new Error(Utils.Errors.BAD_CRC + \" \" + _entryName.toString());\n                    }\n                    return data;\n                } else {\n                    inflater.inflateAsync(function (result) {\n                        result.copy(result, 0);\n                        if (callback) {\n                            if (!crc32OK(result)) {\n                                callback(result, Utils.Errors.BAD_CRC); //si added error\n                            } else {\n                                callback(result);\n                            }\n                        }\n                    });\n                }\n                break;\n            default:\n                if (async && callback) callback(Buffer.alloc(0), Utils.Errors.UNKNOWN_METHOD);\n                throw new Error(Utils.Errors.UNKNOWN_METHOD);\n        }\n    }\n\n    function compress(/*Boolean*/ async, /*Function*/ callback) {\n        if ((!uncompressedData || !uncompressedData.length) && Buffer.isBuffer(input)) {\n            // no data set or the data wasn't changed to require recompression\n            if (async && callback) callback(getCompressedDataFromZip());\n            return getCompressedDataFromZip();\n        }\n\n        if (uncompressedData.length && !_isDirectory) {\n            var compressedData;\n            // Local file header\n            switch (_entryHeader.method) {\n                case Utils.Constants.STORED:\n                    _entryHeader.compressedSize = _entryHeader.size;\n\n                    compressedData = Buffer.alloc(uncompressedData.length);\n                    uncompressedData.copy(compressedData);\n\n                    if (async && callback) callback(compressedData);\n                    return compressedData;\n                default:\n                case Utils.Constants.DEFLATED:\n                    var deflater = new Methods.Deflater(uncompressedData);\n                    if (!async) {\n                        var deflated = deflater.deflate();\n                        _entryHeader.compressedSize = deflated.length;\n                        return deflated;\n                    } else {\n                        deflater.deflateAsync(function (data) {\n                            compressedData = Buffer.alloc(data.length);\n                            _entryHeader.compressedSize = data.length;\n                            data.copy(compressedData);\n                            callback && callback(compressedData);\n                        });\n                    }\n                    deflater = null;\n                    break;\n            }\n        } else if (async && callback) {\n            callback(Buffer.alloc(0));\n        } else {\n            return Buffer.alloc(0);\n        }\n    }\n\n    function readUInt64LE(buffer, offset) {\n        return (buffer.readUInt32LE(offset + 4) << 4) + buffer.readUInt32LE(offset);\n    }\n\n    function parseExtra(data) {\n        var offset = 0;\n        var signature, size, part;\n        while (offset < data.length) {\n            signature = data.readUInt16LE(offset);\n            offset += 2;\n            size = data.readUInt16LE(offset);\n            offset += 2;\n            part = data.slice(offset, offset + size);\n            offset += size;\n            if (Constants.ID_ZIP64 === signature) {\n                parseZip64ExtendedInformation(part);\n            }\n        }\n    }\n\n    //Override header field values with values from the ZIP64 extra field\n    function parseZip64ExtendedInformation(data) {\n        var size, compressedSize, offset, diskNumStart;\n\n        if (data.length >= Constants.EF_ZIP64_SCOMP) {\n            size = readUInt64LE(data, Constants.EF_ZIP64_SUNCOMP);\n            if (_entryHeader.size === Constants.EF_ZIP64_OR_32) {\n                _entryHeader.size = size;\n            }\n        }\n        if (data.length >= Constants.EF_ZIP64_RHO) {\n            compressedSize = readUInt64LE(data, Constants.EF_ZIP64_SCOMP);\n            if (_entryHeader.compressedSize === Constants.EF_ZIP64_OR_32) {\n                _entryHeader.compressedSize = compressedSize;\n            }\n        }\n        if (data.length >= Constants.EF_ZIP64_DSN) {\n            offset = readUInt64LE(data, Constants.EF_ZIP64_RHO);\n            if (_entryHeader.offset === Constants.EF_ZIP64_OR_32) {\n                _entryHeader.offset = offset;\n            }\n        }\n        if (data.length >= Constants.EF_ZIP64_DSN + 4) {\n            diskNumStart = data.readUInt32LE(Constants.EF_ZIP64_DSN);\n            if (_entryHeader.diskNumStart === Constants.EF_ZIP64_OR_16) {\n                _entryHeader.diskNumStart = diskNumStart;\n            }\n        }\n    }\n\n    return {\n        get entryName() {\n            return _entryName.toString();\n        },\n        get rawEntryName() {\n            return _entryName;\n        },\n        set entryName(val) {\n            _entryName = Utils.toBuffer(val);\n            var lastChar = _entryName[_entryName.length - 1];\n            _isDirectory = lastChar === 47 || lastChar === 92;\n            _entryHeader.fileNameLength = _entryName.length;\n        },\n\n        get extra() {\n            return _extra;\n        },\n        set extra(val) {\n            _extra = val;\n            _entryHeader.extraLength = val.length;\n            parseExtra(val);\n        },\n\n        get comment() {\n            return _comment.toString();\n        },\n        set comment(val) {\n            _comment = Utils.toBuffer(val);\n            _entryHeader.commentLength = _comment.length;\n        },\n\n        get name() {\n            var n = _entryName.toString();\n            return _isDirectory\n                ? n\n                      .substr(n.length - 1)\n                      .split(\"/\")\n                      .pop()\n                : n.split(\"/\").pop();\n        },\n        get isDirectory() {\n            return _isDirectory;\n        },\n\n        getCompressedData: function () {\n            return compress(false, null);\n        },\n\n        getCompressedDataAsync: function (/*Function*/ callback) {\n            compress(true, callback);\n        },\n\n        setData: function (value) {\n            uncompressedData = Utils.toBuffer(value);\n            if (!_isDirectory && uncompressedData.length) {\n                _entryHeader.size = uncompressedData.length;\n                _entryHeader.method = Utils.Constants.DEFLATED;\n                _entryHeader.crc = Utils.crc32(value);\n                _entryHeader.changed = true;\n            } else {\n                // folders and blank files should be stored\n                _entryHeader.method = Utils.Constants.STORED;\n            }\n        },\n\n        getData: function (pass) {\n            if (_entryHeader.changed) {\n                return uncompressedData;\n            } else {\n                return decompress(false, null, pass);\n            }\n        },\n\n        getDataAsync: function (/*Function*/ callback, pass) {\n            if (_entryHeader.changed) {\n                callback(uncompressedData);\n            } else {\n                decompress(true, callback, pass);\n            }\n        },\n\n        set attr(attr) {\n            _entryHeader.attr = attr;\n        },\n        get attr() {\n            return _entryHeader.attr;\n        },\n\n        set header(/*Buffer*/ data) {\n            _entryHeader.loadFromBinary(data);\n        },\n\n        get header() {\n            return _entryHeader;\n        },\n\n        packHeader: function () {\n            // 1. create header (buffer)\n            var header = _entryHeader.entryHeaderToBinary();\n            var addpos = Utils.Constants.CENHDR;\n            // 2. add file name\n            _entryName.copy(header, addpos);\n            addpos += _entryName.length;\n            // 3. add extra data\n            if (_entryHeader.extraLength) {\n                _extra.copy(header, addpos);\n                addpos += _entryHeader.extraLength;\n            }\n            // 4. add file comment\n            if (_entryHeader.commentLength) {\n                _comment.copy(header, addpos);\n            }\n            return header;\n        },\n\n        toJSON: function () {\n            const bytes = function (nr) {\n                return \"<\" + ((nr && nr.length + \" bytes buffer\") || \"null\") + \">\";\n            };\n\n            return {\n                entryName: this.entryName,\n                name: this.name,\n                comment: this.comment,\n                isDirectory: this.isDirectory,\n                header: _entryHeader.toJSON(),\n                compressedData: bytes(input),\n                data: bytes(uncompressedData)\n            };\n        },\n\n        toString: function () {\n            return JSON.stringify(this.toJSON(), null, \"\\t\");\n        }\n    };\n};\n","const ZipEntry = require(\"./zipEntry\");\nconst Headers = require(\"./headers\");\nconst Utils = require(\"./util\");\n\nmodule.exports = function (/*Buffer|null*/ inBuffer, /** object */ options) {\n    var entryList = [],\n        entryTable = {},\n        _comment = Buffer.alloc(0),\n        mainHeader = new Headers.MainHeader(),\n        loadedEntries = false;\n\n    // assign options\n    const opts = Object.assign(Object.create(null), options);\n\n    const { noSort } = opts;\n\n    if (inBuffer) {\n        // is a memory buffer\n        readMainHeader(opts.readEntries);\n    } else {\n        // none. is a new file\n        loadedEntries = true;\n    }\n\n    function iterateEntries(callback) {\n        const totalEntries = mainHeader.diskEntries; // total number of entries\n        let index = mainHeader.offset; // offset of first CEN header\n\n        for (let i = 0; i < totalEntries; i++) {\n            let tmp = index;\n            const entry = new ZipEntry(inBuffer);\n\n            entry.header = inBuffer.slice(tmp, (tmp += Utils.Constants.CENHDR));\n            entry.entryName = inBuffer.slice(tmp, (tmp += entry.header.fileNameLength));\n\n            index += entry.header.entryHeaderSize;\n\n            callback(entry);\n        }\n    }\n\n    function readEntries() {\n        loadedEntries = true;\n        entryTable = {};\n        entryList = new Array(mainHeader.diskEntries); // total number of entries\n        var index = mainHeader.offset; // offset of first CEN header\n        for (var i = 0; i < entryList.length; i++) {\n            var tmp = index,\n                entry = new ZipEntry(inBuffer);\n            entry.header = inBuffer.slice(tmp, (tmp += Utils.Constants.CENHDR));\n\n            entry.entryName = inBuffer.slice(tmp, (tmp += entry.header.fileNameLength));\n\n            if (entry.header.extraLength) {\n                entry.extra = inBuffer.slice(tmp, (tmp += entry.header.extraLength));\n            }\n\n            if (entry.header.commentLength) entry.comment = inBuffer.slice(tmp, tmp + entry.header.commentLength);\n\n            index += entry.header.entryHeaderSize;\n\n            entryList[i] = entry;\n            entryTable[entry.entryName] = entry;\n        }\n    }\n\n    function readMainHeader(/*Boolean*/ readNow) {\n        var i = inBuffer.length - Utils.Constants.ENDHDR, // END header size\n            max = Math.max(0, i - 0xffff), // 0xFFFF is the max zip file comment length\n            n = max,\n            endStart = inBuffer.length,\n            endOffset = -1, // Start offset of the END header\n            commentEnd = 0;\n\n        for (i; i >= n; i--) {\n            if (inBuffer[i] !== 0x50) continue; // quick check that the byte is 'P'\n            if (inBuffer.readUInt32LE(i) === Utils.Constants.ENDSIG) {\n                // \"PK\\005\\006\"\n                endOffset = i;\n                commentEnd = i;\n                endStart = i + Utils.Constants.ENDHDR;\n                // We already found a regular signature, let's look just a bit further to check if there's any zip64 signature\n                n = i - Utils.Constants.END64HDR;\n                continue;\n            }\n\n            if (inBuffer.readUInt32LE(i) === Utils.Constants.END64SIG) {\n                // Found a zip64 signature, let's continue reading the whole zip64 record\n                n = max;\n                continue;\n            }\n\n            if (inBuffer.readUInt32LE(i) === Utils.Constants.ZIP64SIG) {\n                // Found the zip64 record, let's determine it's size\n                endOffset = i;\n                endStart = i + Utils.readBigUInt64LE(inBuffer, i + Utils.Constants.ZIP64SIZE) + Utils.Constants.ZIP64LEAD;\n                break;\n            }\n        }\n\n        if (!~endOffset) throw new Error(Utils.Errors.INVALID_FORMAT);\n\n        mainHeader.loadFromBinary(inBuffer.slice(endOffset, endStart));\n        if (mainHeader.commentLength) {\n            _comment = inBuffer.slice(commentEnd + Utils.Constants.ENDHDR);\n        }\n        if (readNow) readEntries();\n    }\n\n    function sortEntries() {\n        if (entryList.length > 1 && !noSort) {\n            entryList.sort((a, b) => a.entryName.toLowerCase().localeCompare(b.entryName.toLowerCase()));\n        }\n    }\n\n    return {\n        /**\n         * Returns an array of ZipEntry objects existent in the current opened archive\n         * @return Array\n         */\n        get entries() {\n            if (!loadedEntries) {\n                readEntries();\n            }\n            return entryList;\n        },\n\n        /**\n         * Archive comment\n         * @return {String}\n         */\n        get comment() {\n            return _comment.toString();\n        },\n        set comment(val) {\n            _comment = Utils.toBuffer(val);\n            mainHeader.commentLength = _comment.length;\n        },\n\n        getEntryCount: function () {\n            if (!loadedEntries) {\n                return mainHeader.diskEntries;\n            }\n\n            return entryList.length;\n        },\n\n        forEach: function (callback) {\n            if (!loadedEntries) {\n                iterateEntries(callback);\n                return;\n            }\n\n            entryList.forEach(callback);\n        },\n\n        /**\n         * Returns a reference to the entry with the given name or null if entry is inexistent\n         *\n         * @param entryName\n         * @return ZipEntry\n         */\n        getEntry: function (/*String*/ entryName) {\n            if (!loadedEntries) {\n                readEntries();\n            }\n            return entryTable[entryName] || null;\n        },\n\n        /**\n         * Adds the given entry to the entry list\n         *\n         * @param entry\n         */\n        setEntry: function (/*ZipEntry*/ entry) {\n            if (!loadedEntries) {\n                readEntries();\n            }\n            entryList.push(entry);\n            entryTable[entry.entryName] = entry;\n            mainHeader.totalEntries = entryList.length;\n        },\n\n        /**\n         * Removes the entry with the given name from the entry list.\n         *\n         * If the entry is a directory, then all nested files and directories will be removed\n         * @param entryName\n         */\n        deleteEntry: function (/*String*/ entryName) {\n            if (!loadedEntries) {\n                readEntries();\n            }\n            var entry = entryTable[entryName];\n            if (entry && entry.isDirectory) {\n                var _self = this;\n                this.getEntryChildren(entry).forEach(function (child) {\n                    if (child.entryName !== entryName) {\n                        _self.deleteEntry(child.entryName);\n                    }\n                });\n            }\n            entryList.splice(entryList.indexOf(entry), 1);\n            delete entryTable[entryName];\n            mainHeader.totalEntries = entryList.length;\n        },\n\n        /**\n         *  Iterates and returns all nested files and directories of the given entry\n         *\n         * @param entry\n         * @return Array\n         */\n        getEntryChildren: function (/*ZipEntry*/ entry) {\n            if (!loadedEntries) {\n                readEntries();\n            }\n            if (entry && entry.isDirectory) {\n                const list = [];\n                const name = entry.entryName;\n                const len = name.length;\n\n                entryList.forEach(function (zipEntry) {\n                    if (zipEntry.entryName.substr(0, len) === name) {\n                        list.push(zipEntry);\n                    }\n                });\n                return list;\n            }\n            return [];\n        },\n\n        /**\n         * Returns the zip file\n         *\n         * @return Buffer\n         */\n        compressToBuffer: function () {\n            if (!loadedEntries) {\n                readEntries();\n            }\n            sortEntries();\n\n            const dataBlock = [];\n            const entryHeaders = [];\n            let totalSize = 0;\n            let dindex = 0;\n\n            mainHeader.size = 0;\n            mainHeader.offset = 0;\n\n            for (const entry of entryList) {\n                // compress data and set local and entry header accordingly. Reason why is called first\n                const compressedData = entry.getCompressedData();\n                // 1. construct data header\n                entry.header.offset = dindex;\n                const dataHeader = entry.header.dataHeaderToBinary();\n                const entryNameLen = entry.rawEntryName.length;\n                // 1.2. postheader - data after data header\n                const postHeader = Buffer.alloc(entryNameLen + entry.extra.length);\n                entry.rawEntryName.copy(postHeader, 0);\n                postHeader.copy(entry.extra, entryNameLen);\n\n                // 2. offsets\n                const dataLength = dataHeader.length + postHeader.length + compressedData.length;\n                dindex += dataLength;\n\n                // 3. store values in sequence\n                dataBlock.push(dataHeader);\n                dataBlock.push(postHeader);\n                dataBlock.push(compressedData);\n\n                // 4. construct entry header\n                const entryHeader = entry.packHeader();\n                entryHeaders.push(entryHeader);\n                // 5. update main header\n                mainHeader.size += entryHeader.length;\n                totalSize += dataLength + entryHeader.length;\n            }\n\n            totalSize += mainHeader.mainHeaderSize; // also includes zip file comment length\n            // point to end of data and beginning of central directory first record\n            mainHeader.offset = dindex;\n\n            dindex = 0;\n            const outBuffer = Buffer.alloc(totalSize);\n            // write data blocks\n            for (const content of dataBlock) {\n                content.copy(outBuffer, dindex);\n                dindex += content.length;\n            }\n\n            // write central directory entries\n            for (const content of entryHeaders) {\n                content.copy(outBuffer, dindex);\n                dindex += content.length;\n            }\n\n            // write main header\n            const mh = mainHeader.toBinary();\n            if (_comment) {\n                _comment.copy(mh, Utils.Constants.ENDHDR); // add zip file comment\n            }\n            mh.copy(outBuffer, dindex);\n\n            return outBuffer;\n        },\n\n        toAsyncBuffer: function (/*Function*/ onSuccess, /*Function*/ onFail, /*Function*/ onItemStart, /*Function*/ onItemEnd) {\n            try {\n                if (!loadedEntries) {\n                    readEntries();\n                }\n                sortEntries();\n\n                const dataBlock = [];\n                const entryHeaders = [];\n                let totalSize = 0;\n                let dindex = 0;\n\n                mainHeader.size = 0;\n                mainHeader.offset = 0;\n\n                const compress2Buffer = function (entryLists) {\n                    if (entryLists.length) {\n                        const entry = entryLists.pop();\n                        const name = entry.entryName + entry.extra.toString();\n                        if (onItemStart) onItemStart(name);\n                        entry.getCompressedDataAsync(function (compressedData) {\n                            if (onItemEnd) onItemEnd(name);\n\n                            entry.header.offset = dindex;\n                            // data header\n                            const dataHeader = entry.header.dataHeaderToBinary();\n                            const postHeader = Buffer.alloc(name.length, name);\n                            const dataLength = dataHeader.length + postHeader.length + compressedData.length;\n\n                            dindex += dataLength;\n\n                            dataBlock.push(dataHeader);\n                            dataBlock.push(postHeader);\n                            dataBlock.push(compressedData);\n\n                            const entryHeader = entry.packHeader();\n                            entryHeaders.push(entryHeader);\n                            mainHeader.size += entryHeader.length;\n                            totalSize += dataLength + entryHeader.length;\n\n                            compress2Buffer(entryLists);\n                        });\n                    } else {\n                        totalSize += mainHeader.mainHeaderSize; // also includes zip file comment length\n                        // point to end of data and beginning of central directory first record\n                        mainHeader.offset = dindex;\n\n                        dindex = 0;\n                        const outBuffer = Buffer.alloc(totalSize);\n                        dataBlock.forEach(function (content) {\n                            content.copy(outBuffer, dindex); // write data blocks\n                            dindex += content.length;\n                        });\n                        entryHeaders.forEach(function (content) {\n                            content.copy(outBuffer, dindex); // write central directory entries\n                            dindex += content.length;\n                        });\n\n                        const mh = mainHeader.toBinary();\n                        if (_comment) {\n                            _comment.copy(mh, Utils.Constants.ENDHDR); // add zip file comment\n                        }\n\n                        mh.copy(outBuffer, dindex); // write main header\n\n                        onSuccess(outBuffer);\n                    }\n                };\n\n                compress2Buffer(entryList);\n            } catch (e) {\n                onFail(e);\n            }\n        }\n    };\n};\n","'use strict'\n\nconst { Buffer } = require('buffer')\nconst symbol = Symbol.for('BufferList')\n\nfunction BufferList (buf) {\n  if (!(this instanceof BufferList)) {\n    return new BufferList(buf)\n  }\n\n  BufferList._init.call(this, buf)\n}\n\nBufferList._init = function _init (buf) {\n  Object.defineProperty(this, symbol, { value: true })\n\n  this._bufs = []\n  this.length = 0\n\n  if (buf) {\n    this.append(buf)\n  }\n}\n\nBufferList.prototype._new = function _new (buf) {\n  return new BufferList(buf)\n}\n\nBufferList.prototype._offset = function _offset (offset) {\n  if (offset === 0) {\n    return [0, 0]\n  }\n\n  let tot = 0\n\n  for (let i = 0; i < this._bufs.length; i++) {\n    const _t = tot + this._bufs[i].length\n    if (offset < _t || i === this._bufs.length - 1) {\n      return [i, offset - tot]\n    }\n    tot = _t\n  }\n}\n\nBufferList.prototype._reverseOffset = function (blOffset) {\n  const bufferId = blOffset[0]\n  let offset = blOffset[1]\n\n  for (let i = 0; i < bufferId; i++) {\n    offset += this._bufs[i].length\n  }\n\n  return offset\n}\n\nBufferList.prototype.get = function get (index) {\n  if (index > this.length || index < 0) {\n    return undefined\n  }\n\n  const offset = this._offset(index)\n\n  return this._bufs[offset[0]][offset[1]]\n}\n\nBufferList.prototype.slice = function slice (start, end) {\n  if (typeof start === 'number' && start < 0) {\n    start += this.length\n  }\n\n  if (typeof end === 'number' && end < 0) {\n    end += this.length\n  }\n\n  return this.copy(null, 0, start, end)\n}\n\nBufferList.prototype.copy = function copy (dst, dstStart, srcStart, srcEnd) {\n  if (typeof srcStart !== 'number' || srcStart < 0) {\n    srcStart = 0\n  }\n\n  if (typeof srcEnd !== 'number' || srcEnd > this.length) {\n    srcEnd = this.length\n  }\n\n  if (srcStart >= this.length) {\n    return dst || Buffer.alloc(0)\n  }\n\n  if (srcEnd <= 0) {\n    return dst || Buffer.alloc(0)\n  }\n\n  const copy = !!dst\n  const off = this._offset(srcStart)\n  const len = srcEnd - srcStart\n  let bytes = len\n  let bufoff = (copy && dstStart) || 0\n  let start = off[1]\n\n  // copy/slice everything\n  if (srcStart === 0 && srcEnd === this.length) {\n    if (!copy) {\n      // slice, but full concat if multiple buffers\n      return this._bufs.length === 1\n        ? this._bufs[0]\n        : Buffer.concat(this._bufs, this.length)\n    }\n\n    // copy, need to copy individual buffers\n    for (let i = 0; i < this._bufs.length; i++) {\n      this._bufs[i].copy(dst, bufoff)\n      bufoff += this._bufs[i].length\n    }\n\n    return dst\n  }\n\n  // easy, cheap case where it's a subset of one of the buffers\n  if (bytes <= this._bufs[off[0]].length - start) {\n    return copy\n      ? this._bufs[off[0]].copy(dst, dstStart, start, start + bytes)\n      : this._bufs[off[0]].slice(start, start + bytes)\n  }\n\n  if (!copy) {\n    // a slice, we need something to copy in to\n    dst = Buffer.allocUnsafe(len)\n  }\n\n  for (let i = off[0]; i < this._bufs.length; i++) {\n    const l = this._bufs[i].length - start\n\n    if (bytes > l) {\n      this._bufs[i].copy(dst, bufoff, start)\n      bufoff += l\n    } else {\n      this._bufs[i].copy(dst, bufoff, start, start + bytes)\n      bufoff += l\n      break\n    }\n\n    bytes -= l\n\n    if (start) {\n      start = 0\n    }\n  }\n\n  // safeguard so that we don't return uninitialized memory\n  if (dst.length > bufoff) return dst.slice(0, bufoff)\n\n  return dst\n}\n\nBufferList.prototype.shallowSlice = function shallowSlice (start, end) {\n  start = start || 0\n  end = typeof end !== 'number' ? this.length : end\n\n  if (start < 0) {\n    start += this.length\n  }\n\n  if (end < 0) {\n    end += this.length\n  }\n\n  if (start === end) {\n    return this._new()\n  }\n\n  const startOffset = this._offset(start)\n  const endOffset = this._offset(end)\n  const buffers = this._bufs.slice(startOffset[0], endOffset[0] + 1)\n\n  if (endOffset[1] === 0) {\n    buffers.pop()\n  } else {\n    buffers[buffers.length - 1] = buffers[buffers.length - 1].slice(0, endOffset[1])\n  }\n\n  if (startOffset[1] !== 0) {\n    buffers[0] = buffers[0].slice(startOffset[1])\n  }\n\n  return this._new(buffers)\n}\n\nBufferList.prototype.toString = function toString (encoding, start, end) {\n  return this.slice(start, end).toString(encoding)\n}\n\nBufferList.prototype.consume = function consume (bytes) {\n  // first, normalize the argument, in accordance with how Buffer does it\n  bytes = Math.trunc(bytes)\n  // do nothing if not a positive number\n  if (Number.isNaN(bytes) || bytes <= 0) return this\n\n  while (this._bufs.length) {\n    if (bytes >= this._bufs[0].length) {\n      bytes -= this._bufs[0].length\n      this.length -= this._bufs[0].length\n      this._bufs.shift()\n    } else {\n      this._bufs[0] = this._bufs[0].slice(bytes)\n      this.length -= bytes\n      break\n    }\n  }\n\n  return this\n}\n\nBufferList.prototype.duplicate = function duplicate () {\n  const copy = this._new()\n\n  for (let i = 0; i < this._bufs.length; i++) {\n    copy.append(this._bufs[i])\n  }\n\n  return copy\n}\n\nBufferList.prototype.append = function append (buf) {\n  if (buf == null) {\n    return this\n  }\n\n  if (buf.buffer) {\n    // append a view of the underlying ArrayBuffer\n    this._appendBuffer(Buffer.from(buf.buffer, buf.byteOffset, buf.byteLength))\n  } else if (Array.isArray(buf)) {\n    for (let i = 0; i < buf.length; i++) {\n      this.append(buf[i])\n    }\n  } else if (this._isBufferList(buf)) {\n    // unwrap argument into individual BufferLists\n    for (let i = 0; i < buf._bufs.length; i++) {\n      this.append(buf._bufs[i])\n    }\n  } else {\n    // coerce number arguments to strings, since Buffer(number) does\n    // uninitialized memory allocation\n    if (typeof buf === 'number') {\n      buf = buf.toString()\n    }\n\n    this._appendBuffer(Buffer.from(buf))\n  }\n\n  return this\n}\n\nBufferList.prototype._appendBuffer = function appendBuffer (buf) {\n  this._bufs.push(buf)\n  this.length += buf.length\n}\n\nBufferList.prototype.indexOf = function (search, offset, encoding) {\n  if (encoding === undefined && typeof offset === 'string') {\n    encoding = offset\n    offset = undefined\n  }\n\n  if (typeof search === 'function' || Array.isArray(search)) {\n    throw new TypeError('The \"value\" argument must be one of type string, Buffer, BufferList, or Uint8Array.')\n  } else if (typeof search === 'number') {\n    search = Buffer.from([search])\n  } else if (typeof search === 'string') {\n    search = Buffer.from(search, encoding)\n  } else if (this._isBufferList(search)) {\n    search = search.slice()\n  } else if (Array.isArray(search.buffer)) {\n    search = Buffer.from(search.buffer, search.byteOffset, search.byteLength)\n  } else if (!Buffer.isBuffer(search)) {\n    search = Buffer.from(search)\n  }\n\n  offset = Number(offset || 0)\n\n  if (isNaN(offset)) {\n    offset = 0\n  }\n\n  if (offset < 0) {\n    offset = this.length + offset\n  }\n\n  if (offset < 0) {\n    offset = 0\n  }\n\n  if (search.length === 0) {\n    return offset > this.length ? this.length : offset\n  }\n\n  const blOffset = this._offset(offset)\n  let blIndex = blOffset[0] // index of which internal buffer we're working on\n  let buffOffset = blOffset[1] // offset of the internal buffer we're working on\n\n  // scan over each buffer\n  for (; blIndex < this._bufs.length; blIndex++) {\n    const buff = this._bufs[blIndex]\n\n    while (buffOffset < buff.length) {\n      const availableWindow = buff.length - buffOffset\n\n      if (availableWindow >= search.length) {\n        const nativeSearchResult = buff.indexOf(search, buffOffset)\n\n        if (nativeSearchResult !== -1) {\n          return this._reverseOffset([blIndex, nativeSearchResult])\n        }\n\n        buffOffset = buff.length - search.length + 1 // end of native search window\n      } else {\n        const revOffset = this._reverseOffset([blIndex, buffOffset])\n\n        if (this._match(revOffset, search)) {\n          return revOffset\n        }\n\n        buffOffset++\n      }\n    }\n\n    buffOffset = 0\n  }\n\n  return -1\n}\n\nBufferList.prototype._match = function (offset, search) {\n  if (this.length - offset < search.length) {\n    return false\n  }\n\n  for (let searchOffset = 0; searchOffset < search.length; searchOffset++) {\n    if (this.get(offset + searchOffset) !== search[searchOffset]) {\n      return false\n    }\n  }\n  return true\n}\n\n;(function () {\n  const methods = {\n    readDoubleBE: 8,\n    readDoubleLE: 8,\n    readFloatBE: 4,\n    readFloatLE: 4,\n    readInt32BE: 4,\n    readInt32LE: 4,\n    readUInt32BE: 4,\n    readUInt32LE: 4,\n    readInt16BE: 2,\n    readInt16LE: 2,\n    readUInt16BE: 2,\n    readUInt16LE: 2,\n    readInt8: 1,\n    readUInt8: 1,\n    readIntBE: null,\n    readIntLE: null,\n    readUIntBE: null,\n    readUIntLE: null\n  }\n\n  for (const m in methods) {\n    (function (m) {\n      if (methods[m] === null) {\n        BufferList.prototype[m] = function (offset, byteLength) {\n          return this.slice(offset, offset + byteLength)[m](0, byteLength)\n        }\n      } else {\n        BufferList.prototype[m] = function (offset = 0) {\n          return this.slice(offset, offset + methods[m])[m](0)\n        }\n      }\n    }(m))\n  }\n}())\n\n// Used internally by the class and also as an indicator of this object being\n// a `BufferList`. It's not possible to use `instanceof BufferList` in a browser\n// environment because there could be multiple different copies of the\n// BufferList class and some `BufferList`s might be `BufferList`s.\nBufferList.prototype._isBufferList = function _isBufferList (b) {\n  return b instanceof BufferList || BufferList.isBufferList(b)\n}\n\nBufferList.isBufferList = function isBufferList (b) {\n  return b != null && b[symbol]\n}\n\nmodule.exports = BufferList\n","'use strict'\n\nconst DuplexStream = require('readable-stream').Duplex\nconst inherits = require('inherits')\nconst BufferList = require('./BufferList')\n\nfunction BufferListStream (callback) {\n  if (!(this instanceof BufferListStream)) {\n    return new BufferListStream(callback)\n  }\n\n  if (typeof callback === 'function') {\n    this._callback = callback\n\n    const piper = function piper (err) {\n      if (this._callback) {\n        this._callback(err)\n        this._callback = null\n      }\n    }.bind(this)\n\n    this.on('pipe', function onPipe (src) {\n      src.on('error', piper)\n    })\n    this.on('unpipe', function onUnpipe (src) {\n      src.removeListener('error', piper)\n    })\n\n    callback = null\n  }\n\n  BufferList._init.call(this, callback)\n  DuplexStream.call(this)\n}\n\ninherits(BufferListStream, DuplexStream)\nObject.assign(BufferListStream.prototype, BufferList.prototype)\n\nBufferListStream.prototype._new = function _new (callback) {\n  return new BufferListStream(callback)\n}\n\nBufferListStream.prototype._write = function _write (buf, encoding, callback) {\n  this._appendBuffer(buf)\n\n  if (typeof callback === 'function') {\n    callback()\n  }\n}\n\nBufferListStream.prototype._read = function _read (size) {\n  if (!this.length) {\n    return this.push(null)\n  }\n\n  size = Math.min(size, this.length)\n  this.push(this.slice(0, size))\n  this.consume(size)\n}\n\nBufferListStream.prototype.end = function end (chunk) {\n  DuplexStream.prototype.end.call(this, chunk)\n\n  if (this._callback) {\n    this._callback(null, this.slice())\n    this._callback = null\n  }\n}\n\nBufferListStream.prototype._destroy = function _destroy (err, cb) {\n  this._bufs.length = 0\n  this.length = 0\n  cb(err)\n}\n\nBufferListStream.prototype._isBufferList = function _isBufferList (b) {\n  return b instanceof BufferListStream || b instanceof BufferList || BufferListStream.isBufferList(b)\n}\n\nBufferListStream.isBufferList = BufferList.isBufferList\n\nmodule.exports = BufferListStream\nmodule.exports.BufferListStream = BufferListStream\nmodule.exports.BufferList = BufferList\n","try {\n  var util = require('util');\n  /* istanbul ignore next */\n  if (typeof util.inherits !== 'function') throw '';\n  module.exports = util.inherits;\n} catch (e) {\n  /* istanbul ignore next */\n  module.exports = require('./inherits_browser.js');\n}\n","if (typeof Object.create === 'function') {\n  // implementation from standard node.js 'util' module\n  module.exports = function inherits(ctor, superCtor) {\n    if (superCtor) {\n      ctor.super_ = superCtor\n      ctor.prototype = Object.create(superCtor.prototype, {\n        constructor: {\n          value: ctor,\n          enumerable: false,\n          writable: true,\n          configurable: true\n        }\n      })\n    }\n  };\n} else {\n  // old school shim for old browsers\n  module.exports = function inherits(ctor, superCtor) {\n    if (superCtor) {\n      ctor.super_ = superCtor\n      var TempCtor = function () {}\n      TempCtor.prototype = superCtor.prototype\n      ctor.prototype = new TempCtor()\n      ctor.prototype.constructor = ctor\n    }\n  }\n}\n","'use strict';\n\nconst codes = {};\n\nfunction createErrorType(code, message, Base) {\n  if (!Base) {\n    Base = Error\n  }\n\n  function getMessage (arg1, arg2, arg3) {\n    if (typeof message === 'string') {\n      return message\n    } else {\n      return message(arg1, arg2, arg3)\n    }\n  }\n\n  class NodeError extends Base {\n    constructor (arg1, arg2, arg3) {\n      super(getMessage(arg1, arg2, arg3));\n    }\n  }\n\n  NodeError.prototype.name = Base.name;\n  NodeError.prototype.code = code;\n\n  codes[code] = NodeError;\n}\n\n// https://github.com/nodejs/node/blob/v10.8.0/lib/internal/errors.js\nfunction oneOf(expected, thing) {\n  if (Array.isArray(expected)) {\n    const len = expected.length;\n    expected = expected.map((i) => String(i));\n    if (len > 2) {\n      return `one of ${thing} ${expected.slice(0, len - 1).join(', ')}, or ` +\n             expected[len - 1];\n    } else if (len === 2) {\n      return `one of ${thing} ${expected[0]} or ${expected[1]}`;\n    } else {\n      return `of ${thing} ${expected[0]}`;\n    }\n  } else {\n    return `of ${thing} ${String(expected)}`;\n  }\n}\n\n// https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String/startsWith\nfunction startsWith(str, search, pos) {\n\treturn str.substr(!pos || pos < 0 ? 0 : +pos, search.length) === search;\n}\n\n// https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String/endsWith\nfunction endsWith(str, search, this_len) {\n\tif (this_len === undefined || this_len > str.length) {\n\t\tthis_len = str.length;\n\t}\n\treturn str.substring(this_len - search.length, this_len) === search;\n}\n\n// https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String/includes\nfunction includes(str, search, start) {\n  if (typeof start !== 'number') {\n    start = 0;\n  }\n\n  if (start + search.length > str.length) {\n    return false;\n  } else {\n    return str.indexOf(search, start) !== -1;\n  }\n}\n\ncreateErrorType('ERR_INVALID_OPT_VALUE', function (name, value) {\n  return 'The value \"' + value + '\" is invalid for option \"' + name + '\"'\n}, TypeError);\ncreateErrorType('ERR_INVALID_ARG_TYPE', function (name, expected, actual) {\n  // determiner: 'must be' or 'must not be'\n  let determiner;\n  if (typeof expected === 'string' && startsWith(expected, 'not ')) {\n    determiner = 'must not be';\n    expected = expected.replace(/^not /, '');\n  } else {\n    determiner = 'must be';\n  }\n\n  let msg;\n  if (endsWith(name, ' argument')) {\n    // For cases like 'first argument'\n    msg = `The ${name} ${determiner} ${oneOf(expected, 'type')}`;\n  } else {\n    const type = includes(name, '.') ? 'property' : 'argument';\n    msg = `The \"${name}\" ${type} ${determiner} ${oneOf(expected, 'type')}`;\n  }\n\n  msg += `. Received type ${typeof actual}`;\n  return msg;\n}, TypeError);\ncreateErrorType('ERR_STREAM_PUSH_AFTER_EOF', 'stream.push() after EOF');\ncreateErrorType('ERR_METHOD_NOT_IMPLEMENTED', function (name) {\n  return 'The ' + name + ' method is not implemented'\n});\ncreateErrorType('ERR_STREAM_PREMATURE_CLOSE', 'Premature close');\ncreateErrorType('ERR_STREAM_DESTROYED', function (name) {\n  return 'Cannot call ' + name + ' after a stream was destroyed';\n});\ncreateErrorType('ERR_MULTIPLE_CALLBACK', 'Callback called multiple times');\ncreateErrorType('ERR_STREAM_CANNOT_PIPE', 'Cannot pipe, not readable');\ncreateErrorType('ERR_STREAM_WRITE_AFTER_END', 'write after end');\ncreateErrorType('ERR_STREAM_NULL_VALUES', 'May not write null values to stream', TypeError);\ncreateErrorType('ERR_UNKNOWN_ENCODING', function (arg) {\n  return 'Unknown encoding: ' + arg\n}, TypeError);\ncreateErrorType('ERR_STREAM_UNSHIFT_AFTER_END_EVENT', 'stream.unshift() after end event');\n\nmodule.exports.codes = codes;\n","// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n// a duplex stream is just a stream that is both readable and writable.\n// Since JS doesn't have multiple prototypal inheritance, this class\n// prototypally inherits from Readable, and then parasitically from\n// Writable.\n'use strict';\n/*<replacement>*/\n\nvar objectKeys = Object.keys || function (obj) {\n  var keys = [];\n\n  for (var key in obj) {\n    keys.push(key);\n  }\n\n  return keys;\n};\n/*</replacement>*/\n\n\nmodule.exports = Duplex;\n\nvar Readable = require('./_stream_readable');\n\nvar Writable = require('./_stream_writable');\n\nrequire('inherits')(Duplex, Readable);\n\n{\n  // Allow the keys array to be GC'ed.\n  var keys = objectKeys(Writable.prototype);\n\n  for (var v = 0; v < keys.length; v++) {\n    var method = keys[v];\n    if (!Duplex.prototype[method]) Duplex.prototype[method] = Writable.prototype[method];\n  }\n}\n\nfunction Duplex(options) {\n  if (!(this instanceof Duplex)) return new Duplex(options);\n  Readable.call(this, options);\n  Writable.call(this, options);\n  this.allowHalfOpen = true;\n\n  if (options) {\n    if (options.readable === false) this.readable = false;\n    if (options.writable === false) this.writable = false;\n\n    if (options.allowHalfOpen === false) {\n      this.allowHalfOpen = false;\n      this.once('end', onend);\n    }\n  }\n}\n\nObject.defineProperty(Duplex.prototype, 'writableHighWaterMark', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    return this._writableState.highWaterMark;\n  }\n});\nObject.defineProperty(Duplex.prototype, 'writableBuffer', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    return this._writableState && this._writableState.getBuffer();\n  }\n});\nObject.defineProperty(Duplex.prototype, 'writableLength', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    return this._writableState.length;\n  }\n}); // the no-half-open enforcer\n\nfunction onend() {\n  // If the writable side ended, then we're ok.\n  if (this._writableState.ended) return; // no more data can be written.\n  // But allow more writes to happen in this tick.\n\n  process.nextTick(onEndNT, this);\n}\n\nfunction onEndNT(self) {\n  self.end();\n}\n\nObject.defineProperty(Duplex.prototype, 'destroyed', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    if (this._readableState === undefined || this._writableState === undefined) {\n      return false;\n    }\n\n    return this._readableState.destroyed && this._writableState.destroyed;\n  },\n  set: function set(value) {\n    // we ignore the value if the stream\n    // has not been initialized yet\n    if (this._readableState === undefined || this._writableState === undefined) {\n      return;\n    } // backward compatibility, the user is explicitly\n    // managing destroyed\n\n\n    this._readableState.destroyed = value;\n    this._writableState.destroyed = value;\n  }\n});","// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n// a passthrough stream.\n// basically just the most minimal sort of Transform stream.\n// Every written chunk gets output as-is.\n'use strict';\n\nmodule.exports = PassThrough;\n\nvar Transform = require('./_stream_transform');\n\nrequire('inherits')(PassThrough, Transform);\n\nfunction PassThrough(options) {\n  if (!(this instanceof PassThrough)) return new PassThrough(options);\n  Transform.call(this, options);\n}\n\nPassThrough.prototype._transform = function (chunk, encoding, cb) {\n  cb(null, chunk);\n};","// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n'use strict';\n\nmodule.exports = Readable;\n/*<replacement>*/\n\nvar Duplex;\n/*</replacement>*/\n\nReadable.ReadableState = ReadableState;\n/*<replacement>*/\n\nvar EE = require('events').EventEmitter;\n\nvar EElistenerCount = function EElistenerCount(emitter, type) {\n  return emitter.listeners(type).length;\n};\n/*</replacement>*/\n\n/*<replacement>*/\n\n\nvar Stream = require('./internal/streams/stream');\n/*</replacement>*/\n\n\nvar Buffer = require('buffer').Buffer;\n\nvar OurUint8Array = global.Uint8Array || function () {};\n\nfunction _uint8ArrayToBuffer(chunk) {\n  return Buffer.from(chunk);\n}\n\nfunction _isUint8Array(obj) {\n  return Buffer.isBuffer(obj) || obj instanceof OurUint8Array;\n}\n/*<replacement>*/\n\n\nvar debugUtil = require('util');\n\nvar debug;\n\nif (debugUtil && debugUtil.debuglog) {\n  debug = debugUtil.debuglog('stream');\n} else {\n  debug = function debug() {};\n}\n/*</replacement>*/\n\n\nvar BufferList = require('./internal/streams/buffer_list');\n\nvar destroyImpl = require('./internal/streams/destroy');\n\nvar _require = require('./internal/streams/state'),\n    getHighWaterMark = _require.getHighWaterMark;\n\nvar _require$codes = require('../errors').codes,\n    ERR_INVALID_ARG_TYPE = _require$codes.ERR_INVALID_ARG_TYPE,\n    ERR_STREAM_PUSH_AFTER_EOF = _require$codes.ERR_STREAM_PUSH_AFTER_EOF,\n    ERR_METHOD_NOT_IMPLEMENTED = _require$codes.ERR_METHOD_NOT_IMPLEMENTED,\n    ERR_STREAM_UNSHIFT_AFTER_END_EVENT = _require$codes.ERR_STREAM_UNSHIFT_AFTER_END_EVENT; // Lazy loaded to improve the startup performance.\n\n\nvar StringDecoder;\nvar createReadableStreamAsyncIterator;\nvar from;\n\nrequire('inherits')(Readable, Stream);\n\nvar errorOrDestroy = destroyImpl.errorOrDestroy;\nvar kProxyEvents = ['error', 'close', 'destroy', 'pause', 'resume'];\n\nfunction prependListener(emitter, event, fn) {\n  // Sadly this is not cacheable as some libraries bundle their own\n  // event emitter implementation with them.\n  if (typeof emitter.prependListener === 'function') return emitter.prependListener(event, fn); // This is a hack to make sure that our error handler is attached before any\n  // userland ones.  NEVER DO THIS. This is here only because this code needs\n  // to continue to work with older versions of Node.js that do not include\n  // the prependListener() method. The goal is to eventually remove this hack.\n\n  if (!emitter._events || !emitter._events[event]) emitter.on(event, fn);else if (Array.isArray(emitter._events[event])) emitter._events[event].unshift(fn);else emitter._events[event] = [fn, emitter._events[event]];\n}\n\nfunction ReadableState(options, stream, isDuplex) {\n  Duplex = Duplex || require('./_stream_duplex');\n  options = options || {}; // Duplex streams are both readable and writable, but share\n  // the same options object.\n  // However, some cases require setting options to different\n  // values for the readable and the writable sides of the duplex stream.\n  // These options can be provided separately as readableXXX and writableXXX.\n\n  if (typeof isDuplex !== 'boolean') isDuplex = stream instanceof Duplex; // object stream flag. Used to make read(n) ignore n and to\n  // make all the buffer merging and length checks go away\n\n  this.objectMode = !!options.objectMode;\n  if (isDuplex) this.objectMode = this.objectMode || !!options.readableObjectMode; // the point at which it stops calling _read() to fill the buffer\n  // Note: 0 is a valid value, means \"don't call _read preemptively ever\"\n\n  this.highWaterMark = getHighWaterMark(this, options, 'readableHighWaterMark', isDuplex); // A linked list is used to store data chunks instead of an array because the\n  // linked list can remove elements from the beginning faster than\n  // array.shift()\n\n  this.buffer = new BufferList();\n  this.length = 0;\n  this.pipes = null;\n  this.pipesCount = 0;\n  this.flowing = null;\n  this.ended = false;\n  this.endEmitted = false;\n  this.reading = false; // a flag to be able to tell if the event 'readable'/'data' is emitted\n  // immediately, or on a later tick.  We set this to true at first, because\n  // any actions that shouldn't happen until \"later\" should generally also\n  // not happen before the first read call.\n\n  this.sync = true; // whenever we return null, then we set a flag to say\n  // that we're awaiting a 'readable' event emission.\n\n  this.needReadable = false;\n  this.emittedReadable = false;\n  this.readableListening = false;\n  this.resumeScheduled = false;\n  this.paused = true; // Should close be emitted on destroy. Defaults to true.\n\n  this.emitClose = options.emitClose !== false; // Should .destroy() be called after 'end' (and potentially 'finish')\n\n  this.autoDestroy = !!options.autoDestroy; // has it been destroyed\n\n  this.destroyed = false; // Crypto is kind of old and crusty.  Historically, its default string\n  // encoding is 'binary' so we have to make this configurable.\n  // Everything else in the universe uses 'utf8', though.\n\n  this.defaultEncoding = options.defaultEncoding || 'utf8'; // the number of writers that are awaiting a drain event in .pipe()s\n\n  this.awaitDrain = 0; // if true, a maybeReadMore has been scheduled\n\n  this.readingMore = false;\n  this.decoder = null;\n  this.encoding = null;\n\n  if (options.encoding) {\n    if (!StringDecoder) StringDecoder = require('string_decoder/').StringDecoder;\n    this.decoder = new StringDecoder(options.encoding);\n    this.encoding = options.encoding;\n  }\n}\n\nfunction Readable(options) {\n  Duplex = Duplex || require('./_stream_duplex');\n  if (!(this instanceof Readable)) return new Readable(options); // Checking for a Stream.Duplex instance is faster here instead of inside\n  // the ReadableState constructor, at least with V8 6.5\n\n  var isDuplex = this instanceof Duplex;\n  this._readableState = new ReadableState(options, this, isDuplex); // legacy\n\n  this.readable = true;\n\n  if (options) {\n    if (typeof options.read === 'function') this._read = options.read;\n    if (typeof options.destroy === 'function') this._destroy = options.destroy;\n  }\n\n  Stream.call(this);\n}\n\nObject.defineProperty(Readable.prototype, 'destroyed', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    if (this._readableState === undefined) {\n      return false;\n    }\n\n    return this._readableState.destroyed;\n  },\n  set: function set(value) {\n    // we ignore the value if the stream\n    // has not been initialized yet\n    if (!this._readableState) {\n      return;\n    } // backward compatibility, the user is explicitly\n    // managing destroyed\n\n\n    this._readableState.destroyed = value;\n  }\n});\nReadable.prototype.destroy = destroyImpl.destroy;\nReadable.prototype._undestroy = destroyImpl.undestroy;\n\nReadable.prototype._destroy = function (err, cb) {\n  cb(err);\n}; // Manually shove something into the read() buffer.\n// This returns true if the highWaterMark has not been hit yet,\n// similar to how Writable.write() returns true if you should\n// write() some more.\n\n\nReadable.prototype.push = function (chunk, encoding) {\n  var state = this._readableState;\n  var skipChunkCheck;\n\n  if (!state.objectMode) {\n    if (typeof chunk === 'string') {\n      encoding = encoding || state.defaultEncoding;\n\n      if (encoding !== state.encoding) {\n        chunk = Buffer.from(chunk, encoding);\n        encoding = '';\n      }\n\n      skipChunkCheck = true;\n    }\n  } else {\n    skipChunkCheck = true;\n  }\n\n  return readableAddChunk(this, chunk, encoding, false, skipChunkCheck);\n}; // Unshift should *always* be something directly out of read()\n\n\nReadable.prototype.unshift = function (chunk) {\n  return readableAddChunk(this, chunk, null, true, false);\n};\n\nfunction readableAddChunk(stream, chunk, encoding, addToFront, skipChunkCheck) {\n  debug('readableAddChunk', chunk);\n  var state = stream._readableState;\n\n  if (chunk === null) {\n    state.reading = false;\n    onEofChunk(stream, state);\n  } else {\n    var er;\n    if (!skipChunkCheck) er = chunkInvalid(state, chunk);\n\n    if (er) {\n      errorOrDestroy(stream, er);\n    } else if (state.objectMode || chunk && chunk.length > 0) {\n      if (typeof chunk !== 'string' && !state.objectMode && Object.getPrototypeOf(chunk) !== Buffer.prototype) {\n        chunk = _uint8ArrayToBuffer(chunk);\n      }\n\n      if (addToFront) {\n        if (state.endEmitted) errorOrDestroy(stream, new ERR_STREAM_UNSHIFT_AFTER_END_EVENT());else addChunk(stream, state, chunk, true);\n      } else if (state.ended) {\n        errorOrDestroy(stream, new ERR_STREAM_PUSH_AFTER_EOF());\n      } else if (state.destroyed) {\n        return false;\n      } else {\n        state.reading = false;\n\n        if (state.decoder && !encoding) {\n          chunk = state.decoder.write(chunk);\n          if (state.objectMode || chunk.length !== 0) addChunk(stream, state, chunk, false);else maybeReadMore(stream, state);\n        } else {\n          addChunk(stream, state, chunk, false);\n        }\n      }\n    } else if (!addToFront) {\n      state.reading = false;\n      maybeReadMore(stream, state);\n    }\n  } // We can push more data if we are below the highWaterMark.\n  // Also, if we have no data yet, we can stand some more bytes.\n  // This is to work around cases where hwm=0, such as the repl.\n\n\n  return !state.ended && (state.length < state.highWaterMark || state.length === 0);\n}\n\nfunction addChunk(stream, state, chunk, addToFront) {\n  if (state.flowing && state.length === 0 && !state.sync) {\n    state.awaitDrain = 0;\n    stream.emit('data', chunk);\n  } else {\n    // update the buffer info.\n    state.length += state.objectMode ? 1 : chunk.length;\n    if (addToFront) state.buffer.unshift(chunk);else state.buffer.push(chunk);\n    if (state.needReadable) emitReadable(stream);\n  }\n\n  maybeReadMore(stream, state);\n}\n\nfunction chunkInvalid(state, chunk) {\n  var er;\n\n  if (!_isUint8Array(chunk) && typeof chunk !== 'string' && chunk !== undefined && !state.objectMode) {\n    er = new ERR_INVALID_ARG_TYPE('chunk', ['string', 'Buffer', 'Uint8Array'], chunk);\n  }\n\n  return er;\n}\n\nReadable.prototype.isPaused = function () {\n  return this._readableState.flowing === false;\n}; // backwards compatibility.\n\n\nReadable.prototype.setEncoding = function (enc) {\n  if (!StringDecoder) StringDecoder = require('string_decoder/').StringDecoder;\n  var decoder = new StringDecoder(enc);\n  this._readableState.decoder = decoder; // If setEncoding(null), decoder.encoding equals utf8\n\n  this._readableState.encoding = this._readableState.decoder.encoding; // Iterate over current buffer to convert already stored Buffers:\n\n  var p = this._readableState.buffer.head;\n  var content = '';\n\n  while (p !== null) {\n    content += decoder.write(p.data);\n    p = p.next;\n  }\n\n  this._readableState.buffer.clear();\n\n  if (content !== '') this._readableState.buffer.push(content);\n  this._readableState.length = content.length;\n  return this;\n}; // Don't raise the hwm > 1GB\n\n\nvar MAX_HWM = 0x40000000;\n\nfunction computeNewHighWaterMark(n) {\n  if (n >= MAX_HWM) {\n    // TODO(ronag): Throw ERR_VALUE_OUT_OF_RANGE.\n    n = MAX_HWM;\n  } else {\n    // Get the next highest power of 2 to prevent increasing hwm excessively in\n    // tiny amounts\n    n--;\n    n |= n >>> 1;\n    n |= n >>> 2;\n    n |= n >>> 4;\n    n |= n >>> 8;\n    n |= n >>> 16;\n    n++;\n  }\n\n  return n;\n} // This function is designed to be inlinable, so please take care when making\n// changes to the function body.\n\n\nfunction howMuchToRead(n, state) {\n  if (n <= 0 || state.length === 0 && state.ended) return 0;\n  if (state.objectMode) return 1;\n\n  if (n !== n) {\n    // Only flow one buffer at a time\n    if (state.flowing && state.length) return state.buffer.head.data.length;else return state.length;\n  } // If we're asking for more than the current hwm, then raise the hwm.\n\n\n  if (n > state.highWaterMark) state.highWaterMark = computeNewHighWaterMark(n);\n  if (n <= state.length) return n; // Don't have enough\n\n  if (!state.ended) {\n    state.needReadable = true;\n    return 0;\n  }\n\n  return state.length;\n} // you can override either this method, or the async _read(n) below.\n\n\nReadable.prototype.read = function (n) {\n  debug('read', n);\n  n = parseInt(n, 10);\n  var state = this._readableState;\n  var nOrig = n;\n  if (n !== 0) state.emittedReadable = false; // if we're doing read(0) to trigger a readable event, but we\n  // already have a bunch of data in the buffer, then just trigger\n  // the 'readable' event and move on.\n\n  if (n === 0 && state.needReadable && ((state.highWaterMark !== 0 ? state.length >= state.highWaterMark : state.length > 0) || state.ended)) {\n    debug('read: emitReadable', state.length, state.ended);\n    if (state.length === 0 && state.ended) endReadable(this);else emitReadable(this);\n    return null;\n  }\n\n  n = howMuchToRead(n, state); // if we've ended, and we're now clear, then finish it up.\n\n  if (n === 0 && state.ended) {\n    if (state.length === 0) endReadable(this);\n    return null;\n  } // All the actual chunk generation logic needs to be\n  // *below* the call to _read.  The reason is that in certain\n  // synthetic stream cases, such as passthrough streams, _read\n  // may be a completely synchronous operation which may change\n  // the state of the read buffer, providing enough data when\n  // before there was *not* enough.\n  //\n  // So, the steps are:\n  // 1. Figure out what the state of things will be after we do\n  // a read from the buffer.\n  //\n  // 2. If that resulting state will trigger a _read, then call _read.\n  // Note that this may be asynchronous, or synchronous.  Yes, it is\n  // deeply ugly to write APIs this way, but that still doesn't mean\n  // that the Readable class should behave improperly, as streams are\n  // designed to be sync/async agnostic.\n  // Take note if the _read call is sync or async (ie, if the read call\n  // has returned yet), so that we know whether or not it's safe to emit\n  // 'readable' etc.\n  //\n  // 3. Actually pull the requested chunks out of the buffer and return.\n  // if we need a readable event, then we need to do some reading.\n\n\n  var doRead = state.needReadable;\n  debug('need readable', doRead); // if we currently have less than the highWaterMark, then also read some\n\n  if (state.length === 0 || state.length - n < state.highWaterMark) {\n    doRead = true;\n    debug('length less than watermark', doRead);\n  } // however, if we've ended, then there's no point, and if we're already\n  // reading, then it's unnecessary.\n\n\n  if (state.ended || state.reading) {\n    doRead = false;\n    debug('reading or ended', doRead);\n  } else if (doRead) {\n    debug('do read');\n    state.reading = true;\n    state.sync = true; // if the length is currently zero, then we *need* a readable event.\n\n    if (state.length === 0) state.needReadable = true; // call internal read method\n\n    this._read(state.highWaterMark);\n\n    state.sync = false; // If _read pushed data synchronously, then `reading` will be false,\n    // and we need to re-evaluate how much data we can return to the user.\n\n    if (!state.reading) n = howMuchToRead(nOrig, state);\n  }\n\n  var ret;\n  if (n > 0) ret = fromList(n, state);else ret = null;\n\n  if (ret === null) {\n    state.needReadable = state.length <= state.highWaterMark;\n    n = 0;\n  } else {\n    state.length -= n;\n    state.awaitDrain = 0;\n  }\n\n  if (state.length === 0) {\n    // If we have nothing in the buffer, then we want to know\n    // as soon as we *do* get something into the buffer.\n    if (!state.ended) state.needReadable = true; // If we tried to read() past the EOF, then emit end on the next tick.\n\n    if (nOrig !== n && state.ended) endReadable(this);\n  }\n\n  if (ret !== null) this.emit('data', ret);\n  return ret;\n};\n\nfunction onEofChunk(stream, state) {\n  debug('onEofChunk');\n  if (state.ended) return;\n\n  if (state.decoder) {\n    var chunk = state.decoder.end();\n\n    if (chunk && chunk.length) {\n      state.buffer.push(chunk);\n      state.length += state.objectMode ? 1 : chunk.length;\n    }\n  }\n\n  state.ended = true;\n\n  if (state.sync) {\n    // if we are sync, wait until next tick to emit the data.\n    // Otherwise we risk emitting data in the flow()\n    // the readable code triggers during a read() call\n    emitReadable(stream);\n  } else {\n    // emit 'readable' now to make sure it gets picked up.\n    state.needReadable = false;\n\n    if (!state.emittedReadable) {\n      state.emittedReadable = true;\n      emitReadable_(stream);\n    }\n  }\n} // Don't emit readable right away in sync mode, because this can trigger\n// another read() call => stack overflow.  This way, it might trigger\n// a nextTick recursion warning, but that's not so bad.\n\n\nfunction emitReadable(stream) {\n  var state = stream._readableState;\n  debug('emitReadable', state.needReadable, state.emittedReadable);\n  state.needReadable = false;\n\n  if (!state.emittedReadable) {\n    debug('emitReadable', state.flowing);\n    state.emittedReadable = true;\n    process.nextTick(emitReadable_, stream);\n  }\n}\n\nfunction emitReadable_(stream) {\n  var state = stream._readableState;\n  debug('emitReadable_', state.destroyed, state.length, state.ended);\n\n  if (!state.destroyed && (state.length || state.ended)) {\n    stream.emit('readable');\n    state.emittedReadable = false;\n  } // The stream needs another readable event if\n  // 1. It is not flowing, as the flow mechanism will take\n  //    care of it.\n  // 2. It is not ended.\n  // 3. It is below the highWaterMark, so we can schedule\n  //    another readable later.\n\n\n  state.needReadable = !state.flowing && !state.ended && state.length <= state.highWaterMark;\n  flow(stream);\n} // at this point, the user has presumably seen the 'readable' event,\n// and called read() to consume some data.  that may have triggered\n// in turn another _read(n) call, in which case reading = true if\n// it's in progress.\n// However, if we're not ended, or reading, and the length < hwm,\n// then go ahead and try to read some more preemptively.\n\n\nfunction maybeReadMore(stream, state) {\n  if (!state.readingMore) {\n    state.readingMore = true;\n    process.nextTick(maybeReadMore_, stream, state);\n  }\n}\n\nfunction maybeReadMore_(stream, state) {\n  // Attempt to read more data if we should.\n  //\n  // The conditions for reading more data are (one of):\n  // - Not enough data buffered (state.length < state.highWaterMark). The loop\n  //   is responsible for filling the buffer with enough data if such data\n  //   is available. If highWaterMark is 0 and we are not in the flowing mode\n  //   we should _not_ attempt to buffer any extra data. We'll get more data\n  //   when the stream consumer calls read() instead.\n  // - No data in the buffer, and the stream is in flowing mode. In this mode\n  //   the loop below is responsible for ensuring read() is called. Failing to\n  //   call read here would abort the flow and there's no other mechanism for\n  //   continuing the flow if the stream consumer has just subscribed to the\n  //   'data' event.\n  //\n  // In addition to the above conditions to keep reading data, the following\n  // conditions prevent the data from being read:\n  // - The stream has ended (state.ended).\n  // - There is already a pending 'read' operation (state.reading). This is a\n  //   case where the the stream has called the implementation defined _read()\n  //   method, but they are processing the call asynchronously and have _not_\n  //   called push() with new data. In this case we skip performing more\n  //   read()s. The execution ends in this method again after the _read() ends\n  //   up calling push() with more data.\n  while (!state.reading && !state.ended && (state.length < state.highWaterMark || state.flowing && state.length === 0)) {\n    var len = state.length;\n    debug('maybeReadMore read 0');\n    stream.read(0);\n    if (len === state.length) // didn't get any data, stop spinning.\n      break;\n  }\n\n  state.readingMore = false;\n} // abstract method.  to be overridden in specific implementation classes.\n// call cb(er, data) where data is <= n in length.\n// for virtual (non-string, non-buffer) streams, \"length\" is somewhat\n// arbitrary, and perhaps not very meaningful.\n\n\nReadable.prototype._read = function (n) {\n  errorOrDestroy(this, new ERR_METHOD_NOT_IMPLEMENTED('_read()'));\n};\n\nReadable.prototype.pipe = function (dest, pipeOpts) {\n  var src = this;\n  var state = this._readableState;\n\n  switch (state.pipesCount) {\n    case 0:\n      state.pipes = dest;\n      break;\n\n    case 1:\n      state.pipes = [state.pipes, dest];\n      break;\n\n    default:\n      state.pipes.push(dest);\n      break;\n  }\n\n  state.pipesCount += 1;\n  debug('pipe count=%d opts=%j', state.pipesCount, pipeOpts);\n  var doEnd = (!pipeOpts || pipeOpts.end !== false) && dest !== process.stdout && dest !== process.stderr;\n  var endFn = doEnd ? onend : unpipe;\n  if (state.endEmitted) process.nextTick(endFn);else src.once('end', endFn);\n  dest.on('unpipe', onunpipe);\n\n  function onunpipe(readable, unpipeInfo) {\n    debug('onunpipe');\n\n    if (readable === src) {\n      if (unpipeInfo && unpipeInfo.hasUnpiped === false) {\n        unpipeInfo.hasUnpiped = true;\n        cleanup();\n      }\n    }\n  }\n\n  function onend() {\n    debug('onend');\n    dest.end();\n  } // when the dest drains, it reduces the awaitDrain counter\n  // on the source.  This would be more elegant with a .once()\n  // handler in flow(), but adding and removing repeatedly is\n  // too slow.\n\n\n  var ondrain = pipeOnDrain(src);\n  dest.on('drain', ondrain);\n  var cleanedUp = false;\n\n  function cleanup() {\n    debug('cleanup'); // cleanup event handlers once the pipe is broken\n\n    dest.removeListener('close', onclose);\n    dest.removeListener('finish', onfinish);\n    dest.removeListener('drain', ondrain);\n    dest.removeListener('error', onerror);\n    dest.removeListener('unpipe', onunpipe);\n    src.removeListener('end', onend);\n    src.removeListener('end', unpipe);\n    src.removeListener('data', ondata);\n    cleanedUp = true; // if the reader is waiting for a drain event from this\n    // specific writer, then it would cause it to never start\n    // flowing again.\n    // So, if this is awaiting a drain, then we just call it now.\n    // If we don't know, then assume that we are waiting for one.\n\n    if (state.awaitDrain && (!dest._writableState || dest._writableState.needDrain)) ondrain();\n  }\n\n  src.on('data', ondata);\n\n  function ondata(chunk) {\n    debug('ondata');\n    var ret = dest.write(chunk);\n    debug('dest.write', ret);\n\n    if (ret === false) {\n      // If the user unpiped during `dest.write()`, it is possible\n      // to get stuck in a permanently paused state if that write\n      // also returned false.\n      // => Check whether `dest` is still a piping destination.\n      if ((state.pipesCount === 1 && state.pipes === dest || state.pipesCount > 1 && indexOf(state.pipes, dest) !== -1) && !cleanedUp) {\n        debug('false write response, pause', state.awaitDrain);\n        state.awaitDrain++;\n      }\n\n      src.pause();\n    }\n  } // if the dest has an error, then stop piping into it.\n  // however, don't suppress the throwing behavior for this.\n\n\n  function onerror(er) {\n    debug('onerror', er);\n    unpipe();\n    dest.removeListener('error', onerror);\n    if (EElistenerCount(dest, 'error') === 0) errorOrDestroy(dest, er);\n  } // Make sure our error handler is attached before userland ones.\n\n\n  prependListener(dest, 'error', onerror); // Both close and finish should trigger unpipe, but only once.\n\n  function onclose() {\n    dest.removeListener('finish', onfinish);\n    unpipe();\n  }\n\n  dest.once('close', onclose);\n\n  function onfinish() {\n    debug('onfinish');\n    dest.removeListener('close', onclose);\n    unpipe();\n  }\n\n  dest.once('finish', onfinish);\n\n  function unpipe() {\n    debug('unpipe');\n    src.unpipe(dest);\n  } // tell the dest that it's being piped to\n\n\n  dest.emit('pipe', src); // start the flow if it hasn't been started already.\n\n  if (!state.flowing) {\n    debug('pipe resume');\n    src.resume();\n  }\n\n  return dest;\n};\n\nfunction pipeOnDrain(src) {\n  return function pipeOnDrainFunctionResult() {\n    var state = src._readableState;\n    debug('pipeOnDrain', state.awaitDrain);\n    if (state.awaitDrain) state.awaitDrain--;\n\n    if (state.awaitDrain === 0 && EElistenerCount(src, 'data')) {\n      state.flowing = true;\n      flow(src);\n    }\n  };\n}\n\nReadable.prototype.unpipe = function (dest) {\n  var state = this._readableState;\n  var unpipeInfo = {\n    hasUnpiped: false\n  }; // if we're not piping anywhere, then do nothing.\n\n  if (state.pipesCount === 0) return this; // just one destination.  most common case.\n\n  if (state.pipesCount === 1) {\n    // passed in one, but it's not the right one.\n    if (dest && dest !== state.pipes) return this;\n    if (!dest) dest = state.pipes; // got a match.\n\n    state.pipes = null;\n    state.pipesCount = 0;\n    state.flowing = false;\n    if (dest) dest.emit('unpipe', this, unpipeInfo);\n    return this;\n  } // slow case. multiple pipe destinations.\n\n\n  if (!dest) {\n    // remove all.\n    var dests = state.pipes;\n    var len = state.pipesCount;\n    state.pipes = null;\n    state.pipesCount = 0;\n    state.flowing = false;\n\n    for (var i = 0; i < len; i++) {\n      dests[i].emit('unpipe', this, {\n        hasUnpiped: false\n      });\n    }\n\n    return this;\n  } // try to find the right one.\n\n\n  var index = indexOf(state.pipes, dest);\n  if (index === -1) return this;\n  state.pipes.splice(index, 1);\n  state.pipesCount -= 1;\n  if (state.pipesCount === 1) state.pipes = state.pipes[0];\n  dest.emit('unpipe', this, unpipeInfo);\n  return this;\n}; // set up data events if they are asked for\n// Ensure readable listeners eventually get something\n\n\nReadable.prototype.on = function (ev, fn) {\n  var res = Stream.prototype.on.call(this, ev, fn);\n  var state = this._readableState;\n\n  if (ev === 'data') {\n    // update readableListening so that resume() may be a no-op\n    // a few lines down. This is needed to support once('readable').\n    state.readableListening = this.listenerCount('readable') > 0; // Try start flowing on next tick if stream isn't explicitly paused\n\n    if (state.flowing !== false) this.resume();\n  } else if (ev === 'readable') {\n    if (!state.endEmitted && !state.readableListening) {\n      state.readableListening = state.needReadable = true;\n      state.flowing = false;\n      state.emittedReadable = false;\n      debug('on readable', state.length, state.reading);\n\n      if (state.length) {\n        emitReadable(this);\n      } else if (!state.reading) {\n        process.nextTick(nReadingNextTick, this);\n      }\n    }\n  }\n\n  return res;\n};\n\nReadable.prototype.addListener = Readable.prototype.on;\n\nReadable.prototype.removeListener = function (ev, fn) {\n  var res = Stream.prototype.removeListener.call(this, ev, fn);\n\n  if (ev === 'readable') {\n    // We need to check if there is someone still listening to\n    // readable and reset the state. However this needs to happen\n    // after readable has been emitted but before I/O (nextTick) to\n    // support once('readable', fn) cycles. This means that calling\n    // resume within the same tick will have no\n    // effect.\n    process.nextTick(updateReadableListening, this);\n  }\n\n  return res;\n};\n\nReadable.prototype.removeAllListeners = function (ev) {\n  var res = Stream.prototype.removeAllListeners.apply(this, arguments);\n\n  if (ev === 'readable' || ev === undefined) {\n    // We need to check if there is someone still listening to\n    // readable and reset the state. However this needs to happen\n    // after readable has been emitted but before I/O (nextTick) to\n    // support once('readable', fn) cycles. This means that calling\n    // resume within the same tick will have no\n    // effect.\n    process.nextTick(updateReadableListening, this);\n  }\n\n  return res;\n};\n\nfunction updateReadableListening(self) {\n  var state = self._readableState;\n  state.readableListening = self.listenerCount('readable') > 0;\n\n  if (state.resumeScheduled && !state.paused) {\n    // flowing needs to be set to true now, otherwise\n    // the upcoming resume will not flow.\n    state.flowing = true; // crude way to check if we should resume\n  } else if (self.listenerCount('data') > 0) {\n    self.resume();\n  }\n}\n\nfunction nReadingNextTick(self) {\n  debug('readable nexttick read 0');\n  self.read(0);\n} // pause() and resume() are remnants of the legacy readable stream API\n// If the user uses them, then switch into old mode.\n\n\nReadable.prototype.resume = function () {\n  var state = this._readableState;\n\n  if (!state.flowing) {\n    debug('resume'); // we flow only if there is no one listening\n    // for readable, but we still have to call\n    // resume()\n\n    state.flowing = !state.readableListening;\n    resume(this, state);\n  }\n\n  state.paused = false;\n  return this;\n};\n\nfunction resume(stream, state) {\n  if (!state.resumeScheduled) {\n    state.resumeScheduled = true;\n    process.nextTick(resume_, stream, state);\n  }\n}\n\nfunction resume_(stream, state) {\n  debug('resume', state.reading);\n\n  if (!state.reading) {\n    stream.read(0);\n  }\n\n  state.resumeScheduled = false;\n  stream.emit('resume');\n  flow(stream);\n  if (state.flowing && !state.reading) stream.read(0);\n}\n\nReadable.prototype.pause = function () {\n  debug('call pause flowing=%j', this._readableState.flowing);\n\n  if (this._readableState.flowing !== false) {\n    debug('pause');\n    this._readableState.flowing = false;\n    this.emit('pause');\n  }\n\n  this._readableState.paused = true;\n  return this;\n};\n\nfunction flow(stream) {\n  var state = stream._readableState;\n  debug('flow', state.flowing);\n\n  while (state.flowing && stream.read() !== null) {\n    ;\n  }\n} // wrap an old-style stream as the async data source.\n// This is *not* part of the readable stream interface.\n// It is an ugly unfortunate mess of history.\n\n\nReadable.prototype.wrap = function (stream) {\n  var _this = this;\n\n  var state = this._readableState;\n  var paused = false;\n  stream.on('end', function () {\n    debug('wrapped end');\n\n    if (state.decoder && !state.ended) {\n      var chunk = state.decoder.end();\n      if (chunk && chunk.length) _this.push(chunk);\n    }\n\n    _this.push(null);\n  });\n  stream.on('data', function (chunk) {\n    debug('wrapped data');\n    if (state.decoder) chunk = state.decoder.write(chunk); // don't skip over falsy values in objectMode\n\n    if (state.objectMode && (chunk === null || chunk === undefined)) return;else if (!state.objectMode && (!chunk || !chunk.length)) return;\n\n    var ret = _this.push(chunk);\n\n    if (!ret) {\n      paused = true;\n      stream.pause();\n    }\n  }); // proxy all the other methods.\n  // important when wrapping filters and duplexes.\n\n  for (var i in stream) {\n    if (this[i] === undefined && typeof stream[i] === 'function') {\n      this[i] = function methodWrap(method) {\n        return function methodWrapReturnFunction() {\n          return stream[method].apply(stream, arguments);\n        };\n      }(i);\n    }\n  } // proxy certain important events.\n\n\n  for (var n = 0; n < kProxyEvents.length; n++) {\n    stream.on(kProxyEvents[n], this.emit.bind(this, kProxyEvents[n]));\n  } // when we try to consume some more bytes, simply unpause the\n  // underlying stream.\n\n\n  this._read = function (n) {\n    debug('wrapped _read', n);\n\n    if (paused) {\n      paused = false;\n      stream.resume();\n    }\n  };\n\n  return this;\n};\n\nif (typeof Symbol === 'function') {\n  Readable.prototype[Symbol.asyncIterator] = function () {\n    if (createReadableStreamAsyncIterator === undefined) {\n      createReadableStreamAsyncIterator = require('./internal/streams/async_iterator');\n    }\n\n    return createReadableStreamAsyncIterator(this);\n  };\n}\n\nObject.defineProperty(Readable.prototype, 'readableHighWaterMark', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    return this._readableState.highWaterMark;\n  }\n});\nObject.defineProperty(Readable.prototype, 'readableBuffer', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    return this._readableState && this._readableState.buffer;\n  }\n});\nObject.defineProperty(Readable.prototype, 'readableFlowing', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    return this._readableState.flowing;\n  },\n  set: function set(state) {\n    if (this._readableState) {\n      this._readableState.flowing = state;\n    }\n  }\n}); // exposed for testing purposes only.\n\nReadable._fromList = fromList;\nObject.defineProperty(Readable.prototype, 'readableLength', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    return this._readableState.length;\n  }\n}); // Pluck off n bytes from an array of buffers.\n// Length is the combined lengths of all the buffers in the list.\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\n\nfunction fromList(n, state) {\n  // nothing buffered\n  if (state.length === 0) return null;\n  var ret;\n  if (state.objectMode) ret = state.buffer.shift();else if (!n || n >= state.length) {\n    // read it all, truncate the list\n    if (state.decoder) ret = state.buffer.join('');else if (state.buffer.length === 1) ret = state.buffer.first();else ret = state.buffer.concat(state.length);\n    state.buffer.clear();\n  } else {\n    // read part of list\n    ret = state.buffer.consume(n, state.decoder);\n  }\n  return ret;\n}\n\nfunction endReadable(stream) {\n  var state = stream._readableState;\n  debug('endReadable', state.endEmitted);\n\n  if (!state.endEmitted) {\n    state.ended = true;\n    process.nextTick(endReadableNT, state, stream);\n  }\n}\n\nfunction endReadableNT(state, stream) {\n  debug('endReadableNT', state.endEmitted, state.length); // Check that we didn't get one last unshift.\n\n  if (!state.endEmitted && state.length === 0) {\n    state.endEmitted = true;\n    stream.readable = false;\n    stream.emit('end');\n\n    if (state.autoDestroy) {\n      // In case of duplex streams we need a way to detect\n      // if the writable side is ready for autoDestroy as well\n      var wState = stream._writableState;\n\n      if (!wState || wState.autoDestroy && wState.finished) {\n        stream.destroy();\n      }\n    }\n  }\n}\n\nif (typeof Symbol === 'function') {\n  Readable.from = function (iterable, opts) {\n    if (from === undefined) {\n      from = require('./internal/streams/from');\n    }\n\n    return from(Readable, iterable, opts);\n  };\n}\n\nfunction indexOf(xs, x) {\n  for (var i = 0, l = xs.length; i < l; i++) {\n    if (xs[i] === x) return i;\n  }\n\n  return -1;\n}","// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n// a transform stream is a readable/writable stream where you do\n// something with the data.  Sometimes it's called a \"filter\",\n// but that's not a great name for it, since that implies a thing where\n// some bits pass through, and others are simply ignored.  (That would\n// be a valid example of a transform, of course.)\n//\n// While the output is causally related to the input, it's not a\n// necessarily symmetric or synchronous transformation.  For example,\n// a zlib stream might take multiple plain-text writes(), and then\n// emit a single compressed chunk some time in the future.\n//\n// Here's how this works:\n//\n// The Transform stream has all the aspects of the readable and writable\n// stream classes.  When you write(chunk), that calls _write(chunk,cb)\n// internally, and returns false if there's a lot of pending writes\n// buffered up.  When you call read(), that calls _read(n) until\n// there's enough pending readable data buffered up.\n//\n// In a transform stream, the written data is placed in a buffer.  When\n// _read(n) is called, it transforms the queued up data, calling the\n// buffered _write cb's as it consumes chunks.  If consuming a single\n// written chunk would result in multiple output chunks, then the first\n// outputted bit calls the readcb, and subsequent chunks just go into\n// the read buffer, and will cause it to emit 'readable' if necessary.\n//\n// This way, back-pressure is actually determined by the reading side,\n// since _read has to be called to start processing a new chunk.  However,\n// a pathological inflate type of transform can cause excessive buffering\n// here.  For example, imagine a stream where every byte of input is\n// interpreted as an integer from 0-255, and then results in that many\n// bytes of output.  Writing the 4 bytes {ff,ff,ff,ff} would result in\n// 1kb of data being output.  In this case, you could write a very small\n// amount of input, and end up with a very large amount of output.  In\n// such a pathological inflating mechanism, there'd be no way to tell\n// the system to stop doing the transform.  A single 4MB write could\n// cause the system to run out of memory.\n//\n// However, even in such a pathological case, only a single written chunk\n// would be consumed, and then the rest would wait (un-transformed) until\n// the results of the previous transformed chunk were consumed.\n'use strict';\n\nmodule.exports = Transform;\n\nvar _require$codes = require('../errors').codes,\n    ERR_METHOD_NOT_IMPLEMENTED = _require$codes.ERR_METHOD_NOT_IMPLEMENTED,\n    ERR_MULTIPLE_CALLBACK = _require$codes.ERR_MULTIPLE_CALLBACK,\n    ERR_TRANSFORM_ALREADY_TRANSFORMING = _require$codes.ERR_TRANSFORM_ALREADY_TRANSFORMING,\n    ERR_TRANSFORM_WITH_LENGTH_0 = _require$codes.ERR_TRANSFORM_WITH_LENGTH_0;\n\nvar Duplex = require('./_stream_duplex');\n\nrequire('inherits')(Transform, Duplex);\n\nfunction afterTransform(er, data) {\n  var ts = this._transformState;\n  ts.transforming = false;\n  var cb = ts.writecb;\n\n  if (cb === null) {\n    return this.emit('error', new ERR_MULTIPLE_CALLBACK());\n  }\n\n  ts.writechunk = null;\n  ts.writecb = null;\n  if (data != null) // single equals check for both `null` and `undefined`\n    this.push(data);\n  cb(er);\n  var rs = this._readableState;\n  rs.reading = false;\n\n  if (rs.needReadable || rs.length < rs.highWaterMark) {\n    this._read(rs.highWaterMark);\n  }\n}\n\nfunction Transform(options) {\n  if (!(this instanceof Transform)) return new Transform(options);\n  Duplex.call(this, options);\n  this._transformState = {\n    afterTransform: afterTransform.bind(this),\n    needTransform: false,\n    transforming: false,\n    writecb: null,\n    writechunk: null,\n    writeencoding: null\n  }; // start out asking for a readable event once data is transformed.\n\n  this._readableState.needReadable = true; // we have implemented the _read method, and done the other things\n  // that Readable wants before the first _read call, so unset the\n  // sync guard flag.\n\n  this._readableState.sync = false;\n\n  if (options) {\n    if (typeof options.transform === 'function') this._transform = options.transform;\n    if (typeof options.flush === 'function') this._flush = options.flush;\n  } // When the writable side finishes, then flush out anything remaining.\n\n\n  this.on('prefinish', prefinish);\n}\n\nfunction prefinish() {\n  var _this = this;\n\n  if (typeof this._flush === 'function' && !this._readableState.destroyed) {\n    this._flush(function (er, data) {\n      done(_this, er, data);\n    });\n  } else {\n    done(this, null, null);\n  }\n}\n\nTransform.prototype.push = function (chunk, encoding) {\n  this._transformState.needTransform = false;\n  return Duplex.prototype.push.call(this, chunk, encoding);\n}; // This is the part where you do stuff!\n// override this function in implementation classes.\n// 'chunk' is an input chunk.\n//\n// Call `push(newChunk)` to pass along transformed output\n// to the readable side.  You may call 'push' zero or more times.\n//\n// Call `cb(err)` when you are done with this chunk.  If you pass\n// an error, then that'll put the hurt on the whole operation.  If you\n// never call cb(), then you'll never get another chunk.\n\n\nTransform.prototype._transform = function (chunk, encoding, cb) {\n  cb(new ERR_METHOD_NOT_IMPLEMENTED('_transform()'));\n};\n\nTransform.prototype._write = function (chunk, encoding, cb) {\n  var ts = this._transformState;\n  ts.writecb = cb;\n  ts.writechunk = chunk;\n  ts.writeencoding = encoding;\n\n  if (!ts.transforming) {\n    var rs = this._readableState;\n    if (ts.needTransform || rs.needReadable || rs.length < rs.highWaterMark) this._read(rs.highWaterMark);\n  }\n}; // Doesn't matter what the args are here.\n// _transform does all the work.\n// That we got here means that the readable side wants more data.\n\n\nTransform.prototype._read = function (n) {\n  var ts = this._transformState;\n\n  if (ts.writechunk !== null && !ts.transforming) {\n    ts.transforming = true;\n\n    this._transform(ts.writechunk, ts.writeencoding, ts.afterTransform);\n  } else {\n    // mark that we need a transform, so that any data that comes in\n    // will get processed, now that we've asked for it.\n    ts.needTransform = true;\n  }\n};\n\nTransform.prototype._destroy = function (err, cb) {\n  Duplex.prototype._destroy.call(this, err, function (err2) {\n    cb(err2);\n  });\n};\n\nfunction done(stream, er, data) {\n  if (er) return stream.emit('error', er);\n  if (data != null) // single equals check for both `null` and `undefined`\n    stream.push(data); // TODO(BridgeAR): Write a test for these two error cases\n  // if there's nothing in the write buffer, then that means\n  // that nothing more will ever be provided\n\n  if (stream._writableState.length) throw new ERR_TRANSFORM_WITH_LENGTH_0();\n  if (stream._transformState.transforming) throw new ERR_TRANSFORM_ALREADY_TRANSFORMING();\n  return stream.push(null);\n}","// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n// A bit simpler than readable streams.\n// Implement an async ._write(chunk, encoding, cb), and it'll handle all\n// the drain event emission and buffering.\n'use strict';\n\nmodule.exports = Writable;\n/* <replacement> */\n\nfunction WriteReq(chunk, encoding, cb) {\n  this.chunk = chunk;\n  this.encoding = encoding;\n  this.callback = cb;\n  this.next = null;\n} // It seems a linked list but it is not\n// there will be only 2 of these for each stream\n\n\nfunction CorkedRequest(state) {\n  var _this = this;\n\n  this.next = null;\n  this.entry = null;\n\n  this.finish = function () {\n    onCorkedFinish(_this, state);\n  };\n}\n/* </replacement> */\n\n/*<replacement>*/\n\n\nvar Duplex;\n/*</replacement>*/\n\nWritable.WritableState = WritableState;\n/*<replacement>*/\n\nvar internalUtil = {\n  deprecate: require('util-deprecate')\n};\n/*</replacement>*/\n\n/*<replacement>*/\n\nvar Stream = require('./internal/streams/stream');\n/*</replacement>*/\n\n\nvar Buffer = require('buffer').Buffer;\n\nvar OurUint8Array = global.Uint8Array || function () {};\n\nfunction _uint8ArrayToBuffer(chunk) {\n  return Buffer.from(chunk);\n}\n\nfunction _isUint8Array(obj) {\n  return Buffer.isBuffer(obj) || obj instanceof OurUint8Array;\n}\n\nvar destroyImpl = require('./internal/streams/destroy');\n\nvar _require = require('./internal/streams/state'),\n    getHighWaterMark = _require.getHighWaterMark;\n\nvar _require$codes = require('../errors').codes,\n    ERR_INVALID_ARG_TYPE = _require$codes.ERR_INVALID_ARG_TYPE,\n    ERR_METHOD_NOT_IMPLEMENTED = _require$codes.ERR_METHOD_NOT_IMPLEMENTED,\n    ERR_MULTIPLE_CALLBACK = _require$codes.ERR_MULTIPLE_CALLBACK,\n    ERR_STREAM_CANNOT_PIPE = _require$codes.ERR_STREAM_CANNOT_PIPE,\n    ERR_STREAM_DESTROYED = _require$codes.ERR_STREAM_DESTROYED,\n    ERR_STREAM_NULL_VALUES = _require$codes.ERR_STREAM_NULL_VALUES,\n    ERR_STREAM_WRITE_AFTER_END = _require$codes.ERR_STREAM_WRITE_AFTER_END,\n    ERR_UNKNOWN_ENCODING = _require$codes.ERR_UNKNOWN_ENCODING;\n\nvar errorOrDestroy = destroyImpl.errorOrDestroy;\n\nrequire('inherits')(Writable, Stream);\n\nfunction nop() {}\n\nfunction WritableState(options, stream, isDuplex) {\n  Duplex = Duplex || require('./_stream_duplex');\n  options = options || {}; // Duplex streams are both readable and writable, but share\n  // the same options object.\n  // However, some cases require setting options to different\n  // values for the readable and the writable sides of the duplex stream,\n  // e.g. options.readableObjectMode vs. options.writableObjectMode, etc.\n\n  if (typeof isDuplex !== 'boolean') isDuplex = stream instanceof Duplex; // object stream flag to indicate whether or not this stream\n  // contains buffers or objects.\n\n  this.objectMode = !!options.objectMode;\n  if (isDuplex) this.objectMode = this.objectMode || !!options.writableObjectMode; // the point at which write() starts returning false\n  // Note: 0 is a valid value, means that we always return false if\n  // the entire buffer is not flushed immediately on write()\n\n  this.highWaterMark = getHighWaterMark(this, options, 'writableHighWaterMark', isDuplex); // if _final has been called\n\n  this.finalCalled = false; // drain event flag.\n\n  this.needDrain = false; // at the start of calling end()\n\n  this.ending = false; // when end() has been called, and returned\n\n  this.ended = false; // when 'finish' is emitted\n\n  this.finished = false; // has it been destroyed\n\n  this.destroyed = false; // should we decode strings into buffers before passing to _write?\n  // this is here so that some node-core streams can optimize string\n  // handling at a lower level.\n\n  var noDecode = options.decodeStrings === false;\n  this.decodeStrings = !noDecode; // Crypto is kind of old and crusty.  Historically, its default string\n  // encoding is 'binary' so we have to make this configurable.\n  // Everything else in the universe uses 'utf8', though.\n\n  this.defaultEncoding = options.defaultEncoding || 'utf8'; // not an actual buffer we keep track of, but a measurement\n  // of how much we're waiting to get pushed to some underlying\n  // socket or file.\n\n  this.length = 0; // a flag to see when we're in the middle of a write.\n\n  this.writing = false; // when true all writes will be buffered until .uncork() call\n\n  this.corked = 0; // a flag to be able to tell if the onwrite cb is called immediately,\n  // or on a later tick.  We set this to true at first, because any\n  // actions that shouldn't happen until \"later\" should generally also\n  // not happen before the first write call.\n\n  this.sync = true; // a flag to know if we're processing previously buffered items, which\n  // may call the _write() callback in the same tick, so that we don't\n  // end up in an overlapped onwrite situation.\n\n  this.bufferProcessing = false; // the callback that's passed to _write(chunk,cb)\n\n  this.onwrite = function (er) {\n    onwrite(stream, er);\n  }; // the callback that the user supplies to write(chunk,encoding,cb)\n\n\n  this.writecb = null; // the amount that is being written when _write is called.\n\n  this.writelen = 0;\n  this.bufferedRequest = null;\n  this.lastBufferedRequest = null; // number of pending user-supplied write callbacks\n  // this must be 0 before 'finish' can be emitted\n\n  this.pendingcb = 0; // emit prefinish if the only thing we're waiting for is _write cbs\n  // This is relevant for synchronous Transform streams\n\n  this.prefinished = false; // True if the error was already emitted and should not be thrown again\n\n  this.errorEmitted = false; // Should close be emitted on destroy. Defaults to true.\n\n  this.emitClose = options.emitClose !== false; // Should .destroy() be called after 'finish' (and potentially 'end')\n\n  this.autoDestroy = !!options.autoDestroy; // count buffered requests\n\n  this.bufferedRequestCount = 0; // allocate the first CorkedRequest, there is always\n  // one allocated and free to use, and we maintain at most two\n\n  this.corkedRequestsFree = new CorkedRequest(this);\n}\n\nWritableState.prototype.getBuffer = function getBuffer() {\n  var current = this.bufferedRequest;\n  var out = [];\n\n  while (current) {\n    out.push(current);\n    current = current.next;\n  }\n\n  return out;\n};\n\n(function () {\n  try {\n    Object.defineProperty(WritableState.prototype, 'buffer', {\n      get: internalUtil.deprecate(function writableStateBufferGetter() {\n        return this.getBuffer();\n      }, '_writableState.buffer is deprecated. Use _writableState.getBuffer ' + 'instead.', 'DEP0003')\n    });\n  } catch (_) {}\n})(); // Test _writableState for inheritance to account for Duplex streams,\n// whose prototype chain only points to Readable.\n\n\nvar realHasInstance;\n\nif (typeof Symbol === 'function' && Symbol.hasInstance && typeof Function.prototype[Symbol.hasInstance] === 'function') {\n  realHasInstance = Function.prototype[Symbol.hasInstance];\n  Object.defineProperty(Writable, Symbol.hasInstance, {\n    value: function value(object) {\n      if (realHasInstance.call(this, object)) return true;\n      if (this !== Writable) return false;\n      return object && object._writableState instanceof WritableState;\n    }\n  });\n} else {\n  realHasInstance = function realHasInstance(object) {\n    return object instanceof this;\n  };\n}\n\nfunction Writable(options) {\n  Duplex = Duplex || require('./_stream_duplex'); // Writable ctor is applied to Duplexes, too.\n  // `realHasInstance` is necessary because using plain `instanceof`\n  // would return false, as no `_writableState` property is attached.\n  // Trying to use the custom `instanceof` for Writable here will also break the\n  // Node.js LazyTransform implementation, which has a non-trivial getter for\n  // `_writableState` that would lead to infinite recursion.\n  // Checking for a Stream.Duplex instance is faster here instead of inside\n  // the WritableState constructor, at least with V8 6.5\n\n  var isDuplex = this instanceof Duplex;\n  if (!isDuplex && !realHasInstance.call(Writable, this)) return new Writable(options);\n  this._writableState = new WritableState(options, this, isDuplex); // legacy.\n\n  this.writable = true;\n\n  if (options) {\n    if (typeof options.write === 'function') this._write = options.write;\n    if (typeof options.writev === 'function') this._writev = options.writev;\n    if (typeof options.destroy === 'function') this._destroy = options.destroy;\n    if (typeof options.final === 'function') this._final = options.final;\n  }\n\n  Stream.call(this);\n} // Otherwise people can pipe Writable streams, which is just wrong.\n\n\nWritable.prototype.pipe = function () {\n  errorOrDestroy(this, new ERR_STREAM_CANNOT_PIPE());\n};\n\nfunction writeAfterEnd(stream, cb) {\n  var er = new ERR_STREAM_WRITE_AFTER_END(); // TODO: defer error events consistently everywhere, not just the cb\n\n  errorOrDestroy(stream, er);\n  process.nextTick(cb, er);\n} // Checks that a user-supplied chunk is valid, especially for the particular\n// mode the stream is in. Currently this means that `null` is never accepted\n// and undefined/non-string values are only allowed in object mode.\n\n\nfunction validChunk(stream, state, chunk, cb) {\n  var er;\n\n  if (chunk === null) {\n    er = new ERR_STREAM_NULL_VALUES();\n  } else if (typeof chunk !== 'string' && !state.objectMode) {\n    er = new ERR_INVALID_ARG_TYPE('chunk', ['string', 'Buffer'], chunk);\n  }\n\n  if (er) {\n    errorOrDestroy(stream, er);\n    process.nextTick(cb, er);\n    return false;\n  }\n\n  return true;\n}\n\nWritable.prototype.write = function (chunk, encoding, cb) {\n  var state = this._writableState;\n  var ret = false;\n\n  var isBuf = !state.objectMode && _isUint8Array(chunk);\n\n  if (isBuf && !Buffer.isBuffer(chunk)) {\n    chunk = _uint8ArrayToBuffer(chunk);\n  }\n\n  if (typeof encoding === 'function') {\n    cb = encoding;\n    encoding = null;\n  }\n\n  if (isBuf) encoding = 'buffer';else if (!encoding) encoding = state.defaultEncoding;\n  if (typeof cb !== 'function') cb = nop;\n  if (state.ending) writeAfterEnd(this, cb);else if (isBuf || validChunk(this, state, chunk, cb)) {\n    state.pendingcb++;\n    ret = writeOrBuffer(this, state, isBuf, chunk, encoding, cb);\n  }\n  return ret;\n};\n\nWritable.prototype.cork = function () {\n  this._writableState.corked++;\n};\n\nWritable.prototype.uncork = function () {\n  var state = this._writableState;\n\n  if (state.corked) {\n    state.corked--;\n    if (!state.writing && !state.corked && !state.bufferProcessing && state.bufferedRequest) clearBuffer(this, state);\n  }\n};\n\nWritable.prototype.setDefaultEncoding = function setDefaultEncoding(encoding) {\n  // node::ParseEncoding() requires lower case.\n  if (typeof encoding === 'string') encoding = encoding.toLowerCase();\n  if (!(['hex', 'utf8', 'utf-8', 'ascii', 'binary', 'base64', 'ucs2', 'ucs-2', 'utf16le', 'utf-16le', 'raw'].indexOf((encoding + '').toLowerCase()) > -1)) throw new ERR_UNKNOWN_ENCODING(encoding);\n  this._writableState.defaultEncoding = encoding;\n  return this;\n};\n\nObject.defineProperty(Writable.prototype, 'writableBuffer', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    return this._writableState && this._writableState.getBuffer();\n  }\n});\n\nfunction decodeChunk(state, chunk, encoding) {\n  if (!state.objectMode && state.decodeStrings !== false && typeof chunk === 'string') {\n    chunk = Buffer.from(chunk, encoding);\n  }\n\n  return chunk;\n}\n\nObject.defineProperty(Writable.prototype, 'writableHighWaterMark', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    return this._writableState.highWaterMark;\n  }\n}); // if we're already writing something, then just put this\n// in the queue, and wait our turn.  Otherwise, call _write\n// If we return false, then we need a drain event, so set that flag.\n\nfunction writeOrBuffer(stream, state, isBuf, chunk, encoding, cb) {\n  if (!isBuf) {\n    var newChunk = decodeChunk(state, chunk, encoding);\n\n    if (chunk !== newChunk) {\n      isBuf = true;\n      encoding = 'buffer';\n      chunk = newChunk;\n    }\n  }\n\n  var len = state.objectMode ? 1 : chunk.length;\n  state.length += len;\n  var ret = state.length < state.highWaterMark; // we must ensure that previous needDrain will not be reset to false.\n\n  if (!ret) state.needDrain = true;\n\n  if (state.writing || state.corked) {\n    var last = state.lastBufferedRequest;\n    state.lastBufferedRequest = {\n      chunk: chunk,\n      encoding: encoding,\n      isBuf: isBuf,\n      callback: cb,\n      next: null\n    };\n\n    if (last) {\n      last.next = state.lastBufferedRequest;\n    } else {\n      state.bufferedRequest = state.lastBufferedRequest;\n    }\n\n    state.bufferedRequestCount += 1;\n  } else {\n    doWrite(stream, state, false, len, chunk, encoding, cb);\n  }\n\n  return ret;\n}\n\nfunction doWrite(stream, state, writev, len, chunk, encoding, cb) {\n  state.writelen = len;\n  state.writecb = cb;\n  state.writing = true;\n  state.sync = true;\n  if (state.destroyed) state.onwrite(new ERR_STREAM_DESTROYED('write'));else if (writev) stream._writev(chunk, state.onwrite);else stream._write(chunk, encoding, state.onwrite);\n  state.sync = false;\n}\n\nfunction onwriteError(stream, state, sync, er, cb) {\n  --state.pendingcb;\n\n  if (sync) {\n    // defer the callback if we are being called synchronously\n    // to avoid piling up things on the stack\n    process.nextTick(cb, er); // this can emit finish, and it will always happen\n    // after error\n\n    process.nextTick(finishMaybe, stream, state);\n    stream._writableState.errorEmitted = true;\n    errorOrDestroy(stream, er);\n  } else {\n    // the caller expect this to happen before if\n    // it is async\n    cb(er);\n    stream._writableState.errorEmitted = true;\n    errorOrDestroy(stream, er); // this can emit finish, but finish must\n    // always follow error\n\n    finishMaybe(stream, state);\n  }\n}\n\nfunction onwriteStateUpdate(state) {\n  state.writing = false;\n  state.writecb = null;\n  state.length -= state.writelen;\n  state.writelen = 0;\n}\n\nfunction onwrite(stream, er) {\n  var state = stream._writableState;\n  var sync = state.sync;\n  var cb = state.writecb;\n  if (typeof cb !== 'function') throw new ERR_MULTIPLE_CALLBACK();\n  onwriteStateUpdate(state);\n  if (er) onwriteError(stream, state, sync, er, cb);else {\n    // Check if we're actually ready to finish, but don't emit yet\n    var finished = needFinish(state) || stream.destroyed;\n\n    if (!finished && !state.corked && !state.bufferProcessing && state.bufferedRequest) {\n      clearBuffer(stream, state);\n    }\n\n    if (sync) {\n      process.nextTick(afterWrite, stream, state, finished, cb);\n    } else {\n      afterWrite(stream, state, finished, cb);\n    }\n  }\n}\n\nfunction afterWrite(stream, state, finished, cb) {\n  if (!finished) onwriteDrain(stream, state);\n  state.pendingcb--;\n  cb();\n  finishMaybe(stream, state);\n} // Must force callback to be called on nextTick, so that we don't\n// emit 'drain' before the write() consumer gets the 'false' return\n// value, and has a chance to attach a 'drain' listener.\n\n\nfunction onwriteDrain(stream, state) {\n  if (state.length === 0 && state.needDrain) {\n    state.needDrain = false;\n    stream.emit('drain');\n  }\n} // if there's something in the buffer waiting, then process it\n\n\nfunction clearBuffer(stream, state) {\n  state.bufferProcessing = true;\n  var entry = state.bufferedRequest;\n\n  if (stream._writev && entry && entry.next) {\n    // Fast case, write everything using _writev()\n    var l = state.bufferedRequestCount;\n    var buffer = new Array(l);\n    var holder = state.corkedRequestsFree;\n    holder.entry = entry;\n    var count = 0;\n    var allBuffers = true;\n\n    while (entry) {\n      buffer[count] = entry;\n      if (!entry.isBuf) allBuffers = false;\n      entry = entry.next;\n      count += 1;\n    }\n\n    buffer.allBuffers = allBuffers;\n    doWrite(stream, state, true, state.length, buffer, '', holder.finish); // doWrite is almost always async, defer these to save a bit of time\n    // as the hot path ends with doWrite\n\n    state.pendingcb++;\n    state.lastBufferedRequest = null;\n\n    if (holder.next) {\n      state.corkedRequestsFree = holder.next;\n      holder.next = null;\n    } else {\n      state.corkedRequestsFree = new CorkedRequest(state);\n    }\n\n    state.bufferedRequestCount = 0;\n  } else {\n    // Slow case, write chunks one-by-one\n    while (entry) {\n      var chunk = entry.chunk;\n      var encoding = entry.encoding;\n      var cb = entry.callback;\n      var len = state.objectMode ? 1 : chunk.length;\n      doWrite(stream, state, false, len, chunk, encoding, cb);\n      entry = entry.next;\n      state.bufferedRequestCount--; // if we didn't call the onwrite immediately, then\n      // it means that we need to wait until it does.\n      // also, that means that the chunk and cb are currently\n      // being processed, so move the buffer counter past them.\n\n      if (state.writing) {\n        break;\n      }\n    }\n\n    if (entry === null) state.lastBufferedRequest = null;\n  }\n\n  state.bufferedRequest = entry;\n  state.bufferProcessing = false;\n}\n\nWritable.prototype._write = function (chunk, encoding, cb) {\n  cb(new ERR_METHOD_NOT_IMPLEMENTED('_write()'));\n};\n\nWritable.prototype._writev = null;\n\nWritable.prototype.end = function (chunk, encoding, cb) {\n  var state = this._writableState;\n\n  if (typeof chunk === 'function') {\n    cb = chunk;\n    chunk = null;\n    encoding = null;\n  } else if (typeof encoding === 'function') {\n    cb = encoding;\n    encoding = null;\n  }\n\n  if (chunk !== null && chunk !== undefined) this.write(chunk, encoding); // .end() fully uncorks\n\n  if (state.corked) {\n    state.corked = 1;\n    this.uncork();\n  } // ignore unnecessary end() calls.\n\n\n  if (!state.ending) endWritable(this, state, cb);\n  return this;\n};\n\nObject.defineProperty(Writable.prototype, 'writableLength', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    return this._writableState.length;\n  }\n});\n\nfunction needFinish(state) {\n  return state.ending && state.length === 0 && state.bufferedRequest === null && !state.finished && !state.writing;\n}\n\nfunction callFinal(stream, state) {\n  stream._final(function (err) {\n    state.pendingcb--;\n\n    if (err) {\n      errorOrDestroy(stream, err);\n    }\n\n    state.prefinished = true;\n    stream.emit('prefinish');\n    finishMaybe(stream, state);\n  });\n}\n\nfunction prefinish(stream, state) {\n  if (!state.prefinished && !state.finalCalled) {\n    if (typeof stream._final === 'function' && !state.destroyed) {\n      state.pendingcb++;\n      state.finalCalled = true;\n      process.nextTick(callFinal, stream, state);\n    } else {\n      state.prefinished = true;\n      stream.emit('prefinish');\n    }\n  }\n}\n\nfunction finishMaybe(stream, state) {\n  var need = needFinish(state);\n\n  if (need) {\n    prefinish(stream, state);\n\n    if (state.pendingcb === 0) {\n      state.finished = true;\n      stream.emit('finish');\n\n      if (state.autoDestroy) {\n        // In case of duplex streams we need a way to detect\n        // if the readable side is ready for autoDestroy as well\n        var rState = stream._readableState;\n\n        if (!rState || rState.autoDestroy && rState.endEmitted) {\n          stream.destroy();\n        }\n      }\n    }\n  }\n\n  return need;\n}\n\nfunction endWritable(stream, state, cb) {\n  state.ending = true;\n  finishMaybe(stream, state);\n\n  if (cb) {\n    if (state.finished) process.nextTick(cb);else stream.once('finish', cb);\n  }\n\n  state.ended = true;\n  stream.writable = false;\n}\n\nfunction onCorkedFinish(corkReq, state, err) {\n  var entry = corkReq.entry;\n  corkReq.entry = null;\n\n  while (entry) {\n    var cb = entry.callback;\n    state.pendingcb--;\n    cb(err);\n    entry = entry.next;\n  } // reuse the free corkReq.\n\n\n  state.corkedRequestsFree.next = corkReq;\n}\n\nObject.defineProperty(Writable.prototype, 'destroyed', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    if (this._writableState === undefined) {\n      return false;\n    }\n\n    return this._writableState.destroyed;\n  },\n  set: function set(value) {\n    // we ignore the value if the stream\n    // has not been initialized yet\n    if (!this._writableState) {\n      return;\n    } // backward compatibility, the user is explicitly\n    // managing destroyed\n\n\n    this._writableState.destroyed = value;\n  }\n});\nWritable.prototype.destroy = destroyImpl.destroy;\nWritable.prototype._undestroy = destroyImpl.undestroy;\n\nWritable.prototype._destroy = function (err, cb) {\n  cb(err);\n};","'use strict';\n\nvar _Object$setPrototypeO;\n\nfunction _defineProperty(obj, key, value) { if (key in obj) { Object.defineProperty(obj, key, { value: value, enumerable: true, configurable: true, writable: true }); } else { obj[key] = value; } return obj; }\n\nvar finished = require('./end-of-stream');\n\nvar kLastResolve = Symbol('lastResolve');\nvar kLastReject = Symbol('lastReject');\nvar kError = Symbol('error');\nvar kEnded = Symbol('ended');\nvar kLastPromise = Symbol('lastPromise');\nvar kHandlePromise = Symbol('handlePromise');\nvar kStream = Symbol('stream');\n\nfunction createIterResult(value, done) {\n  return {\n    value: value,\n    done: done\n  };\n}\n\nfunction readAndResolve(iter) {\n  var resolve = iter[kLastResolve];\n\n  if (resolve !== null) {\n    var data = iter[kStream].read(); // we defer if data is null\n    // we can be expecting either 'end' or\n    // 'error'\n\n    if (data !== null) {\n      iter[kLastPromise] = null;\n      iter[kLastResolve] = null;\n      iter[kLastReject] = null;\n      resolve(createIterResult(data, false));\n    }\n  }\n}\n\nfunction onReadable(iter) {\n  // we wait for the next tick, because it might\n  // emit an error with process.nextTick\n  process.nextTick(readAndResolve, iter);\n}\n\nfunction wrapForNext(lastPromise, iter) {\n  return function (resolve, reject) {\n    lastPromise.then(function () {\n      if (iter[kEnded]) {\n        resolve(createIterResult(undefined, true));\n        return;\n      }\n\n      iter[kHandlePromise](resolve, reject);\n    }, reject);\n  };\n}\n\nvar AsyncIteratorPrototype = Object.getPrototypeOf(function () {});\nvar ReadableStreamAsyncIteratorPrototype = Object.setPrototypeOf((_Object$setPrototypeO = {\n  get stream() {\n    return this[kStream];\n  },\n\n  next: function next() {\n    var _this = this;\n\n    // if we have detected an error in the meanwhile\n    // reject straight away\n    var error = this[kError];\n\n    if (error !== null) {\n      return Promise.reject(error);\n    }\n\n    if (this[kEnded]) {\n      return Promise.resolve(createIterResult(undefined, true));\n    }\n\n    if (this[kStream].destroyed) {\n      // We need to defer via nextTick because if .destroy(err) is\n      // called, the error will be emitted via nextTick, and\n      // we cannot guarantee that there is no error lingering around\n      // waiting to be emitted.\n      return new Promise(function (resolve, reject) {\n        process.nextTick(function () {\n          if (_this[kError]) {\n            reject(_this[kError]);\n          } else {\n            resolve(createIterResult(undefined, true));\n          }\n        });\n      });\n    } // if we have multiple next() calls\n    // we will wait for the previous Promise to finish\n    // this logic is optimized to support for await loops,\n    // where next() is only called once at a time\n\n\n    var lastPromise = this[kLastPromise];\n    var promise;\n\n    if (lastPromise) {\n      promise = new Promise(wrapForNext(lastPromise, this));\n    } else {\n      // fast path needed to support multiple this.push()\n      // without triggering the next() queue\n      var data = this[kStream].read();\n\n      if (data !== null) {\n        return Promise.resolve(createIterResult(data, false));\n      }\n\n      promise = new Promise(this[kHandlePromise]);\n    }\n\n    this[kLastPromise] = promise;\n    return promise;\n  }\n}, _defineProperty(_Object$setPrototypeO, Symbol.asyncIterator, function () {\n  return this;\n}), _defineProperty(_Object$setPrototypeO, \"return\", function _return() {\n  var _this2 = this;\n\n  // destroy(err, cb) is a private API\n  // we can guarantee we have that here, because we control the\n  // Readable class this is attached to\n  return new Promise(function (resolve, reject) {\n    _this2[kStream].destroy(null, function (err) {\n      if (err) {\n        reject(err);\n        return;\n      }\n\n      resolve(createIterResult(undefined, true));\n    });\n  });\n}), _Object$setPrototypeO), AsyncIteratorPrototype);\n\nvar createReadableStreamAsyncIterator = function createReadableStreamAsyncIterator(stream) {\n  var _Object$create;\n\n  var iterator = Object.create(ReadableStreamAsyncIteratorPrototype, (_Object$create = {}, _defineProperty(_Object$create, kStream, {\n    value: stream,\n    writable: true\n  }), _defineProperty(_Object$create, kLastResolve, {\n    value: null,\n    writable: true\n  }), _defineProperty(_Object$create, kLastReject, {\n    value: null,\n    writable: true\n  }), _defineProperty(_Object$create, kError, {\n    value: null,\n    writable: true\n  }), _defineProperty(_Object$create, kEnded, {\n    value: stream._readableState.endEmitted,\n    writable: true\n  }), _defineProperty(_Object$create, kHandlePromise, {\n    value: function value(resolve, reject) {\n      var data = iterator[kStream].read();\n\n      if (data) {\n        iterator[kLastPromise] = null;\n        iterator[kLastResolve] = null;\n        iterator[kLastReject] = null;\n        resolve(createIterResult(data, false));\n      } else {\n        iterator[kLastResolve] = resolve;\n        iterator[kLastReject] = reject;\n      }\n    },\n    writable: true\n  }), _Object$create));\n  iterator[kLastPromise] = null;\n  finished(stream, function (err) {\n    if (err && err.code !== 'ERR_STREAM_PREMATURE_CLOSE') {\n      var reject = iterator[kLastReject]; // reject if we are waiting for data in the Promise\n      // returned by next() and store the error\n\n      if (reject !== null) {\n        iterator[kLastPromise] = null;\n        iterator[kLastResolve] = null;\n        iterator[kLastReject] = null;\n        reject(err);\n      }\n\n      iterator[kError] = err;\n      return;\n    }\n\n    var resolve = iterator[kLastResolve];\n\n    if (resolve !== null) {\n      iterator[kLastPromise] = null;\n      iterator[kLastResolve] = null;\n      iterator[kLastReject] = null;\n      resolve(createIterResult(undefined, true));\n    }\n\n    iterator[kEnded] = true;\n  });\n  stream.on('readable', onReadable.bind(null, iterator));\n  return iterator;\n};\n\nmodule.exports = createReadableStreamAsyncIterator;","'use strict';\n\nfunction ownKeys(object, enumerableOnly) { var keys = Object.keys(object); if (Object.getOwnPropertySymbols) { var symbols = Object.getOwnPropertySymbols(object); if (enumerableOnly) symbols = symbols.filter(function (sym) { return Object.getOwnPropertyDescriptor(object, sym).enumerable; }); keys.push.apply(keys, symbols); } return keys; }\n\nfunction _objectSpread(target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i] != null ? arguments[i] : {}; if (i % 2) { ownKeys(Object(source), true).forEach(function (key) { _defineProperty(target, key, source[key]); }); } else if (Object.getOwnPropertyDescriptors) { Object.defineProperties(target, Object.getOwnPropertyDescriptors(source)); } else { ownKeys(Object(source)).forEach(function (key) { Object.defineProperty(target, key, Object.getOwnPropertyDescriptor(source, key)); }); } } return target; }\n\nfunction _defineProperty(obj, key, value) { if (key in obj) { Object.defineProperty(obj, key, { value: value, enumerable: true, configurable: true, writable: true }); } else { obj[key] = value; } return obj; }\n\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nfunction _defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }\n\nfunction _createClass(Constructor, protoProps, staticProps) { if (protoProps) _defineProperties(Constructor.prototype, protoProps); if (staticProps) _defineProperties(Constructor, staticProps); return Constructor; }\n\nvar _require = require('buffer'),\n    Buffer = _require.Buffer;\n\nvar _require2 = require('util'),\n    inspect = _require2.inspect;\n\nvar custom = inspect && inspect.custom || 'inspect';\n\nfunction copyBuffer(src, target, offset) {\n  Buffer.prototype.copy.call(src, target, offset);\n}\n\nmodule.exports =\n/*#__PURE__*/\nfunction () {\n  function BufferList() {\n    _classCallCheck(this, BufferList);\n\n    this.head = null;\n    this.tail = null;\n    this.length = 0;\n  }\n\n  _createClass(BufferList, [{\n    key: \"push\",\n    value: function push(v) {\n      var entry = {\n        data: v,\n        next: null\n      };\n      if (this.length > 0) this.tail.next = entry;else this.head = entry;\n      this.tail = entry;\n      ++this.length;\n    }\n  }, {\n    key: \"unshift\",\n    value: function unshift(v) {\n      var entry = {\n        data: v,\n        next: this.head\n      };\n      if (this.length === 0) this.tail = entry;\n      this.head = entry;\n      ++this.length;\n    }\n  }, {\n    key: \"shift\",\n    value: function shift() {\n      if (this.length === 0) return;\n      var ret = this.head.data;\n      if (this.length === 1) this.head = this.tail = null;else this.head = this.head.next;\n      --this.length;\n      return ret;\n    }\n  }, {\n    key: \"clear\",\n    value: function clear() {\n      this.head = this.tail = null;\n      this.length = 0;\n    }\n  }, {\n    key: \"join\",\n    value: function join(s) {\n      if (this.length === 0) return '';\n      var p = this.head;\n      var ret = '' + p.data;\n\n      while (p = p.next) {\n        ret += s + p.data;\n      }\n\n      return ret;\n    }\n  }, {\n    key: \"concat\",\n    value: function concat(n) {\n      if (this.length === 0) return Buffer.alloc(0);\n      var ret = Buffer.allocUnsafe(n >>> 0);\n      var p = this.head;\n      var i = 0;\n\n      while (p) {\n        copyBuffer(p.data, ret, i);\n        i += p.data.length;\n        p = p.next;\n      }\n\n      return ret;\n    } // Consumes a specified amount of bytes or characters from the buffered data.\n\n  }, {\n    key: \"consume\",\n    value: function consume(n, hasStrings) {\n      var ret;\n\n      if (n < this.head.data.length) {\n        // `slice` is the same for buffers and strings.\n        ret = this.head.data.slice(0, n);\n        this.head.data = this.head.data.slice(n);\n      } else if (n === this.head.data.length) {\n        // First chunk is a perfect match.\n        ret = this.shift();\n      } else {\n        // Result spans more than one buffer.\n        ret = hasStrings ? this._getString(n) : this._getBuffer(n);\n      }\n\n      return ret;\n    }\n  }, {\n    key: \"first\",\n    value: function first() {\n      return this.head.data;\n    } // Consumes a specified amount of characters from the buffered data.\n\n  }, {\n    key: \"_getString\",\n    value: function _getString(n) {\n      var p = this.head;\n      var c = 1;\n      var ret = p.data;\n      n -= ret.length;\n\n      while (p = p.next) {\n        var str = p.data;\n        var nb = n > str.length ? str.length : n;\n        if (nb === str.length) ret += str;else ret += str.slice(0, n);\n        n -= nb;\n\n        if (n === 0) {\n          if (nb === str.length) {\n            ++c;\n            if (p.next) this.head = p.next;else this.head = this.tail = null;\n          } else {\n            this.head = p;\n            p.data = str.slice(nb);\n          }\n\n          break;\n        }\n\n        ++c;\n      }\n\n      this.length -= c;\n      return ret;\n    } // Consumes a specified amount of bytes from the buffered data.\n\n  }, {\n    key: \"_getBuffer\",\n    value: function _getBuffer(n) {\n      var ret = Buffer.allocUnsafe(n);\n      var p = this.head;\n      var c = 1;\n      p.data.copy(ret);\n      n -= p.data.length;\n\n      while (p = p.next) {\n        var buf = p.data;\n        var nb = n > buf.length ? buf.length : n;\n        buf.copy(ret, ret.length - n, 0, nb);\n        n -= nb;\n\n        if (n === 0) {\n          if (nb === buf.length) {\n            ++c;\n            if (p.next) this.head = p.next;else this.head = this.tail = null;\n          } else {\n            this.head = p;\n            p.data = buf.slice(nb);\n          }\n\n          break;\n        }\n\n        ++c;\n      }\n\n      this.length -= c;\n      return ret;\n    } // Make sure the linked list only shows the minimal necessary information.\n\n  }, {\n    key: custom,\n    value: function value(_, options) {\n      return inspect(this, _objectSpread({}, options, {\n        // Only inspect one level.\n        depth: 0,\n        // It should not recurse.\n        customInspect: false\n      }));\n    }\n  }]);\n\n  return BufferList;\n}();","'use strict'; // undocumented cb() API, needed for core, not for public API\n\nfunction destroy(err, cb) {\n  var _this = this;\n\n  var readableDestroyed = this._readableState && this._readableState.destroyed;\n  var writableDestroyed = this._writableState && this._writableState.destroyed;\n\n  if (readableDestroyed || writableDestroyed) {\n    if (cb) {\n      cb(err);\n    } else if (err) {\n      if (!this._writableState) {\n        process.nextTick(emitErrorNT, this, err);\n      } else if (!this._writableState.errorEmitted) {\n        this._writableState.errorEmitted = true;\n        process.nextTick(emitErrorNT, this, err);\n      }\n    }\n\n    return this;\n  } // we set destroyed to true before firing error callbacks in order\n  // to make it re-entrance safe in case destroy() is called within callbacks\n\n\n  if (this._readableState) {\n    this._readableState.destroyed = true;\n  } // if this is a duplex stream mark the writable part as destroyed as well\n\n\n  if (this._writableState) {\n    this._writableState.destroyed = true;\n  }\n\n  this._destroy(err || null, function (err) {\n    if (!cb && err) {\n      if (!_this._writableState) {\n        process.nextTick(emitErrorAndCloseNT, _this, err);\n      } else if (!_this._writableState.errorEmitted) {\n        _this._writableState.errorEmitted = true;\n        process.nextTick(emitErrorAndCloseNT, _this, err);\n      } else {\n        process.nextTick(emitCloseNT, _this);\n      }\n    } else if (cb) {\n      process.nextTick(emitCloseNT, _this);\n      cb(err);\n    } else {\n      process.nextTick(emitCloseNT, _this);\n    }\n  });\n\n  return this;\n}\n\nfunction emitErrorAndCloseNT(self, err) {\n  emitErrorNT(self, err);\n  emitCloseNT(self);\n}\n\nfunction emitCloseNT(self) {\n  if (self._writableState && !self._writableState.emitClose) return;\n  if (self._readableState && !self._readableState.emitClose) return;\n  self.emit('close');\n}\n\nfunction undestroy() {\n  if (this._readableState) {\n    this._readableState.destroyed = false;\n    this._readableState.reading = false;\n    this._readableState.ended = false;\n    this._readableState.endEmitted = false;\n  }\n\n  if (this._writableState) {\n    this._writableState.destroyed = false;\n    this._writableState.ended = false;\n    this._writableState.ending = false;\n    this._writableState.finalCalled = false;\n    this._writableState.prefinished = false;\n    this._writableState.finished = false;\n    this._writableState.errorEmitted = false;\n  }\n}\n\nfunction emitErrorNT(self, err) {\n  self.emit('error', err);\n}\n\nfunction errorOrDestroy(stream, err) {\n  // We have tests that rely on errors being emitted\n  // in the same tick, so changing this is semver major.\n  // For now when you opt-in to autoDestroy we allow\n  // the error to be emitted nextTick. In a future\n  // semver major update we should change the default to this.\n  var rState = stream._readableState;\n  var wState = stream._writableState;\n  if (rState && rState.autoDestroy || wState && wState.autoDestroy) stream.destroy(err);else stream.emit('error', err);\n}\n\nmodule.exports = {\n  destroy: destroy,\n  undestroy: undestroy,\n  errorOrDestroy: errorOrDestroy\n};","// Ported from https://github.com/mafintosh/end-of-stream with\n// permission from the author, Mathias Buus (@mafintosh).\n'use strict';\n\nvar ERR_STREAM_PREMATURE_CLOSE = require('../../../errors').codes.ERR_STREAM_PREMATURE_CLOSE;\n\nfunction once(callback) {\n  var called = false;\n  return function () {\n    if (called) return;\n    called = true;\n\n    for (var _len = arguments.length, args = new Array(_len), _key = 0; _key < _len; _key++) {\n      args[_key] = arguments[_key];\n    }\n\n    callback.apply(this, args);\n  };\n}\n\nfunction noop() {}\n\nfunction isRequest(stream) {\n  return stream.setHeader && typeof stream.abort === 'function';\n}\n\nfunction eos(stream, opts, callback) {\n  if (typeof opts === 'function') return eos(stream, null, opts);\n  if (!opts) opts = {};\n  callback = once(callback || noop);\n  var readable = opts.readable || opts.readable !== false && stream.readable;\n  var writable = opts.writable || opts.writable !== false && stream.writable;\n\n  var onlegacyfinish = function onlegacyfinish() {\n    if (!stream.writable) onfinish();\n  };\n\n  var writableEnded = stream._writableState && stream._writableState.finished;\n\n  var onfinish = function onfinish() {\n    writable = false;\n    writableEnded = true;\n    if (!readable) callback.call(stream);\n  };\n\n  var readableEnded = stream._readableState && stream._readableState.endEmitted;\n\n  var onend = function onend() {\n    readable = false;\n    readableEnded = true;\n    if (!writable) callback.call(stream);\n  };\n\n  var onerror = function onerror(err) {\n    callback.call(stream, err);\n  };\n\n  var onclose = function onclose() {\n    var err;\n\n    if (readable && !readableEnded) {\n      if (!stream._readableState || !stream._readableState.ended) err = new ERR_STREAM_PREMATURE_CLOSE();\n      return callback.call(stream, err);\n    }\n\n    if (writable && !writableEnded) {\n      if (!stream._writableState || !stream._writableState.ended) err = new ERR_STREAM_PREMATURE_CLOSE();\n      return callback.call(stream, err);\n    }\n  };\n\n  var onrequest = function onrequest() {\n    stream.req.on('finish', onfinish);\n  };\n\n  if (isRequest(stream)) {\n    stream.on('complete', onfinish);\n    stream.on('abort', onclose);\n    if (stream.req) onrequest();else stream.on('request', onrequest);\n  } else if (writable && !stream._writableState) {\n    // legacy streams\n    stream.on('end', onlegacyfinish);\n    stream.on('close', onlegacyfinish);\n  }\n\n  stream.on('end', onend);\n  stream.on('finish', onfinish);\n  if (opts.error !== false) stream.on('error', onerror);\n  stream.on('close', onclose);\n  return function () {\n    stream.removeListener('complete', onfinish);\n    stream.removeListener('abort', onclose);\n    stream.removeListener('request', onrequest);\n    if (stream.req) stream.req.removeListener('finish', onfinish);\n    stream.removeListener('end', onlegacyfinish);\n    stream.removeListener('close', onlegacyfinish);\n    stream.removeListener('finish', onfinish);\n    stream.removeListener('end', onend);\n    stream.removeListener('error', onerror);\n    stream.removeListener('close', onclose);\n  };\n}\n\nmodule.exports = eos;","'use strict';\n\nfunction asyncGeneratorStep(gen, resolve, reject, _next, _throw, key, arg) { try { var info = gen[key](arg); var value = info.value; } catch (error) { reject(error); return; } if (info.done) { resolve(value); } else { Promise.resolve(value).then(_next, _throw); } }\n\nfunction _asyncToGenerator(fn) { return function () { var self = this, args = arguments; return new Promise(function (resolve, reject) { var gen = fn.apply(self, args); function _next(value) { asyncGeneratorStep(gen, resolve, reject, _next, _throw, \"next\", value); } function _throw(err) { asyncGeneratorStep(gen, resolve, reject, _next, _throw, \"throw\", err); } _next(undefined); }); }; }\n\nfunction ownKeys(object, enumerableOnly) { var keys = Object.keys(object); if (Object.getOwnPropertySymbols) { var symbols = Object.getOwnPropertySymbols(object); if (enumerableOnly) symbols = symbols.filter(function (sym) { return Object.getOwnPropertyDescriptor(object, sym).enumerable; }); keys.push.apply(keys, symbols); } return keys; }\n\nfunction _objectSpread(target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i] != null ? arguments[i] : {}; if (i % 2) { ownKeys(Object(source), true).forEach(function (key) { _defineProperty(target, key, source[key]); }); } else if (Object.getOwnPropertyDescriptors) { Object.defineProperties(target, Object.getOwnPropertyDescriptors(source)); } else { ownKeys(Object(source)).forEach(function (key) { Object.defineProperty(target, key, Object.getOwnPropertyDescriptor(source, key)); }); } } return target; }\n\nfunction _defineProperty(obj, key, value) { if (key in obj) { Object.defineProperty(obj, key, { value: value, enumerable: true, configurable: true, writable: true }); } else { obj[key] = value; } return obj; }\n\nvar ERR_INVALID_ARG_TYPE = require('../../../errors').codes.ERR_INVALID_ARG_TYPE;\n\nfunction from(Readable, iterable, opts) {\n  var iterator;\n\n  if (iterable && typeof iterable.next === 'function') {\n    iterator = iterable;\n  } else if (iterable && iterable[Symbol.asyncIterator]) iterator = iterable[Symbol.asyncIterator]();else if (iterable && iterable[Symbol.iterator]) iterator = iterable[Symbol.iterator]();else throw new ERR_INVALID_ARG_TYPE('iterable', ['Iterable'], iterable);\n\n  var readable = new Readable(_objectSpread({\n    objectMode: true\n  }, opts)); // Reading boolean to protect against _read\n  // being called before last iteration completion.\n\n  var reading = false;\n\n  readable._read = function () {\n    if (!reading) {\n      reading = true;\n      next();\n    }\n  };\n\n  function next() {\n    return _next2.apply(this, arguments);\n  }\n\n  function _next2() {\n    _next2 = _asyncToGenerator(function* () {\n      try {\n        var _ref = yield iterator.next(),\n            value = _ref.value,\n            done = _ref.done;\n\n        if (done) {\n          readable.push(null);\n        } else if (readable.push((yield value))) {\n          next();\n        } else {\n          reading = false;\n        }\n      } catch (err) {\n        readable.destroy(err);\n      }\n    });\n    return _next2.apply(this, arguments);\n  }\n\n  return readable;\n}\n\nmodule.exports = from;","// Ported from https://github.com/mafintosh/pump with\n// permission from the author, Mathias Buus (@mafintosh).\n'use strict';\n\nvar eos;\n\nfunction once(callback) {\n  var called = false;\n  return function () {\n    if (called) return;\n    called = true;\n    callback.apply(void 0, arguments);\n  };\n}\n\nvar _require$codes = require('../../../errors').codes,\n    ERR_MISSING_ARGS = _require$codes.ERR_MISSING_ARGS,\n    ERR_STREAM_DESTROYED = _require$codes.ERR_STREAM_DESTROYED;\n\nfunction noop(err) {\n  // Rethrow the error if it exists to avoid swallowing it\n  if (err) throw err;\n}\n\nfunction isRequest(stream) {\n  return stream.setHeader && typeof stream.abort === 'function';\n}\n\nfunction destroyer(stream, reading, writing, callback) {\n  callback = once(callback);\n  var closed = false;\n  stream.on('close', function () {\n    closed = true;\n  });\n  if (eos === undefined) eos = require('./end-of-stream');\n  eos(stream, {\n    readable: reading,\n    writable: writing\n  }, function (err) {\n    if (err) return callback(err);\n    closed = true;\n    callback();\n  });\n  var destroyed = false;\n  return function (err) {\n    if (closed) return;\n    if (destroyed) return;\n    destroyed = true; // request.destroy just do .end - .abort is what we want\n\n    if (isRequest(stream)) return stream.abort();\n    if (typeof stream.destroy === 'function') return stream.destroy();\n    callback(err || new ERR_STREAM_DESTROYED('pipe'));\n  };\n}\n\nfunction call(fn) {\n  fn();\n}\n\nfunction pipe(from, to) {\n  return from.pipe(to);\n}\n\nfunction popCallback(streams) {\n  if (!streams.length) return noop;\n  if (typeof streams[streams.length - 1] !== 'function') return noop;\n  return streams.pop();\n}\n\nfunction pipeline() {\n  for (var _len = arguments.length, streams = new Array(_len), _key = 0; _key < _len; _key++) {\n    streams[_key] = arguments[_key];\n  }\n\n  var callback = popCallback(streams);\n  if (Array.isArray(streams[0])) streams = streams[0];\n\n  if (streams.length < 2) {\n    throw new ERR_MISSING_ARGS('streams');\n  }\n\n  var error;\n  var destroys = streams.map(function (stream, i) {\n    var reading = i < streams.length - 1;\n    var writing = i > 0;\n    return destroyer(stream, reading, writing, function (err) {\n      if (!error) error = err;\n      if (err) destroys.forEach(call);\n      if (reading) return;\n      destroys.forEach(call);\n      callback(error);\n    });\n  });\n  return streams.reduce(pipe);\n}\n\nmodule.exports = pipeline;","'use strict';\n\nvar ERR_INVALID_OPT_VALUE = require('../../../errors').codes.ERR_INVALID_OPT_VALUE;\n\nfunction highWaterMarkFrom(options, isDuplex, duplexKey) {\n  return options.highWaterMark != null ? options.highWaterMark : isDuplex ? options[duplexKey] : null;\n}\n\nfunction getHighWaterMark(state, options, duplexKey, isDuplex) {\n  var hwm = highWaterMarkFrom(options, isDuplex, duplexKey);\n\n  if (hwm != null) {\n    if (!(isFinite(hwm) && Math.floor(hwm) === hwm) || hwm < 0) {\n      var name = isDuplex ? duplexKey : 'highWaterMark';\n      throw new ERR_INVALID_OPT_VALUE(name, hwm);\n    }\n\n    return Math.floor(hwm);\n  } // Default value\n\n\n  return state.objectMode ? 16 : 16 * 1024;\n}\n\nmodule.exports = {\n  getHighWaterMark: getHighWaterMark\n};","module.exports = require('stream');\n","var Stream = require('stream');\nif (process.env.READABLE_STREAM === 'disable' && Stream) {\n  module.exports = Stream.Readable;\n  Object.assign(module.exports, Stream);\n  module.exports.Stream = Stream;\n} else {\n  exports = module.exports = require('./lib/_stream_readable.js');\n  exports.Stream = Stream || exports;\n  exports.Readable = exports;\n  exports.Writable = require('./lib/_stream_writable.js');\n  exports.Duplex = require('./lib/_stream_duplex.js');\n  exports.Transform = require('./lib/_stream_transform.js');\n  exports.PassThrough = require('./lib/_stream_passthrough.js');\n  exports.finished = require('./lib/internal/streams/end-of-stream.js');\n  exports.pipeline = require('./lib/internal/streams/pipeline.js');\n}\n","// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n'use strict';\n\n/*<replacement>*/\n\nvar Buffer = require('safe-buffer').Buffer;\n/*</replacement>*/\n\nvar isEncoding = Buffer.isEncoding || function (encoding) {\n  encoding = '' + encoding;\n  switch (encoding && encoding.toLowerCase()) {\n    case 'hex':case 'utf8':case 'utf-8':case 'ascii':case 'binary':case 'base64':case 'ucs2':case 'ucs-2':case 'utf16le':case 'utf-16le':case 'raw':\n      return true;\n    default:\n      return false;\n  }\n};\n\nfunction _normalizeEncoding(enc) {\n  if (!enc) return 'utf8';\n  var retried;\n  while (true) {\n    switch (enc) {\n      case 'utf8':\n      case 'utf-8':\n        return 'utf8';\n      case 'ucs2':\n      case 'ucs-2':\n      case 'utf16le':\n      case 'utf-16le':\n        return 'utf16le';\n      case 'latin1':\n      case 'binary':\n        return 'latin1';\n      case 'base64':\n      case 'ascii':\n      case 'hex':\n        return enc;\n      default:\n        if (retried) return; // undefined\n        enc = ('' + enc).toLowerCase();\n        retried = true;\n    }\n  }\n};\n\n// Do not cache `Buffer.isEncoding` when checking encoding names as some\n// modules monkey-patch it to support additional encodings\nfunction normalizeEncoding(enc) {\n  var nenc = _normalizeEncoding(enc);\n  if (typeof nenc !== 'string' && (Buffer.isEncoding === isEncoding || !isEncoding(enc))) throw new Error('Unknown encoding: ' + enc);\n  return nenc || enc;\n}\n\n// StringDecoder provides an interface for efficiently splitting a series of\n// buffers into a series of JS strings without breaking apart multi-byte\n// characters.\nexports.StringDecoder = StringDecoder;\nfunction StringDecoder(encoding) {\n  this.encoding = normalizeEncoding(encoding);\n  var nb;\n  switch (this.encoding) {\n    case 'utf16le':\n      this.text = utf16Text;\n      this.end = utf16End;\n      nb = 4;\n      break;\n    case 'utf8':\n      this.fillLast = utf8FillLast;\n      nb = 4;\n      break;\n    case 'base64':\n      this.text = base64Text;\n      this.end = base64End;\n      nb = 3;\n      break;\n    default:\n      this.write = simpleWrite;\n      this.end = simpleEnd;\n      return;\n  }\n  this.lastNeed = 0;\n  this.lastTotal = 0;\n  this.lastChar = Buffer.allocUnsafe(nb);\n}\n\nStringDecoder.prototype.write = function (buf) {\n  if (buf.length === 0) return '';\n  var r;\n  var i;\n  if (this.lastNeed) {\n    r = this.fillLast(buf);\n    if (r === undefined) return '';\n    i = this.lastNeed;\n    this.lastNeed = 0;\n  } else {\n    i = 0;\n  }\n  if (i < buf.length) return r ? r + this.text(buf, i) : this.text(buf, i);\n  return r || '';\n};\n\nStringDecoder.prototype.end = utf8End;\n\n// Returns only complete characters in a Buffer\nStringDecoder.prototype.text = utf8Text;\n\n// Attempts to complete a partial non-UTF-8 character using bytes from a Buffer\nStringDecoder.prototype.fillLast = function (buf) {\n  if (this.lastNeed <= buf.length) {\n    buf.copy(this.lastChar, this.lastTotal - this.lastNeed, 0, this.lastNeed);\n    return this.lastChar.toString(this.encoding, 0, this.lastTotal);\n  }\n  buf.copy(this.lastChar, this.lastTotal - this.lastNeed, 0, buf.length);\n  this.lastNeed -= buf.length;\n};\n\n// Checks the type of a UTF-8 byte, whether it's ASCII, a leading byte, or a\n// continuation byte. If an invalid byte is detected, -2 is returned.\nfunction utf8CheckByte(byte) {\n  if (byte <= 0x7F) return 0;else if (byte >> 5 === 0x06) return 2;else if (byte >> 4 === 0x0E) return 3;else if (byte >> 3 === 0x1E) return 4;\n  return byte >> 6 === 0x02 ? -1 : -2;\n}\n\n// Checks at most 3 bytes at the end of a Buffer in order to detect an\n// incomplete multi-byte UTF-8 character. The total number of bytes (2, 3, or 4)\n// needed to complete the UTF-8 character (if applicable) are returned.\nfunction utf8CheckIncomplete(self, buf, i) {\n  var j = buf.length - 1;\n  if (j < i) return 0;\n  var nb = utf8CheckByte(buf[j]);\n  if (nb >= 0) {\n    if (nb > 0) self.lastNeed = nb - 1;\n    return nb;\n  }\n  if (--j < i || nb === -2) return 0;\n  nb = utf8CheckByte(buf[j]);\n  if (nb >= 0) {\n    if (nb > 0) self.lastNeed = nb - 2;\n    return nb;\n  }\n  if (--j < i || nb === -2) return 0;\n  nb = utf8CheckByte(buf[j]);\n  if (nb >= 0) {\n    if (nb > 0) {\n      if (nb === 2) nb = 0;else self.lastNeed = nb - 3;\n    }\n    return nb;\n  }\n  return 0;\n}\n\n// Validates as many continuation bytes for a multi-byte UTF-8 character as\n// needed or are available. If we see a non-continuation byte where we expect\n// one, we \"replace\" the validated continuation bytes we've seen so far with\n// a single UTF-8 replacement character ('\\ufffd'), to match v8's UTF-8 decoding\n// behavior. The continuation byte check is included three times in the case\n// where all of the continuation bytes for a character exist in the same buffer.\n// It is also done this way as a slight performance increase instead of using a\n// loop.\nfunction utf8CheckExtraBytes(self, buf, p) {\n  if ((buf[0] & 0xC0) !== 0x80) {\n    self.lastNeed = 0;\n    return '\\ufffd';\n  }\n  if (self.lastNeed > 1 && buf.length > 1) {\n    if ((buf[1] & 0xC0) !== 0x80) {\n      self.lastNeed = 1;\n      return '\\ufffd';\n    }\n    if (self.lastNeed > 2 && buf.length > 2) {\n      if ((buf[2] & 0xC0) !== 0x80) {\n        self.lastNeed = 2;\n        return '\\ufffd';\n      }\n    }\n  }\n}\n\n// Attempts to complete a multi-byte UTF-8 character using bytes from a Buffer.\nfunction utf8FillLast(buf) {\n  var p = this.lastTotal - this.lastNeed;\n  var r = utf8CheckExtraBytes(this, buf, p);\n  if (r !== undefined) return r;\n  if (this.lastNeed <= buf.length) {\n    buf.copy(this.lastChar, p, 0, this.lastNeed);\n    return this.lastChar.toString(this.encoding, 0, this.lastTotal);\n  }\n  buf.copy(this.lastChar, p, 0, buf.length);\n  this.lastNeed -= buf.length;\n}\n\n// Returns all complete UTF-8 characters in a Buffer. If the Buffer ended on a\n// partial character, the character's bytes are buffered until the required\n// number of bytes are available.\nfunction utf8Text(buf, i) {\n  var total = utf8CheckIncomplete(this, buf, i);\n  if (!this.lastNeed) return buf.toString('utf8', i);\n  this.lastTotal = total;\n  var end = buf.length - (total - this.lastNeed);\n  buf.copy(this.lastChar, 0, end);\n  return buf.toString('utf8', i, end);\n}\n\n// For UTF-8, a replacement character is added when ending on a partial\n// character.\nfunction utf8End(buf) {\n  var r = buf && buf.length ? this.write(buf) : '';\n  if (this.lastNeed) return r + '\\ufffd';\n  return r;\n}\n\n// UTF-16LE typically needs two bytes per character, but even if we have an even\n// number of bytes available, we need to check if we end on a leading/high\n// surrogate. In that case, we need to wait for the next two bytes in order to\n// decode the last character properly.\nfunction utf16Text(buf, i) {\n  if ((buf.length - i) % 2 === 0) {\n    var r = buf.toString('utf16le', i);\n    if (r) {\n      var c = r.charCodeAt(r.length - 1);\n      if (c >= 0xD800 && c <= 0xDBFF) {\n        this.lastNeed = 2;\n        this.lastTotal = 4;\n        this.lastChar[0] = buf[buf.length - 2];\n        this.lastChar[1] = buf[buf.length - 1];\n        return r.slice(0, -1);\n      }\n    }\n    return r;\n  }\n  this.lastNeed = 1;\n  this.lastTotal = 2;\n  this.lastChar[0] = buf[buf.length - 1];\n  return buf.toString('utf16le', i, buf.length - 1);\n}\n\n// For UTF-16LE we do not explicitly append special replacement characters if we\n// end on a partial character, we simply let v8 handle that.\nfunction utf16End(buf) {\n  var r = buf && buf.length ? this.write(buf) : '';\n  if (this.lastNeed) {\n    var end = this.lastTotal - this.lastNeed;\n    return r + this.lastChar.toString('utf16le', 0, end);\n  }\n  return r;\n}\n\nfunction base64Text(buf, i) {\n  var n = (buf.length - i) % 3;\n  if (n === 0) return buf.toString('base64', i);\n  this.lastNeed = 3 - n;\n  this.lastTotal = 3;\n  if (n === 1) {\n    this.lastChar[0] = buf[buf.length - 1];\n  } else {\n    this.lastChar[0] = buf[buf.length - 2];\n    this.lastChar[1] = buf[buf.length - 1];\n  }\n  return buf.toString('base64', i, buf.length - n);\n}\n\nfunction base64End(buf) {\n  var r = buf && buf.length ? this.write(buf) : '';\n  if (this.lastNeed) return r + this.lastChar.toString('base64', 0, 3 - this.lastNeed);\n  return r;\n}\n\n// Pass bytes on through for single-byte encodings (e.g. ascii, latin1, hex)\nfunction simpleWrite(buf) {\n  return buf.toString(this.encoding);\n}\n\nfunction simpleEnd(buf) {\n  return buf && buf.length ? this.write(buf) : '';\n}","/*! safe-buffer. MIT License. Feross Aboukhadijeh <https://feross.org/opensource> */\n/* eslint-disable node/no-deprecated-api */\nvar buffer = require('buffer')\nvar Buffer = buffer.Buffer\n\n// alternative to using Object.keys for old browsers\nfunction copyProps (src, dst) {\n  for (var key in src) {\n    dst[key] = src[key]\n  }\n}\nif (Buffer.from && Buffer.alloc && Buffer.allocUnsafe && Buffer.allocUnsafeSlow) {\n  module.exports = buffer\n} else {\n  // Copy properties from require('buffer')\n  copyProps(buffer, exports)\n  exports.Buffer = SafeBuffer\n}\n\nfunction SafeBuffer (arg, encodingOrOffset, length) {\n  return Buffer(arg, encodingOrOffset, length)\n}\n\nSafeBuffer.prototype = Object.create(Buffer.prototype)\n\n// Copy static methods from Buffer\ncopyProps(Buffer, SafeBuffer)\n\nSafeBuffer.from = function (arg, encodingOrOffset, length) {\n  if (typeof arg === 'number') {\n    throw new TypeError('Argument must not be a number')\n  }\n  return Buffer(arg, encodingOrOffset, length)\n}\n\nSafeBuffer.alloc = function (size, fill, encoding) {\n  if (typeof size !== 'number') {\n    throw new TypeError('Argument must be a number')\n  }\n  var buf = Buffer(size)\n  if (fill !== undefined) {\n    if (typeof encoding === 'string') {\n      buf.fill(fill, encoding)\n    } else {\n      buf.fill(fill)\n    }\n  } else {\n    buf.fill(0)\n  }\n  return buf\n}\n\nSafeBuffer.allocUnsafe = function (size) {\n  if (typeof size !== 'number') {\n    throw new TypeError('Argument must be a number')\n  }\n  return Buffer(size)\n}\n\nSafeBuffer.allocUnsafeSlow = function (size) {\n  if (typeof size !== 'number') {\n    throw new TypeError('Argument must be a number')\n  }\n  return buffer.SlowBuffer(size)\n}\n","\n/**\n * For Node.js, simply re-export the core `util.deprecate` function.\n */\n\nmodule.exports = require('util').deprecate;\n"],"names":[],"sourceRoot":""}